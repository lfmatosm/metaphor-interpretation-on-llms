{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW3OQVqUYC0z",
        "outputId": "6af96574-8ef2-41ae-f442-eb2c390a05b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mabsl-py==1.4.0\n",
            "accelerate==0.21.0\n",
            "aiohttp==3.9.1\n",
            "aiosignal==1.3.1\n",
            "alabaster==0.7.13\n",
            "albumentations==1.3.1\n",
            "altair==4.2.2\n",
            "anyio==3.7.1\n",
            "appdirs==1.4.4\n",
            "argon2-cffi==23.1.0\n",
            "argon2-cffi-bindings==21.2.0\n",
            "array-record==0.5.0\n",
            "arviz==0.15.1\n",
            "astropy==5.3.4\n",
            "astunparse==1.6.3\n",
            "async-timeout==4.0.3\n",
            "atpublic==4.0\n",
            "attrs==23.1.0\n",
            "audioread==3.0.1\n",
            "autograd==1.6.2\n",
            "Babel==2.13.1\n",
            "backcall==0.2.0\n",
            "beautifulsoup4==4.11.2\n",
            "bidict==0.22.1\n",
            "bigframes==0.15.0\n",
            "bitsandbytes==0.40.2\n",
            "bleach==6.1.0\n",
            "blinker==1.4\n",
            "blis==0.7.11\n",
            "blosc2==2.0.0\n",
            "bokeh==3.3.1\n",
            "bqplot==0.12.42\n",
            "branca==0.7.0\n",
            "build==1.0.3\n",
            "CacheControl==0.13.1\n",
            "cachetools==5.3.2\n",
            "catalogue==2.0.10\n",
            "certifi==2023.11.17\n",
            "cffi==1.16.0\n",
            "chardet==5.2.0\n",
            "charset-normalizer==3.3.2\n",
            "chex==0.1.7\n",
            "click==8.1.7\n",
            "click-plugins==1.1.1\n",
            "cligj==0.7.2\n",
            "cloudpickle==2.2.1\n",
            "cmake==3.27.7\n",
            "cmdstanpy==1.2.0\n",
            "colorcet==3.0.1\n",
            "colorlover==0.3.0\n",
            "colour==0.1.5\n",
            "community==1.0.0b1\n",
            "confection==0.1.4\n",
            "cons==0.4.6\n",
            "contextlib2==21.6.0\n",
            "contourpy==1.2.0\n",
            "cryptography==41.0.7\n",
            "cufflinks==0.17.3\n",
            "cupy-cuda11x==11.0.0\n",
            "cvxopt==1.3.2\n",
            "cvxpy==1.3.2\n",
            "cycler==0.12.1\n",
            "cymem==2.0.8\n",
            "Cython==3.0.6\n",
            "dask==2023.8.1\n",
            "datascience==0.17.6\n",
            "datasets==2.4.0\n",
            "db-dtypes==1.1.1\n",
            "dbus-python==1.2.18\n",
            "debugpy==1.6.6\n",
            "decorator==4.4.2\n",
            "defusedxml==0.7.1\n",
            "dill==0.3.5.1\n",
            "diskcache==5.6.3\n",
            "distributed==2023.8.1\n",
            "distro==1.7.0\n",
            "dlib==19.24.2\n",
            "dm-tree==0.1.8\n",
            "docker-pycreds==0.4.0\n",
            "docutils==0.18.1\n",
            "dopamine-rl==4.0.6\n",
            "duckdb==0.9.2\n",
            "earthengine-api==0.1.381\n",
            "easydict==1.11\n",
            "ecos==2.0.12\n",
            "editdistance==0.6.2\n",
            "eerepr==0.0.4\n",
            "en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl#sha256=83276fc78a70045627144786b52e1f2728ad5e29e5e43916ec37ea9c26a11212\n",
            "entrypoints==0.4\n",
            "et-xmlfile==1.1.0\n",
            "etils==1.5.2\n",
            "etuples==0.3.9\n",
            "exceptiongroup==1.2.0\n",
            "fastai==2.7.13\n",
            "fastcore==1.5.29\n",
            "fastdownload==0.0.7\n",
            "fastjsonschema==2.19.0\n",
            "fastprogress==1.0.3\n",
            "fastrlock==0.8.2\n",
            "filelock==3.13.1\n",
            "fiona==1.9.5\n",
            "firebase-admin==5.3.0\n",
            "Flask==2.2.5\n",
            "flatbuffers==23.5.26\n",
            "flax==0.7.5\n",
            "folium==0.14.0\n",
            "fonttools==4.45.1\n",
            "frozendict==2.3.10\n",
            "frozenlist==1.4.0\n",
            "fsspec==2023.6.0\n",
            "future==0.18.3\n",
            "gast==0.5.4\n",
            "gcsfs==2023.6.0\n",
            "GDAL==3.4.3\n",
            "gdown==4.6.6\n",
            "geemap==0.28.2\n",
            "gensim==4.3.2\n",
            "geocoder==1.38.1\n",
            "geographiclib==2.0\n",
            "geopandas==0.13.2\n",
            "geopy==2.3.0\n",
            "gin-config==0.5.0\n",
            "gitdb==4.0.11\n",
            "GitPython==3.1.40\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-ai-generativelanguage==0.3.3\n",
            "google-api-core==2.11.1\n",
            "google-api-python-client==2.84.0\n",
            "google-auth==2.17.3\n",
            "google-auth-httplib2==0.1.1\n",
            "google-auth-oauthlib==1.0.0\n",
            "google-cloud-aiplatform==1.36.4\n",
            "google-cloud-bigquery==3.12.0\n",
            "google-cloud-bigquery-connection==1.12.1\n",
            "google-cloud-bigquery-storage==2.23.0\n",
            "google-cloud-core==2.3.3\n",
            "google-cloud-datastore==2.15.2\n",
            "google-cloud-firestore==2.11.1\n",
            "google-cloud-functions==1.13.3\n",
            "google-cloud-iam==2.12.2\n",
            "google-cloud-language==2.9.1\n",
            "google-cloud-resource-manager==1.10.4\n",
            "google-cloud-storage==2.8.0\n",
            "google-cloud-translate==3.11.3\n",
            "google-colab @ file:///colabtools/dist/google-colab-1.0.0.tar.gz#sha256=1e49d2e09c34a7c1be521d9f01d40cea4094d4fa6fe403c41c5ff0b6e3a86211\n",
            "google-crc32c==1.5.0\n",
            "google-generativeai==0.2.2\n",
            "google-pasta==0.2.0\n",
            "google-resumable-media==2.6.0\n",
            "googleapis-common-protos==1.61.0\n",
            "googledrivedownloader==0.4\n",
            "graphviz==0.20.1\n",
            "greenlet==3.0.1\n",
            "grpc-google-iam-v1==0.12.7\n",
            "grpcio==1.59.3\n",
            "grpcio-status==1.48.2\n",
            "gspread==3.4.2\n",
            "gspread-dataframe==3.3.1\n",
            "gym==0.25.2\n",
            "gym-notices==0.0.8\n",
            "h5netcdf==1.3.0\n",
            "h5py==3.9.0\n",
            "holidays==0.37\n",
            "holoviews==1.17.1\n",
            "html5lib==1.1\n",
            "httpimport==1.3.1\n",
            "httplib2==0.22.0\n",
            "huggingface-hub==0.19.4\n",
            "humanize==4.7.0\n",
            "hyperopt==0.2.7\n",
            "ibis-framework==6.2.0\n",
            "idna==3.6\n",
            "imageio==2.31.6\n",
            "imageio-ffmpeg==0.4.9\n",
            "imagesize==1.4.1\n",
            "imbalanced-learn==0.10.1\n",
            "imgaug==0.4.0\n",
            "importlib-metadata==6.8.0\n",
            "importlib-resources==6.1.1\n",
            "imutils==0.5.4\n",
            "inflect==7.0.0\n",
            "iniconfig==2.0.0\n",
            "install==1.3.5\n",
            "intel-openmp==2023.2.0\n",
            "ipyevents==2.0.2\n",
            "ipyfilechooser==0.6.0\n",
            "ipykernel==5.5.6\n",
            "ipyleaflet==0.18.0\n",
            "ipython==7.34.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.5.0\n",
            "ipytree==0.2.2\n",
            "ipywidgets==7.7.1\n",
            "itsdangerous==2.1.2\n",
            "jax==0.4.20\n",
            "jaxlib @ https://storage.googleapis.com/jax-releases/cuda11/jaxlib-0.4.20+cuda11.cudnn86-cp310-cp310-manylinux2014_x86_64.whl#sha256=01be66238133f884bf5adf15cd7eaaf8445f9d4b056c5c64df28a997a6aff2fe\n",
            "jeepney==0.7.1\n",
            "jieba==0.42.1\n",
            "Jinja2==3.1.2\n",
            "joblib==1.3.2\n",
            "jsonpickle==3.0.2\n",
            "jsonschema==4.19.2\n",
            "jsonschema-specifications==2023.11.2\n",
            "jupyter-client==6.1.12\n",
            "jupyter-console==6.1.0\n",
            "jupyter-server==1.24.0\n",
            "jupyter_core==5.5.0\n",
            "jupyterlab-widgets==3.0.9\n",
            "jupyterlab_pygments==0.3.0\n",
            "kaggle==1.5.16\n",
            "keras==2.14.0\n",
            "keyring==23.5.0\n",
            "kiwisolver==1.4.5\n",
            "langcodes==3.3.0\n",
            "launchpadlib==1.10.16\n",
            "lazr.restfulclient==0.14.4\n",
            "lazr.uri==1.0.6\n",
            "lazy_loader==0.3\n",
            "libclang==16.0.6\n",
            "librosa==0.10.1\n",
            "lida==0.0.10\n",
            "lightgbm==4.1.0\n",
            "linkify-it-py==2.0.2\n",
            "llmx==0.0.15a0\n",
            "llvmlite==0.41.1\n",
            "locket==1.0.0\n",
            "logical-unification==0.4.6\n",
            "lxml==4.9.3\n",
            "malloy==2023.1064\n",
            "Markdown==3.5.1\n",
            "markdown-it-py==3.0.0\n",
            "MarkupSafe==2.1.3\n",
            "matplotlib==3.7.1\n",
            "matplotlib-inline==0.1.6\n",
            "matplotlib-venn==0.11.9\n",
            "mdit-py-plugins==0.4.0\n",
            "mdurl==0.1.2\n",
            "miniKanren==1.0.3\n",
            "missingno==0.5.2\n",
            "mistune==0.8.4\n",
            "mizani==0.9.3\n",
            "mkl==2023.2.0\n",
            "ml-dtypes==0.2.0\n",
            "mlxtend==0.22.0\n",
            "more-itertools==10.1.0\n",
            "moviepy==1.0.3\n",
            "mpmath==1.3.0\n",
            "msgpack==1.0.7\n",
            "multidict==6.0.4\n",
            "multipledispatch==1.0.0\n",
            "multiprocess==0.70.13\n",
            "multitasking==0.0.11\n",
            "murmurhash==1.0.10\n",
            "music21==9.1.0\n",
            "natsort==8.4.0\n",
            "nbclassic==1.0.0\n",
            "nbclient==0.9.0\n",
            "nbconvert==6.5.4\n",
            "nbformat==5.9.2\n",
            "nest-asyncio==1.5.8\n",
            "networkx==3.2.1\n",
            "nibabel==4.0.2\n",
            "nltk==3.8.1\n",
            "notebook==6.5.5\n",
            "notebook_shim==0.2.3\n",
            "numba==0.58.1\n",
            "numexpr==2.8.7\n",
            "numpy==1.23.5\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.2.2\n",
            "openai==0.22.0\n",
            "opencv-contrib-python==4.8.0.76\n",
            "opencv-python==4.8.0.76\n",
            "opencv-python-headless==4.8.1.78\n",
            "openpyxl==3.1.2\n",
            "opt-einsum==3.3.0\n",
            "optax==0.1.7\n",
            "orbax-checkpoint==0.4.3\n",
            "osqp==0.6.2.post8\n",
            "packaging==23.2\n",
            "pandas==1.5.3\n",
            "pandas-datareader==0.10.0\n",
            "pandas-gbq==0.17.9\n",
            "pandas-stubs==1.5.3.230304\n",
            "pandocfilters==1.5.0\n",
            "panel==1.3.4\n",
            "param==2.0.1\n",
            "parso==0.8.3\n",
            "parsy==2.1\n",
            "partd==1.4.1\n",
            "pathlib==1.0.1\n",
            "pathtools==0.1.2\n",
            "pathy==0.10.3\n",
            "patsy==0.5.3\n",
            "peewee==3.17.0\n",
            "peft==0.4.0\n",
            "pexpect==4.9.0\n",
            "pickleshare==0.7.5\n",
            "Pillow==9.4.0\n",
            "pip-tools==6.13.0\n",
            "platformdirs==4.0.0\n",
            "plotly==5.15.0\n",
            "plotnine==0.12.4\n",
            "pluggy==1.3.0\n",
            "polars==0.17.3\n",
            "pooch==1.8.0\n",
            "portpicker==1.5.2\n",
            "prefetch-generator==1.0.3\n",
            "preshed==3.0.9\n",
            "prettytable==3.9.0\n",
            "proglog==0.1.10\n",
            "progressbar2==4.2.0\n",
            "prometheus-client==0.19.0\n",
            "promise==2.3\n",
            "prompt-toolkit==3.0.41\n",
            "prophet==1.1.5\n",
            "proto-plus==1.22.3\n",
            "protobuf==3.20.3\n",
            "psutil==5.9.5\n",
            "psycopg2==2.9.9\n",
            "ptyprocess==0.7.0\n",
            "py-cpuinfo==9.0.0\n",
            "py4j==0.10.9.7\n",
            "pyarrow==9.0.0\n",
            "pyasn1==0.5.1\n",
            "pyasn1-modules==0.3.0\n",
            "pycocotools==2.0.7\n",
            "pycparser==2.21\n",
            "pyct==0.5.0\n",
            "pydantic==1.10.13\n",
            "pydata-google-auth==1.8.2\n",
            "pydot==1.4.2\n",
            "pydot-ng==2.0.0\n",
            "pydotplus==2.0.2\n",
            "PyDrive==1.3.1\n",
            "PyDrive2==1.6.3\n",
            "pyerfa==2.0.1.1\n",
            "pygame==2.5.2\n",
            "Pygments==2.16.1\n",
            "PyGObject==3.42.1\n",
            "PyJWT==2.3.0\n",
            "pymc==5.7.2\n",
            "pymystem3==0.2.0\n",
            "PyOpenGL==3.1.7\n",
            "pyOpenSSL==23.3.0\n",
            "pyparsing==3.1.1\n",
            "pyperclip==1.8.2\n",
            "pyproj==3.6.1\n",
            "pyproject_hooks==1.0.0\n",
            "pyshp==2.3.1\n",
            "PySocks==1.7.1\n",
            "pytensor==2.14.2\n",
            "pytest==7.4.3\n",
            "python-apt==0.0.0\n",
            "python-box==7.1.1\n",
            "python-dateutil==2.8.2\n",
            "python-louvain==0.16\n",
            "python-slugify==8.0.1\n",
            "python-utils==3.8.1\n",
            "pytz==2023.3.post1\n",
            "pyviz_comms==3.0.0\n",
            "PyWavelets==1.5.0\n",
            "PyYAML==6.0.1\n",
            "pyzmq==23.2.1\n",
            "qdldl==0.1.7.post0\n",
            "qudida==0.0.4\n",
            "ratelim==0.1.6\n",
            "referencing==0.31.1\n",
            "regex==2023.6.3\n",
            "requests==2.31.0\n",
            "requests-oauthlib==1.3.1\n",
            "requirements-parser==0.5.0\n",
            "responses==0.18.0\n",
            "rich==13.7.0\n",
            "rpds-py==0.13.2\n",
            "rpy2==3.4.2\n",
            "rsa==4.9\n",
            "safetensors==0.4.1\n",
            "scikit-image==0.19.3\n",
            "scikit-learn==1.2.2\n",
            "scipy==1.11.4\n",
            "scooby==0.9.2\n",
            "scs==3.2.4.post1\n",
            "seaborn==0.12.2\n",
            "SecretStorage==3.3.1\n",
            "Send2Trash==1.8.2\n",
            "sentry-sdk==1.38.0\n",
            "setproctitle==1.3.3\n",
            "shapely==2.0.2\n",
            "shortuuid==1.0.11\n",
            "six==1.16.0\n",
            "sklearn-pandas==2.2.0\n",
            "smart-open==6.4.0\n",
            "smmap==5.0.1\n",
            "sniffio==1.3.0\n",
            "snowballstemmer==2.2.0\n",
            "sortedcontainers==2.4.0\n",
            "soundfile==0.12.1\n",
            "soupsieve==2.5\n",
            "soxr==0.3.7\n",
            "spacy==3.6.1\n",
            "spacy-legacy==3.0.12\n",
            "spacy-loggers==1.0.5\n",
            "Sphinx==5.0.2\n",
            "sphinxcontrib-applehelp==1.0.7\n",
            "sphinxcontrib-devhelp==1.0.5\n",
            "sphinxcontrib-htmlhelp==2.0.4\n",
            "sphinxcontrib-jsmath==1.0.1\n",
            "sphinxcontrib-qthelp==1.0.6\n",
            "sphinxcontrib-serializinghtml==1.1.9\n",
            "SQLAlchemy==2.0.23\n",
            "sqlglot==17.16.2\n",
            "sqlparse==0.4.4\n",
            "srsly==2.4.8\n",
            "stanio==0.3.0\n",
            "statsmodels==0.14.0\n",
            "sympy==1.12\n",
            "tables==3.8.0\n",
            "tabulate==0.9.0\n",
            "tbb==2021.11.0\n",
            "tblib==3.0.0\n",
            "tenacity==8.2.3\n",
            "tensorboard==2.14.1\n",
            "tensorboard-data-server==0.7.2\n",
            "tensorflow==2.14.0\n",
            "tensorflow-datasets==4.9.3\n",
            "tensorflow-estimator==2.14.0\n",
            "tensorflow-gcs-config==2.14.0\n",
            "tensorflow-hub==0.15.0\n",
            "tensorflow-io-gcs-filesystem==0.34.0\n",
            "tensorflow-metadata==1.14.0\n",
            "tensorflow-probability==0.22.0\n",
            "tensorstore==0.1.45\n",
            "termcolor==2.3.0\n",
            "terminado==0.18.0\n",
            "text-unidecode==1.3\n",
            "textblob==0.17.1\n",
            "tf-slim==1.1.0\n",
            "thinc==8.1.12\n",
            "threadpoolctl==3.2.0\n",
            "tifffile==2023.9.26\n",
            "tinycss2==1.2.1\n",
            "tokenizers==0.13.3\n",
            "toml==0.10.2\n",
            "tomli==2.0.1\n",
            "toolz==0.12.0\n",
            "torch @ https://download.pytorch.org/whl/cu118/torch-2.1.0%2Bcu118-cp310-cp310-linux_x86_64.whl#sha256=a81b554184492005543ddc32e96469f9369d778dedd195d73bda9bed407d6589\n",
            "torchaudio @ https://download.pytorch.org/whl/cu118/torchaudio-2.1.0%2Bcu118-cp310-cp310-linux_x86_64.whl#sha256=cdfd0a129406155eee595f408cafbb92589652da4090d1d2040f5453d4cae71f\n",
            "torchdata==0.7.0\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.16.0\n",
            "torchvision @ https://download.pytorch.org/whl/cu118/torchvision-0.16.0%2Bcu118-cp310-cp310-linux_x86_64.whl#sha256=033712f65d45afe806676c4129dfe601ad1321d9e092df62b15847c02d4061dc\n",
            "tornado==6.3.2\n",
            "tqdm==4.66.1\n",
            "traitlets==5.7.1\n",
            "traittypes==0.2.1\n",
            "transformers==4.31.0\n",
            "triton==2.1.0\n",
            "trl==0.4.7\n",
            "tweepy==4.14.0\n",
            "typer==0.9.0\n",
            "types-pytz==2023.3.1.1\n",
            "types-setuptools==69.0.0.0\n",
            "typing_extensions==4.5.0\n",
            "tzlocal==5.2\n",
            "uc-micro-py==1.0.2\n",
            "uritemplate==4.1.1\n",
            "urllib3==2.0.7\n",
            "vega-datasets==0.9.0\n",
            "wadllib==1.3.6\n",
            "wandb==0.12.19\n",
            "wasabi==1.1.2\n",
            "wcwidth==0.2.12\n",
            "webcolors==1.13\n",
            "webencodings==0.5.1\n",
            "websocket-client==1.6.4\n",
            "Werkzeug==3.0.1\n",
            "widgetsnbextension==3.6.6\n",
            "wordcloud==1.9.2\n",
            "wrapt==1.14.1\n",
            "xarray==2023.7.0\n",
            "xarray-einstats==0.6.0\n",
            "xgboost==2.0.2\n",
            "xlrd==2.0.1\n",
            "xxhash==3.4.1\n",
            "xyzservices==2023.10.1\n",
            "yarl==1.9.3\n",
            "yellowbrick==1.5\n",
            "yfinance==0.2.32\n",
            "zict==3.0.0\n",
            "zipp==3.17.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.31.0 trl==0.4.7 datasets==2.4.0 huggingface_hub matplotlib numpy>=1.25 openai==0.22.0 wandb==0.12.19 pandas requests scikit_learn scipy gensim\n",
        "# !pip install -q accelerate peft bitsandbytes transformers trl datasets huggingface_hub matplotlib numpy openai wandb pandas requests scikit_learn scipy gensim\n",
        "!pip freeze > requirements.txt\n",
        "!cat requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "GLGv8lVuYC00",
        "outputId": "9d6e0bfa-42e0-4ea1-f3c9-e54d9e7132d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import openai\n",
        "from google.colab import drive\n",
        "drive.mount(\"/gdrive\")\n",
        "WORKDIR=\"/gdrive/My Drive/projects/llms-conceptual-metaphor-interpretation\"\n",
        "import os\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElREVv_LqWJ-"
      },
      "source": [
        "# (Llama2-7B) Few-prompting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWDNx3xCqJKR"
      },
      "source": [
        "## Metaphor List - Source domain prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vA2QsOejFgw",
        "outputId": "91d3efc5-6ee5-456e-d666-8c71f5264769"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-11-28 18:00:34.365081: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-28 18:00:34.365139: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-28 18:00:34.365191: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-28 18:00:36.688635: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "User is already logged in.\n",
            "\n",
            "llm: llama2-7b\n",
            "fine_tuned_model_path: None\n",
            "dataset: metaphor_list\n",
            "task: source_domain_prediction\n",
            "temperature: 0.0\n",
            "seed: 1\n",
            "evaluate: True\n",
            "fine_tuning: False\n",
            "\n",
            "\n",
            "Loading checkpoint shards: 100% 2/2 [01:11<00:00, 35.72s/it]\n",
            "Lenght of train: 132\n",
            "Lenght of valid: 120\n",
            "Train indices: [\n",
            "    [\n",
            "        75,\n",
            "        35\n",
            "    ],\n",
            "    [\n",
            "        110,\n",
            "        107\n",
            "    ],\n",
            "    [\n",
            "        125,\n",
            "        106\n",
            "    ],\n",
            "    [\n",
            "        75,\n",
            "        35,\n",
            "        51,\n",
            "        5\n",
            "    ],\n",
            "    [\n",
            "        125,\n",
            "        108,\n",
            "        58,\n",
            "        59\n",
            "    ],\n",
            "    [\n",
            "        50,\n",
            "        121,\n",
            "        79,\n",
            "        113\n",
            "    ],\n",
            "    [\n",
            "        75,\n",
            "        35,\n",
            "        51,\n",
            "        5,\n",
            "        36,\n",
            "        120\n",
            "    ],\n",
            "    [\n",
            "        126,\n",
            "        49,\n",
            "        78,\n",
            "        95,\n",
            "        107,\n",
            "        57\n",
            "    ],\n",
            "    [\n",
            "        104,\n",
            "        60,\n",
            "        65,\n",
            "        129,\n",
            "        85,\n",
            "        50\n",
            "    ],\n",
            "    [\n",
            "        75,\n",
            "        35,\n",
            "        51,\n",
            "        5,\n",
            "        36,\n",
            "        120,\n",
            "        54,\n",
            "        17\n",
            "    ],\n",
            "    [\n",
            "        53,\n",
            "        122,\n",
            "        80,\n",
            "        113,\n",
            "        49,\n",
            "        33,\n",
            "        73,\n",
            "        50\n",
            "    ],\n",
            "    [\n",
            "        108,\n",
            "        52,\n",
            "        66,\n",
            "        110,\n",
            "        82,\n",
            "        130,\n",
            "        86,\n",
            "        68\n",
            "    ],\n",
            "    [\n",
            "        75,\n",
            "        35,\n",
            "        51,\n",
            "        5,\n",
            "        36,\n",
            "        120,\n",
            "        54,\n",
            "        17,\n",
            "        121,\n",
            "        119,\n",
            "        66,\n",
            "        114\n",
            "    ],\n",
            "    [\n",
            "        103,\n",
            "        60,\n",
            "        65,\n",
            "        129,\n",
            "        85,\n",
            "        50,\n",
            "        33,\n",
            "        89,\n",
            "        53,\n",
            "        106,\n",
            "        105,\n",
            "        107\n",
            "    ],\n",
            "    [\n",
            "        123,\n",
            "        109,\n",
            "        111,\n",
            "        108,\n",
            "        124,\n",
            "        67,\n",
            "        104,\n",
            "        64,\n",
            "        57,\n",
            "        79,\n",
            "        70,\n",
            "        2\n",
            "    ]\n",
            "]\n",
            "\n",
            "Number of parameter combinations: 15 \n",
            "\n",
            "[{'few_shot_sample_indices': [75, 35]}, {'few_shot_sample_indices': [110, 107]}, {'few_shot_sample_indices': [125, 106]}, {'few_shot_sample_indices': [75, 35, 51, 5]}, {'few_shot_sample_indices': [125, 108, 58, 59]}, {'few_shot_sample_indices': [50, 121, 79, 113]}, {'few_shot_sample_indices': [75, 35, 51, 5, 36, 120]}, {'few_shot_sample_indices': [126, 49, 78, 95, 107, 57]}, {'few_shot_sample_indices': [104, 60, 65, 129, 85, 50]}, {'few_shot_sample_indices': [75, 35, 51, 5, 36, 120, 54, 17]}, {'few_shot_sample_indices': [53, 122, 80, 113, 49, 33, 73, 50]}, {'few_shot_sample_indices': [108, 52, 66, 110, 82, 130, 86, 68]}, {'few_shot_sample_indices': [75, 35, 51, 5, 36, 120, 54, 17, 121, 119, 66, 114]}, {'few_shot_sample_indices': [103, 60, 65, 129, 85, 50, 33, 89, 53, 106, 105, 107]}, {'few_shot_sample_indices': [123, 109, 111, 108, 124, 67, 104, 64, 57, 79, 70, 2]}]\n",
            "\n",
            "Current few-shot sample: 1 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.4720093836386999\n",
            "llama2-7b - (fasttext) Standard deviation:  0.10454521816058392\n",
            "\n",
            "Current few-shot sample: 2 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.48558238285283245\n",
            "llama2-7b - (fasttext) Standard deviation:  0.11433277634277733\n",
            "\n",
            "Current few-shot sample: 3 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.456750342870752\n",
            "llama2-7b - (fasttext) Standard deviation:  0.11637371400091556\n",
            "\n",
            "Current few-shot sample: 4 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.4828187885383765\n",
            "llama2-7b - (fasttext) Standard deviation:  0.1099078574459905\n",
            "\n",
            "Current few-shot sample: 5 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.4622267307092746\n",
            "llama2-7b - (fasttext) Standard deviation:  0.1026955201598885\n",
            "\n",
            "Current few-shot sample: 6 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.48639578794439636\n",
            "llama2-7b - (fasttext) Standard deviation:  0.1234236315143692\n",
            "\n",
            "Current few-shot sample: 7 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.4929043826957544\n",
            "llama2-7b - (fasttext) Standard deviation:  0.15248903386265483\n",
            "\n",
            "Current few-shot sample: 8 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.47960087259610495\n",
            "llama2-7b - (fasttext) Standard deviation:  0.10317011439785781\n",
            "\n",
            "Current few-shot sample: 9 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.46093851812183856\n",
            "llama2-7b - (fasttext) Standard deviation:  0.11490236927977181\n",
            "\n",
            "Current few-shot sample: 10 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.4948984608054161\n",
            "llama2-7b - (fasttext) Standard deviation:  0.13053402706934922\n",
            "\n",
            "Current few-shot sample: 11 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.4685552455484867\n",
            "llama2-7b - (fasttext) Standard deviation:  0.10274795747223818\n",
            "\n",
            "Current few-shot sample: 12 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.481391071031491\n",
            "llama2-7b - (fasttext) Standard deviation:  0.1453907262409617\n",
            "\n",
            "Current few-shot sample: 13 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.4714809184273084\n",
            "llama2-7b - (fasttext) Standard deviation:  0.16469034173688246\n",
            "\n",
            "Current few-shot sample: 14 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.46065318981806436\n",
            "llama2-7b - (fasttext) Standard deviation:  0.10219046390894714\n",
            "\n",
            "Current few-shot sample: 15 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.48365463862816493\n",
            "llama2-7b - (fasttext) Standard deviation:  0.1170851527885024\n",
            "Validation results: [\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.4720093836386999,\n",
            "        \"std_em\": 0.10454521816058392,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            75,\n",
            "            35\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.48558238285283245,\n",
            "        \"std_em\": 0.11433277634277733,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            110,\n",
            "            107\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.456750342870752,\n",
            "        \"std_em\": 0.11637371400091556,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            125,\n",
            "            106\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.4828187885383765,\n",
            "        \"std_em\": 0.1099078574459905,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            75,\n",
            "            35,\n",
            "            51,\n",
            "            5\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.4622267307092746,\n",
            "        \"std_em\": 0.1026955201598885,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            125,\n",
            "            108,\n",
            "            58,\n",
            "            59\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.48639578794439636,\n",
            "        \"std_em\": 0.1234236315143692,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            50,\n",
            "            121,\n",
            "            79,\n",
            "            113\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.4929043826957544,\n",
            "        \"std_em\": 0.15248903386265483,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            75,\n",
            "            35,\n",
            "            51,\n",
            "            5,\n",
            "            36,\n",
            "            120\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.47960087259610495,\n",
            "        \"std_em\": 0.10317011439785781,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            126,\n",
            "            49,\n",
            "            78,\n",
            "            95,\n",
            "            107,\n",
            "            57\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.46093851812183856,\n",
            "        \"std_em\": 0.11490236927977181,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            104,\n",
            "            60,\n",
            "            65,\n",
            "            129,\n",
            "            85,\n",
            "            50\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.4948984608054161,\n",
            "        \"std_em\": 0.13053402706934922,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            75,\n",
            "            35,\n",
            "            51,\n",
            "            5,\n",
            "            36,\n",
            "            120,\n",
            "            54,\n",
            "            17\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.4685552455484867,\n",
            "        \"std_em\": 0.10274795747223818,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            53,\n",
            "            122,\n",
            "            80,\n",
            "            113,\n",
            "            49,\n",
            "            33,\n",
            "            73,\n",
            "            50\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.481391071031491,\n",
            "        \"std_em\": 0.1453907262409617,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            108,\n",
            "            52,\n",
            "            66,\n",
            "            110,\n",
            "            82,\n",
            "            130,\n",
            "            86,\n",
            "            68\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.4714809184273084,\n",
            "        \"std_em\": 0.16469034173688246,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            75,\n",
            "            35,\n",
            "            51,\n",
            "            5,\n",
            "            36,\n",
            "            120,\n",
            "            54,\n",
            "            17,\n",
            "            121,\n",
            "            119,\n",
            "            66,\n",
            "            114\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.46065318981806436,\n",
            "        \"std_em\": 0.10219046390894714,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            103,\n",
            "            60,\n",
            "            65,\n",
            "            129,\n",
            "            85,\n",
            "            50,\n",
            "            33,\n",
            "            89,\n",
            "            53,\n",
            "            106,\n",
            "            105,\n",
            "            107\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.48365463862816493,\n",
            "        \"std_em\": 0.1170851527885024,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            123,\n",
            "            109,\n",
            "            111,\n",
            "            108,\n",
            "            124,\n",
            "            67,\n",
            "            104,\n",
            "            64,\n",
            "            57,\n",
            "            79,\n",
            "            70,\n",
            "            2\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    }\n",
            "]\n",
            "\n",
            "Lenght of test: 244\n",
            "Getting completions...\n",
            "Evaluating test set performance...\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.4875150193445018\n",
            "llama2-7b - (fasttext) Standard deviation:  0.12321749099917086\n",
            "Test results: {\n",
            "    \"model\": \"llama2-7b\",\n",
            "    \"acc\": 0.0,\n",
            "    \"mean_em\": 0.4875150193445018,\n",
            "    \"std_em\": 0.12321749099917086,\n",
            "    \"few_shot_sample_indices\": [\n",
            "        75,\n",
            "        35,\n",
            "        51,\n",
            "        5,\n",
            "        36,\n",
            "        120,\n",
            "        54,\n",
            "        17\n",
            "    ],\n",
            "    \"few_shot_samples\": 8,\n",
            "    \"temperature\": 0.0,\n",
            "    \"eval_split\": \"test\",\n",
            "    \"dataset_name\": \"metaphor_list\",\n",
            "    \"fine_tuning\": false\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"$WORKDIR\" python -m src.main --llm llama2-7b --temperature 0 --dataset metaphor_list --task source_domain_prediction --seed 1 --evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3Y3nzHsqPwh"
      },
      "source": [
        "## Metaphor list - Target domain prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzxNTyLld7AZ",
        "outputId": "e4da1125-19bb-4f94-b0d2-2c55d69bd06a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-11-28 19:26:04.086712: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-28 19:26:04.086762: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-28 19:26:04.086797: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-28 19:26:05.987552: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "User is already logged in.\n",
            "\n",
            "llm: llama2-7b\n",
            "fine_tuned_model_path: None\n",
            "dataset: metaphor_list\n",
            "task: target_domain_prediction\n",
            "temperature: 0.0\n",
            "seed: 1\n",
            "evaluate: True\n",
            "fine_tuning: False\n",
            "\n",
            "\n",
            "Loading checkpoint shards: 100% 2/2 [01:13<00:00, 36.67s/it]\n",
            "Lenght of train: 132\n",
            "Lenght of valid: 120\n",
            "Train indices: [\n",
            "    [\n",
            "        75,\n",
            "        35\n",
            "    ],\n",
            "    [\n",
            "        110,\n",
            "        107\n",
            "    ],\n",
            "    [\n",
            "        125,\n",
            "        106\n",
            "    ],\n",
            "    [\n",
            "        75,\n",
            "        35,\n",
            "        51,\n",
            "        5\n",
            "    ],\n",
            "    [\n",
            "        125,\n",
            "        108,\n",
            "        58,\n",
            "        59\n",
            "    ],\n",
            "    [\n",
            "        50,\n",
            "        121,\n",
            "        79,\n",
            "        113\n",
            "    ],\n",
            "    [\n",
            "        75,\n",
            "        35,\n",
            "        51,\n",
            "        5,\n",
            "        36,\n",
            "        120\n",
            "    ],\n",
            "    [\n",
            "        126,\n",
            "        49,\n",
            "        78,\n",
            "        95,\n",
            "        107,\n",
            "        57\n",
            "    ],\n",
            "    [\n",
            "        104,\n",
            "        60,\n",
            "        65,\n",
            "        129,\n",
            "        85,\n",
            "        50\n",
            "    ],\n",
            "    [\n",
            "        75,\n",
            "        35,\n",
            "        51,\n",
            "        5,\n",
            "        36,\n",
            "        120,\n",
            "        54,\n",
            "        17\n",
            "    ],\n",
            "    [\n",
            "        53,\n",
            "        122,\n",
            "        80,\n",
            "        113,\n",
            "        49,\n",
            "        33,\n",
            "        73,\n",
            "        50\n",
            "    ],\n",
            "    [\n",
            "        108,\n",
            "        52,\n",
            "        66,\n",
            "        110,\n",
            "        82,\n",
            "        130,\n",
            "        86,\n",
            "        68\n",
            "    ],\n",
            "    [\n",
            "        75,\n",
            "        35,\n",
            "        51,\n",
            "        5,\n",
            "        36,\n",
            "        120,\n",
            "        54,\n",
            "        17,\n",
            "        121,\n",
            "        119,\n",
            "        66,\n",
            "        114\n",
            "    ],\n",
            "    [\n",
            "        103,\n",
            "        60,\n",
            "        65,\n",
            "        129,\n",
            "        85,\n",
            "        50,\n",
            "        33,\n",
            "        89,\n",
            "        53,\n",
            "        106,\n",
            "        105,\n",
            "        107\n",
            "    ],\n",
            "    [\n",
            "        123,\n",
            "        109,\n",
            "        111,\n",
            "        108,\n",
            "        124,\n",
            "        67,\n",
            "        104,\n",
            "        64,\n",
            "        57,\n",
            "        79,\n",
            "        70,\n",
            "        2\n",
            "    ]\n",
            "]\n",
            "\n",
            "Number of parameter combinations: 15 \n",
            "\n",
            "[{'few_shot_sample_indices': [75, 35]}, {'few_shot_sample_indices': [110, 107]}, {'few_shot_sample_indices': [125, 106]}, {'few_shot_sample_indices': [75, 35, 51, 5]}, {'few_shot_sample_indices': [125, 108, 58, 59]}, {'few_shot_sample_indices': [50, 121, 79, 113]}, {'few_shot_sample_indices': [75, 35, 51, 5, 36, 120]}, {'few_shot_sample_indices': [126, 49, 78, 95, 107, 57]}, {'few_shot_sample_indices': [104, 60, 65, 129, 85, 50]}, {'few_shot_sample_indices': [75, 35, 51, 5, 36, 120, 54, 17]}, {'few_shot_sample_indices': [53, 122, 80, 113, 49, 33, 73, 50]}, {'few_shot_sample_indices': [108, 52, 66, 110, 82, 130, 86, 68]}, {'few_shot_sample_indices': [75, 35, 51, 5, 36, 120, 54, 17, 121, 119, 66, 114]}, {'few_shot_sample_indices': [103, 60, 65, 129, 85, 50, 33, 89, 53, 106, 105, 107]}, {'few_shot_sample_indices': [123, 109, 111, 108, 124, 67, 104, 64, 57, 79, 70, 2]}]\n",
            "\n",
            "Current few-shot sample: 1 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' search\n",
            "Context: In linguistics, conceptual ', but wanted ' missing  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sound\n",
            "Context: In linguistics, conceptual ', but wanted ' bells  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' time\n",
            "Context: In linguistics, conceptual ', but wanted ' time  '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5040223093082508\n",
            "llama2-7b - (fasttext) Standard deviation:  0.14402223757133065\n",
            "\n",
            "Current few-shot sample: 2 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' scientist\n",
            "Context: In linguistics, concept ', but wanted ' missing  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sound\n",
            "Context: In linguistics, conceptual ', but wanted ' bells  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' time\n",
            "Context: In linguistics, conceptual ', but wanted ' time  '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5123609642187754\n",
            "llama2-7b - (fasttext) Standard deviation:  0.14029864150138757\n",
            "\n",
            "Current few-shot sample: 3 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' scientist\n",
            "Context: In linguistics, concept ', but wanted ' missing  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sound\n",
            "Context: In linguistics, conceptual ', but wanted ' bells  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' time\n",
            "Context: In linguistics, conceptual ', but wanted ' time  '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.523089346041282\n",
            "llama2-7b - (fasttext) Standard deviation:  0.15224543945467403\n",
            "\n",
            "Current few-shot sample: 4 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' missing\n",
            "Context: In linguistics, conceptual ', but wanted ' missing  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sound\n",
            "Context: In linguistics, conceptual ', but wanted ' bells  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' time\n",
            "Context: In linguistics, conceptual ', but wanted ' time  '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5162998246649901\n",
            "llama2-7b - (fasttext) Standard deviation:  0.15166793653338212\n",
            "\n",
            "Current few-shot sample: 5 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' scientist\n",
            "Context: In linguistics, concept ', but wanted ' missing  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sound\n",
            "Context: In linguistics, conceptual ', but wanted ' bells  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' time\n",
            "Context: In linguistics, conceptual ', but wanted ' time  '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5123126536607743\n",
            "llama2-7b - (fasttext) Standard deviation:  0.15010812013980573\n",
            "\n",
            "Current few-shot sample: 6 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' scientist\n",
            "Context: In linguistics, concept ', but wanted ' missing  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sound\n",
            "Context: In linguistics, conceptual ', but wanted ' bells  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' instruction\n",
            "Context: In linguistics, conceptual ', but wanted ' time  '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5076181069016457\n",
            "llama2-7b - (fasttext) Standard deviation:  0.14216040796674598\n",
            "\n",
            "Current few-shot sample: 7 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' people\n",
            "Context: In linguistics, conceptual ', but wanted ' missing  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sounds\n",
            "Context: In linguistics, conceptual ', but wanted ' bells  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' days\n",
            "Context: In linguistics, conceptual ', but wanted ' time  '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5170022919774055\n",
            "llama2-7b - (fasttext) Standard deviation:  0.1500096662426405\n",
            "\n",
            "Current few-shot sample: 8 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' scientists\n",
            "Context: In linguistics, concept ', but wanted ' missing  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sound\n",
            "Context: In linguistics, conceptual ', but wanted ' bells  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' time\n",
            "Context: In linguistics, conceptual ', but wanted ' time  '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5183807380497456\n",
            "llama2-7b - (fasttext) Standard deviation:  0.15691528281989411\n",
            "\n",
            "Current few-shot sample: 9 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' scientist\n",
            "Context: In linguistics, concept ', but wanted ' missing  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sound\n",
            "Context: In linguistics, conceptual ', but wanted ' bells  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' instruction\n",
            "Context: In linguistics, conceptual ', but wanted ' time  '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5149344243109226\n",
            "llama2-7b - (fasttext) Standard deviation:  0.153142711674318\n",
            "\n",
            "Current few-shot sample: 10 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' scientists\n",
            "Context: In linguistics, concept ', but wanted ' missing  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sounds\n",
            "Context: In linguistics, conceptual ', but wanted ' bells  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' time\n",
            "Context: In linguistics, conceptual ', but wanted ' time  '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5121978898843129\n",
            "llama2-7b - (fasttext) Standard deviation:  0.14864084636388025\n",
            "\n",
            "Current few-shot sample: 11 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' scientists\n",
            "Context: In linguistics, concept ', but wanted ' missing  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sound\n",
            "Context: In linguistics, conceptual ', but wanted ' bells  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' instruction\n",
            "Context: In linguistics, conceptual ', but wanted ' time  '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.52283564483126\n",
            "llama2-7b - (fasttext) Standard deviation:  0.15054105761367542\n",
            "\n",
            "Current few-shot sample: 12 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' scientist\n",
            "Context: In linguistics, concept ', but wanted ' missing  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sound\n",
            "Context: In linguistics, conceptual ', but wanted ' bells  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' instruction\n",
            "Context: In linguistics, conceptual ', but wanted ' time  '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5256492170194785\n",
            "llama2-7b - (fasttext) Standard deviation:  0.1536201138441554\n",
            "\n",
            "Current few-shot sample: 13 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' scientists\n",
            "Context: In linguistics, concept ', but wanted ' missing  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' doorbells\n",
            "Context: In linguistics, ', but wanted ' bells  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' time\n",
            "Context: In linguistics, conceptual ', but wanted ' time  '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.517762125035127\n",
            "llama2-7b - (fasttext) Standard deviation:  0.14439987166482815\n",
            "\n",
            "Current few-shot sample: 14 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' scientist\n",
            "Context: In linguistics, concept ', but wanted ' missing  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sound\n",
            "Context: In linguistics, conceptual ', but wanted ' bells  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' instruction\n",
            "Context: In linguistics, conceptual ', but wanted ' time  '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5129846877108017\n",
            "llama2-7b - (fasttext) Standard deviation:  0.15116430790337956\n",
            "\n",
            "Current few-shot sample: 15 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' scientist\n",
            "Context: In linguistics, concept ', but wanted ' missing  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sound\n",
            "Context: In linguistics, conceptual ', but wanted ' bells  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' instruction\n",
            "Context: In linguistics, conceptual ', but wanted ' time  '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5253143257151047\n",
            "llama2-7b - (fasttext) Standard deviation:  0.15286828678300224\n",
            "Validation results: [\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.5040223093082508,\n",
            "        \"std_em\": 0.14402223757133065,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            75,\n",
            "            35\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.5123609642187754,\n",
            "        \"std_em\": 0.14029864150138757,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            110,\n",
            "            107\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.523089346041282,\n",
            "        \"std_em\": 0.15224543945467403,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            125,\n",
            "            106\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.5162998246649901,\n",
            "        \"std_em\": 0.15166793653338212,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            75,\n",
            "            35,\n",
            "            51,\n",
            "            5\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.5123126536607743,\n",
            "        \"std_em\": 0.15010812013980573,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            125,\n",
            "            108,\n",
            "            58,\n",
            "            59\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.5076181069016457,\n",
            "        \"std_em\": 0.14216040796674598,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            50,\n",
            "            121,\n",
            "            79,\n",
            "            113\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.5170022919774055,\n",
            "        \"std_em\": 0.1500096662426405,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            75,\n",
            "            35,\n",
            "            51,\n",
            "            5,\n",
            "            36,\n",
            "            120\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.5183807380497456,\n",
            "        \"std_em\": 0.15691528281989411,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            126,\n",
            "            49,\n",
            "            78,\n",
            "            95,\n",
            "            107,\n",
            "            57\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.5149344243109226,\n",
            "        \"std_em\": 0.153142711674318,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            104,\n",
            "            60,\n",
            "            65,\n",
            "            129,\n",
            "            85,\n",
            "            50\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.5121978898843129,\n",
            "        \"std_em\": 0.14864084636388025,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            75,\n",
            "            35,\n",
            "            51,\n",
            "            5,\n",
            "            36,\n",
            "            120,\n",
            "            54,\n",
            "            17\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.52283564483126,\n",
            "        \"std_em\": 0.15054105761367542,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            53,\n",
            "            122,\n",
            "            80,\n",
            "            113,\n",
            "            49,\n",
            "            33,\n",
            "            73,\n",
            "            50\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.5256492170194785,\n",
            "        \"std_em\": 0.1536201138441554,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            108,\n",
            "            52,\n",
            "            66,\n",
            "            110,\n",
            "            82,\n",
            "            130,\n",
            "            86,\n",
            "            68\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.517762125035127,\n",
            "        \"std_em\": 0.14439987166482815,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            75,\n",
            "            35,\n",
            "            51,\n",
            "            5,\n",
            "            36,\n",
            "            120,\n",
            "            54,\n",
            "            17,\n",
            "            121,\n",
            "            119,\n",
            "            66,\n",
            "            114\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.5129846877108017,\n",
            "        \"std_em\": 0.15116430790337956,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            103,\n",
            "            60,\n",
            "            65,\n",
            "            129,\n",
            "            85,\n",
            "            50,\n",
            "            33,\n",
            "            89,\n",
            "            53,\n",
            "            106,\n",
            "            105,\n",
            "            107\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.5253143257151047,\n",
            "        \"std_em\": 0.15286828678300224,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            123,\n",
            "            109,\n",
            "            111,\n",
            "            108,\n",
            "            124,\n",
            "            67,\n",
            "            104,\n",
            "            64,\n",
            "            57,\n",
            "            79,\n",
            "            70,\n",
            "            2\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    }\n",
            "]\n",
            "\n",
            "Lenght of test: 244\n",
            "Getting completions...\n",
            "Evaluating test set performance...\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' scanning\n",
            "Context: In linguistics, concept ', but wanted ' scanning  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' crouching\n",
            "Context: In linguistics, ', but wanted ' arriving  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' population\n",
            "Context: In linguistics, conceptual ', but wanted ' paths   '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5464976504445076\n",
            "llama2-7b - (fasttext) Standard deviation:  0.14243733656309057\n",
            "Test results: {\n",
            "    \"model\": \"llama2-7b\",\n",
            "    \"acc\": 0.0,\n",
            "    \"mean_em\": 0.5464976504445076,\n",
            "    \"std_em\": 0.14243733656309057,\n",
            "    \"few_shot_sample_indices\": [\n",
            "        108,\n",
            "        52,\n",
            "        66,\n",
            "        110,\n",
            "        82,\n",
            "        130,\n",
            "        86,\n",
            "        68\n",
            "    ],\n",
            "    \"few_shot_samples\": 8,\n",
            "    \"temperature\": 0.0,\n",
            "    \"eval_split\": \"test\",\n",
            "    \"dataset_name\": \"metaphor_list\",\n",
            "    \"fine_tuning\": false\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"$WORKDIR\" python -m src.main --llm llama2-7b --temperature 0 --dataset metaphor_list --task target_domain_prediction --seed 1 --evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqWhDsCRqrVD"
      },
      "source": [
        "## LCC (EN) - Source domain prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZxC1ivwnzNX",
        "outputId": "320cb4c8-a7f6-4a08-9058-95a0f62c54fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-11-28 16:34:38.277487: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-28 16:34:38.277544: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-28 16:34:38.277586: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-28 16:34:39.878132: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n",
            "\n",
            "llm: llama2-7b\n",
            "fine_tuned_model_path: None\n",
            "dataset: lcc_en_subset\n",
            "task: source_domain_prediction\n",
            "temperature: 0.0\n",
            "seed: 1\n",
            "evaluate: True\n",
            "fine_tuning: False\n",
            "\n",
            "\n",
            "config.json: 100% 609/609 [00:00<00:00, 3.22MB/s]\n",
            "model.safetensors.index.json: 100% 26.8k/26.8k [00:00<00:00, 21.8MB/s]\n",
            "Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00001-of-00002.safetensors:   0% 0.00/9.98G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 10.5M/9.98G [00:00<01:44, 95.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 41.9M/9.98G [00:00<00:56, 177MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 73.4M/9.98G [00:00<00:49, 199MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 105M/9.98G [00:00<00:46, 210MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 126M/9.98G [00:00<00:47, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 147M/9.98G [00:00<00:48, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 168M/9.98G [00:00<00:49, 200MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 189M/9.98G [00:00<00:49, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 210M/9.98G [00:01<00:49, 199MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 231M/9.98G [00:01<00:48, 200MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 252M/9.98G [00:01<00:48, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 273M/9.98G [00:01<00:47, 202MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 294M/9.98G [00:01<00:47, 204MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 325M/9.98G [00:01<00:46, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 357M/9.98G [00:01<00:45, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 388M/9.98G [00:01<00:45, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 419M/9.98G [00:02<00:44, 213MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 451M/9.98G [00:02<00:45, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 482M/9.98G [00:02<00:46, 204MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 503M/9.98G [00:02<00:46, 202MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 535M/9.98G [00:02<00:45, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 556M/9.98G [00:05<05:07, 30.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 577M/9.98G [00:05<04:00, 39.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 598M/9.98G [00:05<03:10, 49.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 619M/9.98G [00:05<02:41, 58.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 640M/9.98G [00:05<02:10, 71.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 671M/9.98G [00:05<01:37, 95.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 692M/9.98G [00:05<01:24, 110MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 713M/9.98G [00:06<01:16, 122MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 734M/9.98G [00:06<01:13, 126MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 755M/9.98G [00:06<01:07, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 776M/9.98G [00:06<01:01, 149MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 797M/9.98G [00:06<00:56, 162MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 818M/9.98G [00:06<00:52, 173MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 839M/9.98G [00:06<00:50, 179MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 860M/9.98G [00:06<00:52, 172MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 881M/9.98G [00:07<00:51, 175MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 902M/9.98G [00:07<00:50, 179MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 923M/9.98G [00:07<00:50, 180MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 944M/9.98G [00:07<00:49, 182MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 965M/9.98G [00:08<03:13, 46.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 996M/9.98G [00:08<02:13, 67.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 1.02G/9.98G [00:08<01:50, 81.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 1.04G/9.98G [00:09<01:41, 88.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.06G/9.98G [00:09<01:25, 104MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.09G/9.98G [00:09<01:08, 129MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.11G/9.98G [00:09<01:03, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.13G/9.98G [00:09<01:03, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 1.15G/9.98G [00:09<00:59, 148MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 1.17G/9.98G [00:10<01:38, 89.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 1.20G/9.98G [00:10<01:22, 107MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 1.22G/9.98G [00:10<01:11, 123MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.25G/9.98G [00:10<01:04, 135MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.27G/9.98G [00:10<01:02, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.29G/9.98G [00:10<00:58, 149MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.32G/9.98G [00:10<00:51, 169MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.34G/9.98G [00:11<00:51, 169MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 1.37G/9.98G [00:11<00:46, 183MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 1.39G/9.98G [00:11<00:45, 188MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 1.43G/9.98G [00:11<00:43, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.46G/9.98G [00:11<00:41, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.49G/9.98G [00:11<00:40, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.52G/9.98G [00:11<00:40, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 1.55G/9.98G [00:12<00:40, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 1.57G/9.98G [00:12<00:40, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 1.60G/9.98G [00:12<00:40, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 1.63G/9.98G [00:12<00:41, 203MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.66G/9.98G [00:12<00:39, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.69G/9.98G [00:12<00:38, 213MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.72G/9.98G [00:12<00:38, 213MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.75G/9.98G [00:13<00:38, 215MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.78G/9.98G [00:13<00:37, 219MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.81G/9.98G [00:13<00:37, 220MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.85G/9.98G [00:13<00:38, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 1.88G/9.98G [00:13<00:38, 208MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 1.91G/9.98G [00:13<00:38, 208MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 1.93G/9.98G [00:15<02:48, 47.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.95G/9.98G [00:16<04:27, 30.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.98G/9.98G [00:17<03:07, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 2.00G/9.98G [00:17<02:37, 50.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 2.02G/9.98G [00:17<02:11, 60.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 2.04G/9.98G [00:17<01:47, 74.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 2.08G/9.98G [00:17<01:20, 98.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 2.11G/9.98G [00:17<01:06, 119MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 2.13G/9.98G [00:17<00:59, 133MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.15G/9.98G [00:17<00:54, 144MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.18G/9.98G [00:18<00:47, 164MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.21G/9.98G [00:18<00:43, 180MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.24G/9.98G [00:18<00:40, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.28G/9.98G [00:18<00:38, 199MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.31G/9.98G [00:18<00:37, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.34G/9.98G [00:18<00:35, 213MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.37G/9.98G [00:18<00:35, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.40G/9.98G [00:19<00:36, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.43G/9.98G [00:19<00:36, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.46G/9.98G [00:20<01:49, 68.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.49G/9.98G [00:21<03:20, 37.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.51G/9.98G [00:22<02:42, 46.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.53G/9.98G [00:22<02:11, 56.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.55G/9.98G [00:22<01:45, 70.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.58G/9.98G [00:22<01:18, 93.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.60G/9.98G [00:22<01:10, 104MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.62G/9.98G [00:22<01:01, 120MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.64G/9.98G [00:22<00:54, 135MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.67G/9.98G [00:22<00:47, 153MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.69G/9.98G [00:23<00:45, 160MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.72G/9.98G [00:23<00:45, 161MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.74G/9.98G [00:23<00:42, 170MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.76G/9.98G [00:23<00:41, 174MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.79G/9.98G [00:23<00:38, 186MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.81G/9.98G [00:23<00:37, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.84G/9.98G [00:23<00:36, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.86G/9.98G [00:23<00:36, 194MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.88G/9.98G [00:23<00:37, 189MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.90G/9.98G [00:24<00:38, 186MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.93G/9.98G [00:24<00:38, 183MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 2.95G/9.98G [00:24<00:39, 177MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 2.97G/9.98G [00:26<04:34, 25.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 3.00G/9.98G [00:27<02:59, 38.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 3.02G/9.98G [00:27<02:24, 48.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 3.04G/9.98G [00:27<02:01, 57.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.06G/9.98G [00:27<01:37, 70.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.09G/9.98G [00:27<01:12, 95.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.11G/9.98G [00:27<01:02, 109MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.14G/9.98G [00:27<00:55, 123MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.16G/9.98G [00:27<00:49, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.19G/9.98G [00:28<00:42, 159MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.21G/9.98G [00:28<00:39, 170MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.23G/9.98G [00:28<00:37, 178MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.26G/9.98G [00:28<00:35, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.29G/9.98G [00:28<00:33, 199MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.32G/9.98G [00:28<00:32, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.36G/9.98G [00:28<00:31, 208MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.39G/9.98G [00:29<00:32, 203MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.41G/9.98G [00:29<00:47, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.44G/9.98G [00:29<00:41, 158MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.47G/9.98G [00:29<00:37, 175MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.50G/9.98G [00:29<00:34, 187MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.52G/9.98G [00:29<00:34, 187MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.54G/9.98G [00:30<00:35, 180MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.57G/9.98G [00:30<00:34, 183MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.59G/9.98G [00:30<00:34, 187MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.61G/9.98G [00:30<00:33, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.64G/9.98G [00:31<02:13, 47.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.67G/9.98G [00:31<01:38, 64.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.69G/9.98G [00:32<01:22, 76.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.71G/9.98G [00:32<01:13, 85.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.74G/9.98G [00:32<00:57, 109MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.77G/9.98G [00:32<00:47, 131MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.80G/9.98G [00:32<00:43, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.82G/9.98G [00:32<00:41, 148MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.84G/9.98G [00:32<00:39, 155MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.87G/9.98G [00:33<00:35, 171MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.90G/9.98G [00:33<00:33, 182MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.93G/9.98G [00:33<00:31, 195MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 3.96G/9.98G [00:33<00:29, 204MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 4.00G/9.98G [00:33<00:30, 199MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 4.02G/9.98G [00:33<00:29, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.05G/9.98G [00:33<00:29, 204MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.08G/9.98G [00:34<00:27, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.11G/9.98G [00:34<00:27, 216MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.14G/9.98G [00:34<00:26, 219MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.17G/9.98G [00:34<00:27, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.20G/9.98G [00:34<00:27, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.24G/9.98G [00:34<00:26, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.27G/9.98G [00:34<00:26, 216MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.30G/9.98G [00:35<00:26, 218MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.33G/9.98G [00:35<00:27, 203MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.35G/9.98G [00:35<00:27, 204MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.37G/9.98G [00:35<00:27, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.39G/9.98G [00:35<00:28, 196MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.41G/9.98G [00:36<01:52, 49.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.44G/9.98G [00:36<01:28, 62.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 4.46G/9.98G [00:37<01:11, 77.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 4.48G/9.98G [00:37<01:04, 85.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 4.50G/9.98G [00:37<00:54, 101MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 4.52G/9.98G [00:37<00:46, 117MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.55G/9.98G [00:37<00:40, 135MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.57G/9.98G [00:37<00:38, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.59G/9.98G [00:37<00:38, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.61G/9.98G [00:38<00:36, 147MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.65G/9.98G [00:38<00:31, 167MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.68G/9.98G [00:38<00:29, 180MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.70G/9.98G [00:38<00:29, 181MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.72G/9.98G [00:38<00:29, 180MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.74G/9.98G [00:38<00:28, 187MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.76G/9.98G [00:38<00:29, 180MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.79G/9.98G [00:38<00:27, 188MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.81G/9.98G [00:39<00:27, 189MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.83G/9.98G [00:39<00:26, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.85G/9.98G [00:39<00:26, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.88G/9.98G [00:39<00:26, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.90G/9.98G [00:39<00:27, 184MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.92G/9.98G [00:39<00:27, 181MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 4.94G/9.98G [00:41<02:53, 29.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 4.96G/9.98G [00:41<02:08, 39.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 4.98G/9.98G [00:42<01:40, 49.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 5.00G/9.98G [00:42<01:23, 59.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 5.03G/9.98G [00:42<00:59, 83.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.05G/9.98G [00:42<00:50, 97.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.08G/9.98G [00:42<00:42, 114MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.10G/9.98G [00:42<00:39, 124MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.12G/9.98G [00:42<00:35, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.14G/9.98G [00:42<00:31, 152MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.16G/9.98G [00:43<00:29, 165MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.19G/9.98G [00:43<00:26, 183MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.22G/9.98G [00:43<00:24, 195MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.25G/9.98G [00:43<00:24, 196MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.27G/9.98G [00:43<00:24, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.30G/9.98G [00:43<00:36, 127MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.32G/9.98G [00:44<00:32, 142MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.34G/9.98G [00:44<00:29, 155MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 5.36G/9.98G [00:44<00:27, 165MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 5.38G/9.98G [00:46<03:04, 24.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 5.41G/9.98G [00:47<02:01, 37.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 5.43G/9.98G [00:47<01:35, 47.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.45G/9.98G [00:47<01:20, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.47G/9.98G [00:47<01:03, 70.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.49G/9.98G [00:47<00:51, 86.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.53G/9.98G [00:47<00:40, 111MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 5.55G/9.98G [00:47<00:35, 123MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 5.57G/9.98G [00:47<00:32, 136MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 5.60G/9.98G [00:48<00:28, 156MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 5.62G/9.98G [00:48<00:26, 167MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.65G/9.98G [00:48<00:23, 183MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.68G/9.98G [00:48<00:21, 196MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.71G/9.98G [00:48<00:20, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.75G/9.98G [00:48<00:20, 202MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.78G/9.98G [00:48<00:20, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.81G/9.98G [00:49<00:19, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.84G/9.98G [00:51<02:05, 32.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.86G/9.98G [00:51<01:42, 40.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.88G/9.98G [00:52<01:22, 49.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.90G/9.98G [00:52<01:07, 60.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.92G/9.98G [00:52<00:55, 73.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 5.95G/9.98G [00:52<00:46, 87.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 5.97G/9.98G [00:52<00:39, 101MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 5.99G/9.98G [00:52<00:34, 115MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 6.01G/9.98G [00:52<00:30, 130MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 6.03G/9.98G [00:52<00:27, 144MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.05G/9.98G [00:53<00:24, 159MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.07G/9.98G [00:53<00:23, 169MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.09G/9.98G [00:53<00:21, 179MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.11G/9.98G [00:53<00:20, 186MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.13G/9.98G [00:53<00:21, 177MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.16G/9.98G [00:53<00:21, 176MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.18G/9.98G [00:53<00:22, 168MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.20G/9.98G [00:53<00:22, 170MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.22G/9.98G [00:53<00:21, 174MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.24G/9.98G [00:54<00:21, 176MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.26G/9.98G [00:54<00:20, 181MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.28G/9.98G [00:54<00:19, 185MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.30G/9.98G [00:54<00:19, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.32G/9.98G [00:54<00:18, 195MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 6.34G/9.98G [00:54<00:19, 182MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 6.36G/9.98G [00:54<00:20, 178MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 6.39G/9.98G [00:54<00:19, 186MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 6.41G/9.98G [00:54<00:18, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.44G/9.98G [00:55<00:17, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.46G/9.98G [00:55<00:17, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.48G/9.98G [00:55<00:19, 183MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.50G/9.98G [00:55<00:19, 182MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.52G/9.98G [00:55<00:19, 181MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.54G/9.98G [00:55<00:18, 182MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.56G/9.98G [00:55<00:19, 178MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.59G/9.98G [00:56<01:01, 54.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.61G/9.98G [00:56<00:48, 70.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.64G/9.98G [00:57<00:34, 95.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.67G/9.98G [00:57<00:29, 111MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.69G/9.98G [00:57<00:28, 117MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.72G/9.98G [00:57<00:23, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 6.75G/9.98G [00:57<00:20, 157MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 6.77G/9.98G [00:57<00:20, 154MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 6.79G/9.98G [00:57<00:19, 165MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 6.82G/9.98G [00:58<00:18, 173MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.85G/9.98G [00:58<00:16, 186MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.88G/9.98G [00:58<00:15, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.90G/9.98G [00:58<00:15, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.93G/9.98G [00:58<00:14, 203MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 6.96G/9.98G [00:58<00:21, 143MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 6.98G/9.98G [00:59<00:19, 153MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 7.00G/9.98G [00:59<00:18, 160MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 7.03G/9.98G [00:59<00:17, 170MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.06G/9.98G [00:59<00:15, 186MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.09G/9.98G [00:59<00:14, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.12G/9.98G [00:59<00:14, 203MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.14G/9.98G [00:59<00:14, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.16G/9.98G [00:59<00:14, 193MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.18G/9.98G [01:00<00:14, 195MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.20G/9.98G [01:00<00:14, 197MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.22G/9.98G [01:00<00:13, 200MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.25G/9.98G [01:01<01:10, 38.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.28G/9.98G [01:02<00:47, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.30G/9.98G [01:02<00:40, 65.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.32G/9.98G [01:02<00:34, 76.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.35G/9.98G [01:02<00:26, 101MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.38G/9.98G [01:02<00:21, 122MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.40G/9.98G [01:02<00:20, 125MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.42G/9.98G [01:02<00:18, 137MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.46G/9.98G [01:03<00:16, 155MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.48G/9.98G [01:03<00:15, 166MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.51G/9.98G [01:03<00:13, 183MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.53G/9.98G [01:03<00:13, 188MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.56G/9.98G [01:03<00:12, 197MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.59G/9.98G [01:03<00:11, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.62G/9.98G [01:03<00:11, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.65G/9.98G [01:04<00:11, 200MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.68G/9.98G [01:04<00:11, 197MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.70G/9.98G [01:04<00:11, 200MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.72G/9.98G [01:04<00:11, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.74G/9.98G [01:04<00:11, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.76G/9.98G [01:06<01:20, 27.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.78G/9.98G [01:06<01:00, 36.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.80G/9.98G [01:07<00:46, 47.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.82G/9.98G [01:07<00:37, 57.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.84G/9.98G [01:07<00:29, 72.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.86G/9.98G [01:07<00:24, 86.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.89G/9.98G [01:07<00:20, 103MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.91G/9.98G [01:07<00:18, 113MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.93G/9.98G [01:07<00:16, 124MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 7.95G/9.98G [01:08<00:15, 134MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 7.97G/9.98G [01:08<00:13, 148MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 7.99G/9.98G [01:08<00:12, 161MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 8.02G/9.98G [01:08<00:11, 176MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.05G/9.98G [01:08<00:10, 189MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.08G/9.98G [01:08<00:09, 195MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.11G/9.98G [01:08<00:09, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.13G/9.98G [01:08<00:10, 183MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.15G/9.98G [01:09<00:10, 181MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.17G/9.98G [01:09<00:10, 181MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.19G/9.98G [01:09<00:10, 177MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.21G/9.98G [01:11<01:08, 25.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.24G/9.98G [01:11<00:44, 38.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.26G/9.98G [01:12<00:35, 48.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.28G/9.98G [01:12<00:29, 58.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.30G/9.98G [01:12<00:22, 72.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.33G/9.98G [01:12<00:18, 89.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 8.36G/9.98G [01:12<00:14, 111MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 8.38G/9.98G [01:12<00:13, 121MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 8.40G/9.98G [01:13<00:15, 99.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.43G/9.98G [01:13<00:12, 126MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.46G/9.98G [01:13<00:10, 147MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.49G/9.98G [01:13<00:09, 163MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.51G/9.98G [01:13<00:08, 170MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 8.54G/9.98G [01:13<00:08, 177MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 8.56G/9.98G [01:13<00:07, 182MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 8.58G/9.98G [01:13<00:07, 186MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 8.60G/9.98G [01:14<00:15, 88.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 8.62G/9.98G [01:16<00:54, 24.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.65G/9.98G [01:17<00:35, 37.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.67G/9.98G [01:17<00:28, 45.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.69G/9.98G [01:17<00:22, 56.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.72G/9.98G [01:17<00:16, 77.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.76G/9.98G [01:17<00:12, 100MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.78G/9.98G [01:17<00:11, 109MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.81G/9.98G [01:17<00:08, 130MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 8.84G/9.98G [01:18<00:07, 150MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 8.86G/9.98G [01:18<00:06, 160MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 8.89G/9.98G [01:18<00:06, 178MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 8.92G/9.98G [01:18<00:05, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 8.95G/9.98G [01:18<00:05, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 8.99G/9.98G [01:18<00:05, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 9.01G/9.98G [01:18<00:04, 195MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 9.03G/9.98G [01:19<00:04, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 9.05G/9.98G [01:19<00:04, 195MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 9.07G/9.98G [01:19<00:04, 193MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 9.09G/9.98G [01:21<00:34, 25.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 9.11G/9.98G [01:21<00:25, 34.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.13G/9.98G [01:22<00:19, 44.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.15G/9.98G [01:22<00:15, 54.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.18G/9.98G [01:22<00:11, 69.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.20G/9.98G [01:22<00:09, 86.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.22G/9.98G [01:22<00:07, 103MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.24G/9.98G [01:22<00:06, 118MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.26G/9.98G [01:22<00:05, 127MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.28G/9.98G [01:22<00:05, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.30G/9.98G [01:23<00:04, 149MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.32G/9.98G [01:23<00:04, 159MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.34G/9.98G [01:23<00:03, 172MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.36G/9.98G [01:23<00:03, 179MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.38G/9.98G [01:23<00:03, 183MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.41G/9.98G [01:23<00:03, 184MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.43G/9.98G [01:23<00:03, 182MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.45G/9.98G [01:23<00:02, 182MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.47G/9.98G [01:23<00:02, 177MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.49G/9.98G [01:26<00:21, 22.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.51G/9.98G [01:26<00:15, 30.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.54G/9.98G [01:27<00:09, 45.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.56G/9.98G [01:27<00:07, 55.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.58G/9.98G [01:27<00:05, 67.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.62G/9.98G [01:27<00:03, 91.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.65G/9.98G [01:27<00:02, 113MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.67G/9.98G [01:27<00:02, 123MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.70G/9.98G [01:27<00:01, 144MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.72G/9.98G [01:28<00:01, 156MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.75G/9.98G [01:28<00:01, 172MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.77G/9.98G [01:28<00:01, 180MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.80G/9.98G [01:28<00:00, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.84G/9.98G [01:28<00:00, 200MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.87G/9.98G [01:28<00:00, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.90G/9.98G [01:28<00:00, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.92G/9.98G [01:29<00:00, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 9.94G/9.98G [01:29<00:00, 193MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 9.98G/9.98G [01:29<00:00, 112MB/s]\n",
            "Downloading shards:  50% 1/2 [01:29<01:29, 89.50s/it]\n",
            "model-00002-of-00002.safetensors:   0% 0.00/3.50G [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   1% 31.5M/3.50G [00:00<00:15, 230MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   2% 62.9M/3.50G [00:00<00:15, 220MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   3% 94.4M/3.50G [00:00<00:15, 220MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   4% 126M/3.50G [00:00<00:16, 207MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:   4% 147M/3.50G [00:00<00:16, 198MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   5% 168M/3.50G [00:00<00:16, 200MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   6% 199M/3.50G [00:00<00:16, 202MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   6% 220M/3.50G [00:01<00:37, 87.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   7% 241M/3.50G [00:02<01:03, 51.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   8% 273M/3.50G [00:02<00:44, 72.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   8% 294M/3.50G [00:02<00:37, 86.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   9% 315M/3.50G [00:02<00:35, 90.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  10% 336M/3.50G [00:03<00:30, 104MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  10% 357M/3.50G [00:03<00:25, 121MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  11% 388M/3.50G [00:03<00:21, 144MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  12% 409M/3.50G [00:03<00:21, 144MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  13% 440M/3.50G [00:03<00:18, 162MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  13% 461M/3.50G [00:03<00:17, 170MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  14% 493M/3.50G [00:03<00:16, 182MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  15% 524M/3.50G [00:03<00:15, 194MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  16% 556M/3.50G [00:04<00:14, 199MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  17% 587M/3.50G [00:04<00:14, 205MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  18% 619M/3.50G [00:04<00:13, 211MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  19% 650M/3.50G [00:04<00:14, 197MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  19% 671M/3.50G [00:04<00:14, 200MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  20% 703M/3.50G [00:04<00:13, 203MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  21% 734M/3.50G [00:04<00:13, 210MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  22% 765M/3.50G [00:05<00:12, 210MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  23% 797M/3.50G [00:05<00:13, 202MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  23% 818M/3.50G [00:05<00:13, 199MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  24% 839M/3.50G [00:05<00:13, 197MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  25% 870M/3.50G [00:05<00:13, 202MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  25% 891M/3.50G [00:07<01:05, 40.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  26% 912M/3.50G [00:07<00:51, 50.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  27% 933M/3.50G [00:07<00:41, 62.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  27% 954M/3.50G [00:07<00:32, 77.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  28% 986M/3.50G [00:07<00:24, 102MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  29% 1.01G/3.50G [00:08<00:21, 118MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  29% 1.03G/3.50G [00:08<00:19, 128MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  30% 1.05G/3.50G [00:08<00:17, 144MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  31% 1.07G/3.50G [00:08<00:15, 156MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  31% 1.09G/3.50G [00:08<00:14, 162MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  32% 1.11G/3.50G [00:08<00:15, 159MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  32% 1.13G/3.50G [00:08<00:14, 162MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  33% 1.15G/3.50G [00:08<00:13, 171MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  34% 1.17G/3.50G [00:08<00:12, 181MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  34% 1.20G/3.50G [00:09<00:12, 187MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  35% 1.22G/3.50G [00:09<00:12, 189MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  35% 1.24G/3.50G [00:09<00:12, 188MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  36% 1.27G/3.50G [00:09<00:11, 194MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  37% 1.29G/3.50G [00:09<00:17, 128MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  37% 1.31G/3.50G [00:09<00:15, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  38% 1.33G/3.50G [00:09<00:14, 152MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  39% 1.35G/3.50G [00:10<00:13, 160MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  39% 1.37G/3.50G [00:12<01:17, 27.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  40% 1.41G/3.50G [00:12<00:50, 41.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  41% 1.44G/3.50G [00:12<00:35, 58.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  42% 1.46G/3.50G [00:12<00:28, 70.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  42% 1.48G/3.50G [00:12<00:25, 79.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  43% 1.50G/3.50G [00:13<00:21, 95.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  44% 1.53G/3.50G [00:13<00:16, 120MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  44% 1.55G/3.50G [00:13<00:14, 132MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  45% 1.57G/3.50G [00:13<00:13, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  46% 1.59G/3.50G [00:13<00:12, 152MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  46% 1.61G/3.50G [00:13<00:11, 162MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  47% 1.65G/3.50G [00:13<00:10, 174MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  48% 1.68G/3.50G [00:13<00:09, 188MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  49% 1.71G/3.50G [00:14<00:09, 196MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  49% 1.73G/3.50G [00:14<00:09, 194MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  50% 1.75G/3.50G [00:14<00:08, 196MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  51% 1.77G/3.50G [00:14<00:08, 197MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  51% 1.79G/3.50G [00:14<00:08, 197MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  52% 1.81G/3.50G [00:14<00:08, 196MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  52% 1.84G/3.50G [00:17<01:09, 24.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  53% 1.87G/3.50G [00:17<00:44, 36.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  54% 1.89G/3.50G [00:17<00:34, 46.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  55% 1.91G/3.50G [00:17<00:28, 55.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  55% 1.93G/3.50G [00:17<00:22, 68.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  56% 1.96G/3.50G [00:18<00:16, 92.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  57% 1.98G/3.50G [00:18<00:14, 108MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  57% 2.00G/3.50G [00:18<00:12, 121MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  58% 2.02G/3.50G [00:18<00:10, 135MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  58% 2.04G/3.50G [00:18<00:09, 146MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  59% 2.07G/3.50G [00:18<00:09, 159MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  60% 2.09G/3.50G [00:18<00:08, 167MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  60% 2.11G/3.50G [00:18<00:07, 177MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  61% 2.14G/3.50G [00:18<00:07, 192MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  62% 2.16G/3.50G [00:19<00:06, 193MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  63% 2.19G/3.50G [00:19<00:06, 200MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  64% 2.22G/3.50G [00:19<00:06, 207MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  64% 2.25G/3.50G [00:19<00:05, 209MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  65% 2.29G/3.50G [00:19<00:06, 197MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  66% 2.31G/3.50G [00:19<00:06, 199MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  67% 2.34G/3.50G [00:19<00:05, 203MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  67% 2.36G/3.50G [00:20<00:05, 201MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  68% 2.38G/3.50G [00:22<00:35, 31.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  69% 2.40G/3.50G [00:22<00:27, 39.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  69% 2.42G/3.50G [00:22<00:21, 50.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  70% 2.44G/3.50G [00:22<00:16, 64.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  70% 2.46G/3.50G [00:22<00:13, 79.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  71% 2.49G/3.50G [00:22<00:10, 93.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  72% 2.51G/3.50G [00:23<00:11, 83.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  72% 2.53G/3.50G [00:23<00:09, 98.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  73% 2.55G/3.50G [00:23<00:08, 109MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  73% 2.57G/3.50G [00:23<00:07, 120MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  74% 2.59G/3.50G [00:23<00:06, 132MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  75% 2.61G/3.50G [00:23<00:06, 142MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  75% 2.63G/3.50G [00:24<00:05, 149MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  76% 2.65G/3.50G [00:24<00:05, 154MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  76% 2.67G/3.50G [00:24<00:05, 163MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  77% 2.71G/3.50G [00:24<00:04, 179MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  78% 2.73G/3.50G [00:24<00:04, 186MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  78% 2.75G/3.50G [00:24<00:04, 183MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  79% 2.77G/3.50G [00:24<00:04, 179MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  80% 2.79G/3.50G [00:24<00:03, 179MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  80% 2.81G/3.50G [00:25<00:03, 186MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  81% 2.83G/3.50G [00:25<00:03, 181MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  81% 2.85G/3.50G [00:25<00:03, 182MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  82% 2.87G/3.50G [00:27<00:21, 28.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  83% 2.90G/3.50G [00:27<00:13, 43.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  84% 2.93G/3.50G [00:27<00:10, 54.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  84% 2.95G/3.50G [00:27<00:08, 64.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  85% 2.97G/3.50G [00:28<00:06, 77.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  86% 3.00G/3.50G [00:28<00:04, 103MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  86% 3.02G/3.50G [00:28<00:04, 118MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  87% 3.04G/3.50G [00:28<00:03, 124MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  87% 3.06G/3.50G [00:28<00:03, 137MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  88% 3.08G/3.50G [00:28<00:02, 148MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  89% 3.10G/3.50G [00:28<00:02, 161MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  89% 3.12G/3.50G [00:28<00:02, 170MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  90% 3.15G/3.50G [00:28<00:01, 178MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  91% 3.18G/3.50G [00:29<00:01, 191MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  92% 3.21G/3.50G [00:29<00:01, 200MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  92% 3.23G/3.50G [00:29<00:01, 196MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  93% 3.25G/3.50G [00:29<00:01, 194MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  93% 3.27G/3.50G [00:29<00:01, 196MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  94% 3.29G/3.50G [00:29<00:01, 195MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  95% 3.31G/3.50G [00:29<00:00, 195MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  95% 3.33G/3.50G [00:29<00:00, 196MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  96% 3.37G/3.50G [00:30<00:00, 206MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  97% 3.40G/3.50G [00:30<00:00, 212MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  98% 3.43G/3.50G [00:30<00:00, 197MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  99% 3.45G/3.50G [00:30<00:00, 185MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  99% 3.47G/3.50G [00:30<00:00, 180MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 3.50G/3.50G [00:30<00:00, 114MB/s]\n",
            "Downloading shards: 100% 2/2 [02:00<00:00, 60.21s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [01:12<00:00, 36.46s/it]\n",
            "generation_config.json: 100% 188/188 [00:00<00:00, 1.12MB/s]\n",
            "tokenizer_config.json: 100% 776/776 [00:00<00:00, 4.92MB/s]\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 341MB/s]\n",
            "tokenizer.json: 100% 1.84M/1.84M [00:00<00:00, 16.8MB/s]\n",
            "special_tokens_map.json: 100% 414/414 [00:00<00:00, 2.62MB/s]\n",
            "Lenght of train: 1206\n",
            "Lenght of valid: 172\n",
            "Train indices: [\n",
            "    [\n",
            "        200,\n",
            "        584\n",
            "    ],\n",
            "    [\n",
            "        638,\n",
            "        307\n",
            "    ],\n",
            "    [\n",
            "        628,\n",
            "        607\n",
            "    ],\n",
            "    [\n",
            "        200,\n",
            "        584,\n",
            "        807,\n",
            "        895\n",
            "    ],\n",
            "    [\n",
            "        627,\n",
            "        606,\n",
            "        245,\n",
            "        458\n",
            "    ],\n",
            "    [\n",
            "        467,\n",
            "        607,\n",
            "        490,\n",
            "        189\n",
            "    ],\n",
            "    [\n",
            "        200,\n",
            "        584,\n",
            "        807,\n",
            "        895,\n",
            "        336,\n",
            "        314\n",
            "    ],\n",
            "    [\n",
            "        640,\n",
            "        687,\n",
            "        1039,\n",
            "        190,\n",
            "        1089,\n",
            "        284\n",
            "    ],\n",
            "    [\n",
            "        49,\n",
            "        1152,\n",
            "        309,\n",
            "        1026,\n",
            "        869,\n",
            "        826\n",
            "    ],\n",
            "    [\n",
            "        200,\n",
            "        584,\n",
            "        807,\n",
            "        895,\n",
            "        336,\n",
            "        314,\n",
            "        311,\n",
            "        198\n",
            "    ],\n",
            "    [\n",
            "        469,\n",
            "        608,\n",
            "        492,\n",
            "        189,\n",
            "        1026,\n",
            "        943,\n",
            "        204,\n",
            "        1152\n",
            "    ],\n",
            "    [\n",
            "        49,\n",
            "        389,\n",
            "        308,\n",
            "        1024,\n",
            "        810,\n",
            "        1027,\n",
            "        316,\n",
            "        397\n",
            "    ],\n",
            "    [\n",
            "        200,\n",
            "        584,\n",
            "        807,\n",
            "        895,\n",
            "        336,\n",
            "        314,\n",
            "        311,\n",
            "        198,\n",
            "        1029,\n",
            "        189,\n",
            "        190,\n",
            "        49\n",
            "    ],\n",
            "    [\n",
            "        50,\n",
            "        1152,\n",
            "        312,\n",
            "        1027,\n",
            "        870,\n",
            "        827,\n",
            "        773,\n",
            "        915,\n",
            "        670,\n",
            "        608,\n",
            "        82,\n",
            "        887\n",
            "    ],\n",
            "    [\n",
            "        941,\n",
            "        305,\n",
            "        948,\n",
            "        333,\n",
            "        246,\n",
            "        145,\n",
            "        689,\n",
            "        1160,\n",
            "        606,\n",
            "        561,\n",
            "        1058,\n",
            "        564\n",
            "    ]\n",
            "]\n",
            "\n",
            "Number of parameter combinations: 15 \n",
            "\n",
            "[{'few_shot_sample_indices': [200, 584]}, {'few_shot_sample_indices': [638, 307]}, {'few_shot_sample_indices': [628, 607]}, {'few_shot_sample_indices': [200, 584, 807, 895]}, {'few_shot_sample_indices': [627, 606, 245, 458]}, {'few_shot_sample_indices': [467, 607, 490, 189]}, {'few_shot_sample_indices': [200, 584, 807, 895, 336, 314]}, {'few_shot_sample_indices': [640, 687, 1039, 190, 1089, 284]}, {'few_shot_sample_indices': [49, 1152, 309, 1026, 869, 826]}, {'few_shot_sample_indices': [200, 584, 807, 895, 336, 314, 311, 198]}, {'few_shot_sample_indices': [469, 608, 492, 189, 1026, 943, 204, 1152]}, {'few_shot_sample_indices': [49, 389, 308, 1024, 810, 1027, 316, 397]}, {'few_shot_sample_indices': [200, 584, 807, 895, 336, 314, 311, 198, 1029, 189, 190, 49]}, {'few_shot_sample_indices': [50, 1152, 312, 1027, 870, 827, 773, 915, 670, 608, 82, 887]}, {'few_shot_sample_indices': [941, 305, 948, 333, 246, 145, 689, 1160, 606, 561, 1058, 564]}]\n",
            "\n",
            "Current few-shot sample: 1 / 15\n",
            "[==================================================] 100.0% 958.5/958.4MB downloaded\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5140352502118709\n",
            "llama2-7b - (fasttext) Standard deviation:  0.10923661727044902\n",
            "\n",
            "Current few-shot sample: 2 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.47543060545657956\n",
            "llama2-7b - (fasttext) Standard deviation:  0.10187492289418106\n",
            "\n",
            "Current few-shot sample: 3 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5223568426661713\n",
            "llama2-7b - (fasttext) Standard deviation:  0.15414252499001785\n",
            "\n",
            "Current few-shot sample: 4 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.529980905354023\n",
            "llama2-7b - (fasttext) Standard deviation:  0.11142077613731398\n",
            "\n",
            "Current few-shot sample: 5 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5147465006556622\n",
            "llama2-7b - (fasttext) Standard deviation:  0.11189190448662216\n",
            "\n",
            "Current few-shot sample: 6 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5159348575181739\n",
            "llama2-7b - (fasttext) Standard deviation:  0.13286476638381878\n",
            "\n",
            "Current few-shot sample: 7 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5235802200297976\n",
            "llama2-7b - (fasttext) Standard deviation:  0.11289589380566345\n",
            "\n",
            "Current few-shot sample: 8 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5138558460356191\n",
            "llama2-7b - (fasttext) Standard deviation:  0.11212561487302462\n",
            "\n",
            "Current few-shot sample: 9 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.4664232698810655\n",
            "llama2-7b - (fasttext) Standard deviation:  0.1229769956759881\n",
            "\n",
            "Current few-shot sample: 10 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5183119004548982\n",
            "llama2-7b - (fasttext) Standard deviation:  0.11202285655137673\n",
            "\n",
            "Current few-shot sample: 11 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5188587626745534\n",
            "llama2-7b - (fasttext) Standard deviation:  0.13550657876978292\n",
            "\n",
            "Current few-shot sample: 12 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.49988874342552453\n",
            "llama2-7b - (fasttext) Standard deviation:  0.12141223973459862\n",
            "\n",
            "Current few-shot sample: 13 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5161065374349438\n",
            "llama2-7b - (fasttext) Standard deviation:  0.11588753315644104\n",
            "\n",
            "Current few-shot sample: 14 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5370480205084003\n",
            "llama2-7b - (fasttext) Standard deviation:  0.16250555420151477\n",
            "\n",
            "Current few-shot sample: 15 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5495653421033261\n",
            "llama2-7b - (fasttext) Standard deviation:  0.12337086516522291\n",
            "Validation results: [\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.5140352502118709,\n",
            "        \"std_em\": 0.10923661727044902,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            200,\n",
            "            584\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.47543060545657956,\n",
            "        \"std_em\": 0.10187492289418106,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            638,\n",
            "            307\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.5223568426661713,\n",
            "        \"std_em\": 0.15414252499001785,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            628,\n",
            "            607\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.529980905354023,\n",
            "        \"std_em\": 0.11142077613731398,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            200,\n",
            "            584,\n",
            "            807,\n",
            "            895\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.5147465006556622,\n",
            "        \"std_em\": 0.11189190448662216,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            627,\n",
            "            606,\n",
            "            245,\n",
            "            458\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.5159348575181739,\n",
            "        \"std_em\": 0.13286476638381878,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            467,\n",
            "            607,\n",
            "            490,\n",
            "            189\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.5235802200297976,\n",
            "        \"std_em\": 0.11289589380566345,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            200,\n",
            "            584,\n",
            "            807,\n",
            "            895,\n",
            "            336,\n",
            "            314\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.5138558460356191,\n",
            "        \"std_em\": 0.11212561487302462,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            640,\n",
            "            687,\n",
            "            1039,\n",
            "            190,\n",
            "            1089,\n",
            "            284\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.4664232698810655,\n",
            "        \"std_em\": 0.1229769956759881,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            49,\n",
            "            1152,\n",
            "            309,\n",
            "            1026,\n",
            "            869,\n",
            "            826\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.5183119004548982,\n",
            "        \"std_em\": 0.11202285655137673,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            200,\n",
            "            584,\n",
            "            807,\n",
            "            895,\n",
            "            336,\n",
            "            314,\n",
            "            311,\n",
            "            198\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.5188587626745534,\n",
            "        \"std_em\": 0.13550657876978292,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            469,\n",
            "            608,\n",
            "            492,\n",
            "            189,\n",
            "            1026,\n",
            "            943,\n",
            "            204,\n",
            "            1152\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.49988874342552453,\n",
            "        \"std_em\": 0.12141223973459862,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            49,\n",
            "            389,\n",
            "            308,\n",
            "            1024,\n",
            "            810,\n",
            "            1027,\n",
            "            316,\n",
            "            397\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.5161065374349438,\n",
            "        \"std_em\": 0.11588753315644104,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            200,\n",
            "            584,\n",
            "            807,\n",
            "            895,\n",
            "            336,\n",
            "            314,\n",
            "            311,\n",
            "            198,\n",
            "            1029,\n",
            "            189,\n",
            "            190,\n",
            "            49\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.5370480205084003,\n",
            "        \"std_em\": 0.16250555420151477,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            50,\n",
            "            1152,\n",
            "            312,\n",
            "            1027,\n",
            "            870,\n",
            "            827,\n",
            "            773,\n",
            "            915,\n",
            "            670,\n",
            "            608,\n",
            "            82,\n",
            "            887\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.5495653421033261,\n",
            "        \"std_em\": 0.12337086516522291,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            941,\n",
            "            305,\n",
            "            948,\n",
            "            333,\n",
            "            246,\n",
            "            145,\n",
            "            689,\n",
            "            1160,\n",
            "            606,\n",
            "            561,\n",
            "            1058,\n",
            "            564\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    }\n",
            "]\n",
            "\n",
            "Lenght of test: 345\n",
            "Getting completions...\n",
            "Evaluating test set performance...\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5463024220604827\n",
            "llama2-7b - (fasttext) Standard deviation:  0.13008070040735425\n",
            "Test results: {\n",
            "    \"model\": \"llama2-7b\",\n",
            "    \"acc\": 0.0,\n",
            "    \"mean_em\": 0.5463024220604827,\n",
            "    \"std_em\": 0.13008070040735425,\n",
            "    \"few_shot_sample_indices\": [\n",
            "        941,\n",
            "        305,\n",
            "        948,\n",
            "        333,\n",
            "        246,\n",
            "        145,\n",
            "        689,\n",
            "        1160,\n",
            "        606,\n",
            "        561,\n",
            "        1058,\n",
            "        564\n",
            "    ],\n",
            "    \"few_shot_samples\": 12,\n",
            "    \"temperature\": 0.0,\n",
            "    \"eval_split\": \"test\",\n",
            "    \"dataset_name\": \"lcc_en_subset\",\n",
            "    \"fine_tuning\": false\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"$WORKDIR\" python -m src.main --llm llama2-7b --temperature 0 --dataset lcc_en_subset --task source_domain_prediction --seed 1 --evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlxAkDh4qvla"
      },
      "source": [
        "## LCC (EN) - Target domain prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiuBKBnFZX9p",
        "outputId": "8fbde6fa-f3c7-4fa9-b194-9e72c871e0d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-11-28 20:13:49.371046: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-28 20:13:49.371111: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-28 20:13:49.371150: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-28 20:13:51.536956: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "User is already logged in.\n",
            "\n",
            "llm: llama2-7b\n",
            "fine_tuned_model_path: None\n",
            "dataset: lcc_en_subset\n",
            "task: target_domain_prediction\n",
            "temperature: 0.0\n",
            "seed: 1\n",
            "evaluate: True\n",
            "fine_tuning: False\n",
            "\n",
            "\n",
            "Loading checkpoint shards: 100% 2/2 [01:13<00:00, 36.91s/it]\n",
            "Lenght of train: 1206\n",
            "Lenght of valid: 172\n",
            "Train indices: [\n",
            "    [\n",
            "        200,\n",
            "        584\n",
            "    ],\n",
            "    [\n",
            "        638,\n",
            "        307\n",
            "    ],\n",
            "    [\n",
            "        628,\n",
            "        607\n",
            "    ],\n",
            "    [\n",
            "        200,\n",
            "        584,\n",
            "        807,\n",
            "        895\n",
            "    ],\n",
            "    [\n",
            "        627,\n",
            "        606,\n",
            "        245,\n",
            "        458\n",
            "    ],\n",
            "    [\n",
            "        467,\n",
            "        607,\n",
            "        490,\n",
            "        189\n",
            "    ],\n",
            "    [\n",
            "        200,\n",
            "        584,\n",
            "        807,\n",
            "        895,\n",
            "        336,\n",
            "        314\n",
            "    ],\n",
            "    [\n",
            "        640,\n",
            "        687,\n",
            "        1039,\n",
            "        190,\n",
            "        1089,\n",
            "        284\n",
            "    ],\n",
            "    [\n",
            "        49,\n",
            "        1152,\n",
            "        309,\n",
            "        1026,\n",
            "        869,\n",
            "        826\n",
            "    ],\n",
            "    [\n",
            "        200,\n",
            "        584,\n",
            "        807,\n",
            "        895,\n",
            "        336,\n",
            "        314,\n",
            "        311,\n",
            "        198\n",
            "    ],\n",
            "    [\n",
            "        469,\n",
            "        608,\n",
            "        492,\n",
            "        189,\n",
            "        1026,\n",
            "        943,\n",
            "        204,\n",
            "        1152\n",
            "    ],\n",
            "    [\n",
            "        49,\n",
            "        389,\n",
            "        308,\n",
            "        1024,\n",
            "        810,\n",
            "        1027,\n",
            "        316,\n",
            "        397\n",
            "    ],\n",
            "    [\n",
            "        200,\n",
            "        584,\n",
            "        807,\n",
            "        895,\n",
            "        336,\n",
            "        314,\n",
            "        311,\n",
            "        198,\n",
            "        1029,\n",
            "        189,\n",
            "        190,\n",
            "        49\n",
            "    ],\n",
            "    [\n",
            "        50,\n",
            "        1152,\n",
            "        312,\n",
            "        1027,\n",
            "        870,\n",
            "        827,\n",
            "        773,\n",
            "        915,\n",
            "        670,\n",
            "        608,\n",
            "        82,\n",
            "        887\n",
            "    ],\n",
            "    [\n",
            "        941,\n",
            "        305,\n",
            "        948,\n",
            "        333,\n",
            "        246,\n",
            "        145,\n",
            "        689,\n",
            "        1160,\n",
            "        606,\n",
            "        561,\n",
            "        1058,\n",
            "        564\n",
            "    ]\n",
            "]\n",
            "\n",
            "Number of parameter combinations: 15 \n",
            "\n",
            "[{'few_shot_sample_indices': [200, 584]}, {'few_shot_sample_indices': [638, 307]}, {'few_shot_sample_indices': [628, 607]}, {'few_shot_sample_indices': [200, 584, 807, 895]}, {'few_shot_sample_indices': [627, 606, 245, 458]}, {'few_shot_sample_indices': [467, 607, 490, 189]}, {'few_shot_sample_indices': [200, 584, 807, 895, 336, 314]}, {'few_shot_sample_indices': [640, 687, 1039, 190, 1089, 284]}, {'few_shot_sample_indices': [49, 1152, 309, 1026, 869, 826]}, {'few_shot_sample_indices': [200, 584, 807, 895, 336, 314, 311, 198]}, {'few_shot_sample_indices': [469, 608, 492, 189, 1026, 943, 204, 1152]}, {'few_shot_sample_indices': [49, 389, 308, 1024, 810, 1027, 316, 397]}, {'few_shot_sample_indices': [200, 584, 807, 895, 336, 314, 311, 198, 1029, 189, 190, 49]}, {'few_shot_sample_indices': [50, 1152, 312, 1027, 870, 827, 773, 915, 670, 608, 82, 887]}, {'few_shot_sample_indices': [941, 305, 948, 333, 246, 145, 689, 1160, 606, 561, 1058, 564]}]\n",
            "\n",
            "Current few-shot sample: 1 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5884295658663262\n",
            "llama2-7b - (fasttext) Standard deviation:  0.14290013686551736\n",
            "\n",
            "Current few-shot sample: 2 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5810071576473325\n",
            "llama2-7b - (fasttext) Standard deviation:  0.15831662774885444\n",
            "\n",
            "Current few-shot sample: 3 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.6277175334303878\n",
            "llama2-7b - (fasttext) Standard deviation:  0.12745857151974652\n",
            "\n",
            "Current few-shot sample: 4 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.609557450684004\n",
            "llama2-7b - (fasttext) Standard deviation:  0.13704056836851383\n",
            "\n",
            "Current few-shot sample: 5 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.6268073187837767\n",
            "llama2-7b - (fasttext) Standard deviation:  0.1404116799643144\n",
            "\n",
            "Current few-shot sample: 6 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.6375243367497311\n",
            "llama2-7b - (fasttext) Standard deviation:  0.11907954358079333\n",
            "\n",
            "Current few-shot sample: 7 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.6259183369057123\n",
            "llama2-7b - (fasttext) Standard deviation:  0.12801220351218567\n",
            "\n",
            "Current few-shot sample: 8 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.6160595229891843\n",
            "llama2-7b - (fasttext) Standard deviation:  0.13881055660020408\n",
            "\n",
            "Current few-shot sample: 9 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.6468204741561135\n",
            "llama2-7b - (fasttext) Standard deviation:  0.13038495987077958\n",
            "\n",
            "Current few-shot sample: 10 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.634838324646617\n",
            "llama2-7b - (fasttext) Standard deviation:  0.12377150448746038\n",
            "\n",
            "Current few-shot sample: 11 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.641491116652655\n",
            "llama2-7b - (fasttext) Standard deviation:  0.12247964504583483\n",
            "\n",
            "Current few-shot sample: 12 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.637186158361823\n",
            "llama2-7b - (fasttext) Standard deviation:  0.12539079201118722\n",
            "\n",
            "Current few-shot sample: 13 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.639964068871598\n",
            "llama2-7b - (fasttext) Standard deviation:  0.12370170313993459\n",
            "\n",
            "Current few-shot sample: 14 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.6624771954361782\n",
            "llama2-7b - (fasttext) Standard deviation:  0.09696946031977761\n",
            "\n",
            "Current few-shot sample: 15 / 15\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.670536701242591\n",
            "llama2-7b - (fasttext) Standard deviation:  0.10803595253114573\n",
            "Validation results: [\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.5884295658663262,\n",
            "        \"std_em\": 0.14290013686551736,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            200,\n",
            "            584\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.5810071576473325,\n",
            "        \"std_em\": 0.15831662774885444,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            638,\n",
            "            307\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.6277175334303878,\n",
            "        \"std_em\": 0.12745857151974652,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            628,\n",
            "            607\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.609557450684004,\n",
            "        \"std_em\": 0.13704056836851383,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            200,\n",
            "            584,\n",
            "            807,\n",
            "            895\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.6268073187837767,\n",
            "        \"std_em\": 0.1404116799643144,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            627,\n",
            "            606,\n",
            "            245,\n",
            "            458\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.6375243367497311,\n",
            "        \"std_em\": 0.11907954358079333,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            467,\n",
            "            607,\n",
            "            490,\n",
            "            189\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.6259183369057123,\n",
            "        \"std_em\": 0.12801220351218567,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            200,\n",
            "            584,\n",
            "            807,\n",
            "            895,\n",
            "            336,\n",
            "            314\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.6160595229891843,\n",
            "        \"std_em\": 0.13881055660020408,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            640,\n",
            "            687,\n",
            "            1039,\n",
            "            190,\n",
            "            1089,\n",
            "            284\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.6468204741561135,\n",
            "        \"std_em\": 0.13038495987077958,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            49,\n",
            "            1152,\n",
            "            309,\n",
            "            1026,\n",
            "            869,\n",
            "            826\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.634838324646617,\n",
            "        \"std_em\": 0.12377150448746038,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            200,\n",
            "            584,\n",
            "            807,\n",
            "            895,\n",
            "            336,\n",
            "            314,\n",
            "            311,\n",
            "            198\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.641491116652655,\n",
            "        \"std_em\": 0.12247964504583483,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            469,\n",
            "            608,\n",
            "            492,\n",
            "            189,\n",
            "            1026,\n",
            "            943,\n",
            "            204,\n",
            "            1152\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.637186158361823,\n",
            "        \"std_em\": 0.12539079201118722,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            49,\n",
            "            389,\n",
            "            308,\n",
            "            1024,\n",
            "            810,\n",
            "            1027,\n",
            "            316,\n",
            "            397\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.639964068871598,\n",
            "        \"std_em\": 0.12370170313993459,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            200,\n",
            "            584,\n",
            "            807,\n",
            "            895,\n",
            "            336,\n",
            "            314,\n",
            "            311,\n",
            "            198,\n",
            "            1029,\n",
            "            189,\n",
            "            190,\n",
            "            49\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.6624771954361782,\n",
            "        \"std_em\": 0.09696946031977761,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            50,\n",
            "            1152,\n",
            "            312,\n",
            "            1027,\n",
            "            870,\n",
            "            827,\n",
            "            773,\n",
            "            915,\n",
            "            670,\n",
            "            608,\n",
            "            82,\n",
            "            887\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.670536701242591,\n",
            "        \"std_em\": 0.10803595253114573,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            941,\n",
            "            305,\n",
            "            948,\n",
            "            333,\n",
            "            246,\n",
            "            145,\n",
            "            689,\n",
            "            1160,\n",
            "            606,\n",
            "            561,\n",
            "            1058,\n",
            "            564\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    }\n",
            "]\n",
            "\n",
            "Lenght of test: 345\n",
            "Getting completions...\n",
            "Evaluating test set performance...\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.6438123452058737\n",
            "llama2-7b - (fasttext) Standard deviation:  0.13144609862446044\n",
            "Test results: {\n",
            "    \"model\": \"llama2-7b\",\n",
            "    \"acc\": 0.0,\n",
            "    \"mean_em\": 0.6438123452058737,\n",
            "    \"std_em\": 0.13144609862446044,\n",
            "    \"few_shot_sample_indices\": [\n",
            "        941,\n",
            "        305,\n",
            "        948,\n",
            "        333,\n",
            "        246,\n",
            "        145,\n",
            "        689,\n",
            "        1160,\n",
            "        606,\n",
            "        561,\n",
            "        1058,\n",
            "        564\n",
            "    ],\n",
            "    \"few_shot_samples\": 12,\n",
            "    \"temperature\": 0.0,\n",
            "    \"eval_split\": \"test\",\n",
            "    \"dataset_name\": \"lcc_en_subset\",\n",
            "    \"fine_tuning\": false\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"$WORKDIR\" python -m src.main --llm llama2-7b --temperature 0 --dataset lcc_en_subset --task target_domain_prediction --seed 1 --evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dN0bDTJHq246"
      },
      "source": [
        "## LCC (EN) - Source lexeme prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWIyeTdmZa0G",
        "outputId": "35dba905-2680-400b-d414-a930670bd0a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-11-28 22:07:50.910952: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-28 22:07:50.911018: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-28 22:07:50.911059: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-28 22:07:53.662972: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "User is already logged in.\n",
            "\n",
            "llm: llama2-7b\n",
            "fine_tuned_model_path: None\n",
            "dataset: lcc_en_subset\n",
            "task: source_lexeme_prediction\n",
            "temperature: 0.0\n",
            "seed: 1\n",
            "evaluate: True\n",
            "fine_tuning: False\n",
            "\n",
            "\n",
            "Loading checkpoint shards: 100% 2/2 [01:16<00:00, 38.30s/it]\n",
            "Lenght of train: 1206\n",
            "Lenght of valid: 172\n",
            "Train indices: [\n",
            "    [\n",
            "        200,\n",
            "        584\n",
            "    ],\n",
            "    [\n",
            "        638,\n",
            "        307\n",
            "    ],\n",
            "    [\n",
            "        628,\n",
            "        607\n",
            "    ],\n",
            "    [\n",
            "        200,\n",
            "        584,\n",
            "        807,\n",
            "        895\n",
            "    ],\n",
            "    [\n",
            "        627,\n",
            "        606,\n",
            "        245,\n",
            "        458\n",
            "    ],\n",
            "    [\n",
            "        467,\n",
            "        607,\n",
            "        490,\n",
            "        189\n",
            "    ],\n",
            "    [\n",
            "        200,\n",
            "        584,\n",
            "        807,\n",
            "        895,\n",
            "        336,\n",
            "        314\n",
            "    ],\n",
            "    [\n",
            "        640,\n",
            "        687,\n",
            "        1039,\n",
            "        190,\n",
            "        1089,\n",
            "        284\n",
            "    ],\n",
            "    [\n",
            "        49,\n",
            "        1152,\n",
            "        309,\n",
            "        1026,\n",
            "        869,\n",
            "        826\n",
            "    ],\n",
            "    [\n",
            "        200,\n",
            "        584,\n",
            "        807,\n",
            "        895,\n",
            "        336,\n",
            "        314,\n",
            "        311,\n",
            "        198\n",
            "    ],\n",
            "    [\n",
            "        469,\n",
            "        608,\n",
            "        492,\n",
            "        189,\n",
            "        1026,\n",
            "        943,\n",
            "        204,\n",
            "        1152\n",
            "    ],\n",
            "    [\n",
            "        49,\n",
            "        389,\n",
            "        308,\n",
            "        1024,\n",
            "        810,\n",
            "        1027,\n",
            "        316,\n",
            "        397\n",
            "    ],\n",
            "    [\n",
            "        200,\n",
            "        584,\n",
            "        807,\n",
            "        895,\n",
            "        336,\n",
            "        314,\n",
            "        311,\n",
            "        198,\n",
            "        1029,\n",
            "        189,\n",
            "        190,\n",
            "        49\n",
            "    ],\n",
            "    [\n",
            "        50,\n",
            "        1152,\n",
            "        312,\n",
            "        1027,\n",
            "        870,\n",
            "        827,\n",
            "        773,\n",
            "        915,\n",
            "        670,\n",
            "        608,\n",
            "        82,\n",
            "        887\n",
            "    ],\n",
            "    [\n",
            "        941,\n",
            "        305,\n",
            "        948,\n",
            "        333,\n",
            "        246,\n",
            "        145,\n",
            "        689,\n",
            "        1160,\n",
            "        606,\n",
            "        561,\n",
            "        1058,\n",
            "        564\n",
            "    ]\n",
            "]\n",
            "\n",
            "Number of parameter combinations: 15 \n",
            "\n",
            "[{'few_shot_sample_indices': [200, 584]}, {'few_shot_sample_indices': [638, 307]}, {'few_shot_sample_indices': [628, 607]}, {'few_shot_sample_indices': [200, 584, 807, 895]}, {'few_shot_sample_indices': [627, 606, 245, 458]}, {'few_shot_sample_indices': [467, 607, 490, 189]}, {'few_shot_sample_indices': [200, 584, 807, 895, 336, 314]}, {'few_shot_sample_indices': [640, 687, 1039, 190, 1089, 284]}, {'few_shot_sample_indices': [49, 1152, 309, 1026, 869, 826]}, {'few_shot_sample_indices': [200, 584, 807, 895, 336, 314, 311, 198]}, {'few_shot_sample_indices': [469, 608, 492, 189, 1026, 943, 204, 1152]}, {'few_shot_sample_indices': [49, 389, 308, 1024, 810, 1027, 316, 397]}, {'few_shot_sample_indices': [200, 584, 807, 895, 336, 314, 311, 198, 1029, 189, 190, 49]}, {'few_shot_sample_indices': [50, 1152, 312, 1027, 870, 827, 773, 915, 670, 608, 82, 887]}, {'few_shot_sample_indices': [941, 305, 948, 333, 246, 145, 689, 1160, 606, 561, 1058, 564]}]\n",
            "\n",
            "Current few-shot sample: 1 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' remedy\n",
            "Context: In linguistics, concept ', but wanted ' remedy' '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' through\n",
            "Context: In linguistics, conceptual ', but wanted ' flows '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5004321285888964\n",
            "llama2-7b - (fasttext) Standard deviation:  0.19887552539286207\n",
            "\n",
            "Current few-shot sample: 2 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' remedy\n",
            "Context: In linguistics, concept ', but wanted ' remedy' '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' taxation\n",
            "Context: In linguistics, concept ', but wanted ' flows '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.4523889825917607\n",
            "llama2-7b - (fasttext) Standard deviation:  0.18848924303686898\n",
            "\n",
            "Current few-shot sample: 3 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' remedy\n",
            "Context: In linguistics, concept ', but wanted ' remedy' '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' taxation\n",
            "Context: In linguistics, concept ', but wanted ' flows '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.4627827055925547\n",
            "llama2-7b - (fasttext) Standard deviation:  0.19781839816308988\n",
            "\n",
            "Current few-shot sample: 4 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' remedy\n",
            "Context: In linguistics, concept ', but wanted ' remedy' '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' flows\n",
            "Context: In linguistics, conceptual ', but wanted ' flows '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5321667255877063\n",
            "llama2-7b - (fasttext) Standard deviation:  0.19657663133132572\n",
            "\n",
            "Current few-shot sample: 5 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' remedy\n",
            "Context: In linguistics, concept ', but wanted ' remedy' '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' flow\n",
            "Context: In linguistics, conceptual ', but wanted ' flows '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5594354986624662\n",
            "llama2-7b - (fasttext) Standard deviation:  0.19797453658313102\n",
            "\n",
            "Current few-shot sample: 6 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' remedy\n",
            "Context: In linguistics, concept ', but wanted ' remedy' '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' flow\n",
            "Context: In linguistics, conceptual ', but wanted ' flows '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.4884404029783814\n",
            "llama2-7b - (fasttext) Standard deviation:  0.19720398842104508\n",
            "\n",
            "Current few-shot sample: 7 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' remedy\n",
            "Context: In linguistics, concept ', but wanted ' remedy' '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' flow\n",
            "Context: In linguistics, conceptual ', but wanted ' flows '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5264120198093182\n",
            "llama2-7b - (fasttext) Standard deviation:  0.19384464141771685\n",
            "\n",
            "Current few-shot sample: 8 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' remedy\n",
            "Context: In linguistics, concept ', but wanted ' remedy' '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' flows\n",
            "Context: In linguistics, conceptual ', but wanted ' flows '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5141818388297525\n",
            "llama2-7b - (fasttext) Standard deviation:  0.19580798665031168\n",
            "\n",
            "Current few-shot sample: 9 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' remedy\n",
            "Context: In linguistics, concept ', but wanted ' remedy' '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' flows through\n",
            "Context: In linguistics, concept ', but wanted ' flows '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5762059115046678\n",
            "llama2-7b - (fasttext) Standard deviation:  0.19528967765975166\n",
            "\n",
            "Current few-shot sample: 10 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' remedy\n",
            "Context: In linguistics, concept ', but wanted ' remedy' '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' flows\n",
            "Context: In linguistics, conceptual ', but wanted ' flows '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5359453683675721\n",
            "llama2-7b - (fasttext) Standard deviation:  0.19372430197698892\n",
            "\n",
            "Current few-shot sample: 11 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' remedy\n",
            "Context: In linguistics, concept ', but wanted ' remedy' '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' flows\n",
            "Context: In linguistics, conceptual ', but wanted ' flows '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5567054973785267\n",
            "llama2-7b - (fasttext) Standard deviation:  0.18963963991597982\n",
            "\n",
            "Current few-shot sample: 12 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' remedy\n",
            "Context: In linguistics, concept ', but wanted ' remedy' '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' flows\n",
            "Context: In linguistics, conceptual ', but wanted ' flows '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5405607690254963\n",
            "llama2-7b - (fasttext) Standard deviation:  0.2017678384668239\n",
            "\n",
            "Current few-shot sample: 13 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' remedy\n",
            "Context: In linguistics, concept ', but wanted ' remedy' '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' flows\n",
            "Context: In linguistics, conceptual ', but wanted ' flows '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5439203482738502\n",
            "llama2-7b - (fasttext) Standard deviation:  0.19721508490474043\n",
            "\n",
            "Current few-shot sample: 14 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' remedy\n",
            "Context: In linguistics, concept ', but wanted ' remedy' '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' flows\n",
            "Context: In linguistics, conceptual ', but wanted ' flows '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5237673562409919\n",
            "llama2-7b - (fasttext) Standard deviation:  0.19630998135505137\n",
            "\n",
            "Current few-shot sample: 15 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' remedy\n",
            "Context: In linguistics, concept ', but wanted ' remedy' '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' flows through\n",
            "Context: In linguistics, concept ', but wanted ' flows '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5717599894418273\n",
            "llama2-7b - (fasttext) Standard deviation:  0.1922563984879474\n",
            "Validation results: [\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.5004321285888964,\n",
            "        \"std_em\": 0.19887552539286207,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            200,\n",
            "            584\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.4523889825917607,\n",
            "        \"std_em\": 0.18848924303686898,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            638,\n",
            "            307\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.4627827055925547,\n",
            "        \"std_em\": 0.19781839816308988,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            628,\n",
            "            607\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.5321667255877063,\n",
            "        \"std_em\": 0.19657663133132572,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            200,\n",
            "            584,\n",
            "            807,\n",
            "            895\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.5594354986624662,\n",
            "        \"std_em\": 0.19797453658313102,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            627,\n",
            "            606,\n",
            "            245,\n",
            "            458\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.4884404029783814,\n",
            "        \"std_em\": 0.19720398842104508,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            467,\n",
            "            607,\n",
            "            490,\n",
            "            189\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.5264120198093182,\n",
            "        \"std_em\": 0.19384464141771685,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            200,\n",
            "            584,\n",
            "            807,\n",
            "            895,\n",
            "            336,\n",
            "            314\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.5141818388297525,\n",
            "        \"std_em\": 0.19580798665031168,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            640,\n",
            "            687,\n",
            "            1039,\n",
            "            190,\n",
            "            1089,\n",
            "            284\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.5762059115046678,\n",
            "        \"std_em\": 0.19528967765975166,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            49,\n",
            "            1152,\n",
            "            309,\n",
            "            1026,\n",
            "            869,\n",
            "            826\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.5359453683675721,\n",
            "        \"std_em\": 0.19372430197698892,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            200,\n",
            "            584,\n",
            "            807,\n",
            "            895,\n",
            "            336,\n",
            "            314,\n",
            "            311,\n",
            "            198\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.5567054973785267,\n",
            "        \"std_em\": 0.18963963991597982,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            469,\n",
            "            608,\n",
            "            492,\n",
            "            189,\n",
            "            1026,\n",
            "            943,\n",
            "            204,\n",
            "            1152\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.5405607690254963,\n",
            "        \"std_em\": 0.2017678384668239,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            49,\n",
            "            389,\n",
            "            308,\n",
            "            1024,\n",
            "            810,\n",
            "            1027,\n",
            "            316,\n",
            "            397\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.5439203482738502,\n",
            "        \"std_em\": 0.19721508490474043,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            200,\n",
            "            584,\n",
            "            807,\n",
            "            895,\n",
            "            336,\n",
            "            314,\n",
            "            311,\n",
            "            198,\n",
            "            1029,\n",
            "            189,\n",
            "            190,\n",
            "            49\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.5237673562409919,\n",
            "        \"std_em\": 0.19630998135505137,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            50,\n",
            "            1152,\n",
            "            312,\n",
            "            1027,\n",
            "            870,\n",
            "            827,\n",
            "            773,\n",
            "            915,\n",
            "            670,\n",
            "            608,\n",
            "            82,\n",
            "            887\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.5717599894418273,\n",
            "        \"std_em\": 0.1922563984879474,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            941,\n",
            "            305,\n",
            "            948,\n",
            "            333,\n",
            "            246,\n",
            "            145,\n",
            "            689,\n",
            "            1160,\n",
            "            606,\n",
            "            561,\n",
            "            1058,\n",
            "            564\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    }\n",
            "]\n",
            "\n",
            "Lenght of test: 345\n",
            "Getting completions...\n",
            "Evaluating test set performance...\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' passionist\n",
            "Context: In linguistics, concept ', but wanted ' passionist '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' brayers\n",
            "Context: In linguistics, ', but wanted ' brayers '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5765718899127366\n",
            "llama2-7b - (fasttext) Standard deviation:  0.1830668094471654\n",
            "Test results: {\n",
            "    \"model\": \"llama2-7b\",\n",
            "    \"acc\": 0.0,\n",
            "    \"mean_em\": 0.5765718899127366,\n",
            "    \"std_em\": 0.1830668094471654,\n",
            "    \"few_shot_sample_indices\": [\n",
            "        49,\n",
            "        1152,\n",
            "        309,\n",
            "        1026,\n",
            "        869,\n",
            "        826\n",
            "    ],\n",
            "    \"few_shot_samples\": 6,\n",
            "    \"temperature\": 0.0,\n",
            "    \"eval_split\": \"test\",\n",
            "    \"dataset_name\": \"lcc_en_subset\",\n",
            "    \"fine_tuning\": false\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"$WORKDIR\" python -m src.main --llm llama2-7b --temperature 0 --dataset lcc_en_subset --task source_lexeme_prediction --seed 1 --evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eIiQL1Fq6Cp"
      },
      "source": [
        "## LCC (EN) - Target lexeme prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DL6DG7qwZdJD",
        "outputId": "f3e4569a-cbe2-4288-cbc3-9a8c04fdbe3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-11-28 23:29:02.720373: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-28 23:29:02.720427: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-28 23:29:02.720464: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-28 23:29:04.773996: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "User is already logged in.\n",
            "\n",
            "llm: llama2-7b\n",
            "fine_tuned_model_path: None\n",
            "dataset: lcc_en_subset\n",
            "task: target_lexeme_prediction\n",
            "temperature: 0.0\n",
            "seed: 1\n",
            "evaluate: True\n",
            "fine_tuning: False\n",
            "\n",
            "\n",
            "Loading checkpoint shards: 100% 2/2 [01:18<00:00, 39.05s/it]\n",
            "Lenght of train: 1206\n",
            "Lenght of valid: 172\n",
            "Train indices: [\n",
            "    [\n",
            "        200,\n",
            "        584\n",
            "    ],\n",
            "    [\n",
            "        638,\n",
            "        307\n",
            "    ],\n",
            "    [\n",
            "        628,\n",
            "        607\n",
            "    ],\n",
            "    [\n",
            "        200,\n",
            "        584,\n",
            "        807,\n",
            "        895\n",
            "    ],\n",
            "    [\n",
            "        627,\n",
            "        606,\n",
            "        245,\n",
            "        458\n",
            "    ],\n",
            "    [\n",
            "        467,\n",
            "        607,\n",
            "        490,\n",
            "        189\n",
            "    ],\n",
            "    [\n",
            "        200,\n",
            "        584,\n",
            "        807,\n",
            "        895,\n",
            "        336,\n",
            "        314\n",
            "    ],\n",
            "    [\n",
            "        640,\n",
            "        687,\n",
            "        1039,\n",
            "        190,\n",
            "        1089,\n",
            "        284\n",
            "    ],\n",
            "    [\n",
            "        49,\n",
            "        1152,\n",
            "        309,\n",
            "        1026,\n",
            "        869,\n",
            "        826\n",
            "    ],\n",
            "    [\n",
            "        200,\n",
            "        584,\n",
            "        807,\n",
            "        895,\n",
            "        336,\n",
            "        314,\n",
            "        311,\n",
            "        198\n",
            "    ],\n",
            "    [\n",
            "        469,\n",
            "        608,\n",
            "        492,\n",
            "        189,\n",
            "        1026,\n",
            "        943,\n",
            "        204,\n",
            "        1152\n",
            "    ],\n",
            "    [\n",
            "        49,\n",
            "        389,\n",
            "        308,\n",
            "        1024,\n",
            "        810,\n",
            "        1027,\n",
            "        316,\n",
            "        397\n",
            "    ],\n",
            "    [\n",
            "        200,\n",
            "        584,\n",
            "        807,\n",
            "        895,\n",
            "        336,\n",
            "        314,\n",
            "        311,\n",
            "        198,\n",
            "        1029,\n",
            "        189,\n",
            "        190,\n",
            "        49\n",
            "    ],\n",
            "    [\n",
            "        50,\n",
            "        1152,\n",
            "        312,\n",
            "        1027,\n",
            "        870,\n",
            "        827,\n",
            "        773,\n",
            "        915,\n",
            "        670,\n",
            "        608,\n",
            "        82,\n",
            "        887\n",
            "    ],\n",
            "    [\n",
            "        941,\n",
            "        305,\n",
            "        948,\n",
            "        333,\n",
            "        246,\n",
            "        145,\n",
            "        689,\n",
            "        1160,\n",
            "        606,\n",
            "        561,\n",
            "        1058,\n",
            "        564\n",
            "    ]\n",
            "]\n",
            "\n",
            "Number of parameter combinations: 15 \n",
            "\n",
            "[{'few_shot_sample_indices': [200, 584]}, {'few_shot_sample_indices': [638, 307]}, {'few_shot_sample_indices': [628, 607]}, {'few_shot_sample_indices': [200, 584, 807, 895]}, {'few_shot_sample_indices': [627, 606, 245, 458]}, {'few_shot_sample_indices': [467, 607, 490, 189]}, {'few_shot_sample_indices': [200, 584, 807, 895, 336, 314]}, {'few_shot_sample_indices': [640, 687, 1039, 190, 1089, 284]}, {'few_shot_sample_indices': [49, 1152, 309, 1026, 869, 826]}, {'few_shot_sample_indices': [200, 584, 807, 895, 336, 314, 311, 198]}, {'few_shot_sample_indices': [469, 608, 492, 189, 1026, 943, 204, 1152]}, {'few_shot_sample_indices': [49, 389, 308, 1024, 810, 1027, 316, 397]}, {'few_shot_sample_indices': [200, 584, 807, 895, 336, 314, 311, 198, 1029, 189, 190, 49]}, {'few_shot_sample_indices': [50, 1152, 312, 1027, 870, 827, 773, 915, 670, 608, 82, 887]}, {'few_shot_sample_indices': [941, 305, 948, 333, 246, 145, 689, 1160, 606, 561, 1058, 564]}]\n",
            "\n",
            "Current few-shot sample: 1 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Spring\n",
            "Context: In linguistics, conceptual ', but wanted ' Democracys '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' taxes\n",
            "Context: In linguistics, concept ', but wanted ' \"taxes\" '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' militia\n",
            "Context: In linguistics, concept ', but wanted ' 2A. '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government\n",
            "Context: In linguistics, conceptual ', but wanted ' government's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' democracy\n",
            "Context: In linguistics, concept ', but wanted ' \"democracy\" '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5833164977104685\n",
            "llama2-7b - (fasttext) Standard deviation:  0.18498474957084268\n",
            "\n",
            "Current few-shot sample: 2 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' ball\n",
            "Context: In linguistics, conceptual ', but wanted ' Democracys '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' taxes\n",
            "Context: In linguistics, concept ', but wanted ' \"taxes\" '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' militia\n",
            "Context: In linguistics, concept ', but wanted ' 2A. '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government\n",
            "Context: In linguistics, conceptual ', but wanted ' government's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' democracy\n",
            "Context: In linguistics, concept ', but wanted ' \"democracy\" '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.566414445714462\n",
            "llama2-7b - (fasttext) Standard deviation:  0.21400931678627433\n",
            "\n",
            "Current few-shot sample: 3 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Democracy\n",
            "Context: In linguistics, concept ', but wanted ' Democracys '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' taxes\n",
            "Context: In linguistics, concept ', but wanted ' \"taxes\" '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' 2A\n",
            "Context: In linguistics, ', but wanted ' 2A. '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government\n",
            "Context: In linguistics, conceptual ', but wanted ' government's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' democracy\n",
            "Context: In linguistics, concept ', but wanted ' \"democracy\" '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.612574428612323\n",
            "llama2-7b - (fasttext) Standard deviation:  0.18957898762340633\n",
            "\n",
            "Current few-shot sample: 4 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Spring\n",
            "Context: In linguistics, conceptual ', but wanted ' Democracys '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' taxes\n",
            "Context: In linguistics, concept ', but wanted ' \"taxes\" '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' militia\n",
            "Context: In linguistics, concept ', but wanted ' 2A. '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government\n",
            "Context: In linguistics, conceptual ', but wanted ' government's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' democracy\n",
            "Context: In linguistics, concept ', but wanted ' \"democracy\" '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5928515749766903\n",
            "llama2-7b - (fasttext) Standard deviation:  0.18457767726829274\n",
            "\n",
            "Current few-shot sample: 5 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' democracy\n",
            "Context: In linguistics, concept ', but wanted ' Democracys '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' taxes\n",
            "Context: In linguistics, concept ', but wanted ' \"taxes\" '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' militia\n",
            "Context: In linguistics, concept ', but wanted ' 2A. '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government\n",
            "Context: In linguistics, conceptual ', but wanted ' government's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' democracy\n",
            "Context: In linguistics, concept ', but wanted ' \"democracy\" '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.6171191958818845\n",
            "llama2-7b - (fasttext) Standard deviation:  0.18570396861228614\n",
            "\n",
            "Current few-shot sample: 6 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Democracy\n",
            "Context: In linguistics, concept ', but wanted ' Democracys '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' taxes\n",
            "Context: In linguistics, concept ', but wanted ' \"taxes\" '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' 2A\n",
            "Context: In linguistics, ', but wanted ' 2A. '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government\n",
            "Context: In linguistics, conceptual ', but wanted ' government's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' democracy\n",
            "Context: In linguistics, concept ', but wanted ' \"democracy\" '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.6220557362945793\n",
            "llama2-7b - (fasttext) Standard deviation:  0.18096190858181266\n",
            "\n",
            "Current few-shot sample: 7 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Spring\n",
            "Context: In linguistics, conceptual ', but wanted ' Democracys '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' taxes\n",
            "Context: In linguistics, concept ', but wanted ' \"taxes\" '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' militia\n",
            "Context: In linguistics, concept ', but wanted ' 2A. '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government\n",
            "Context: In linguistics, conceptual ', but wanted ' government's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' democracy\n",
            "Context: In linguistics, concept ', but wanted ' \"democracy\" '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.6127941406028735\n",
            "llama2-7b - (fasttext) Standard deviation:  0.1802576981500189\n",
            "\n",
            "Current few-shot sample: 8 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' democracy\n",
            "Context: In linguistics, concept ', but wanted ' Democracys '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' taxes\n",
            "Context: In linguistics, concept ', but wanted ' \"taxes\" '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' militia\n",
            "Context: In linguistics, concept ', but wanted ' 2A. '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government\n",
            "Context: In linguistics, conceptual ', but wanted ' government's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' democracy\n",
            "Context: In linguistics, concept ', but wanted ' \"democracy\" '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.6167274018164811\n",
            "llama2-7b - (fasttext) Standard deviation:  0.17893735659389082\n",
            "\n",
            "Current few-shot sample: 9 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' democracy\n",
            "Context: In linguistics, concept ', but wanted ' Democracys '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' taxes\n",
            "Context: In linguistics, concept ', but wanted ' \"taxes\" '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' 2A\n",
            "Context: In linguistics, ', but wanted ' 2A. '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government\n",
            "Context: In linguistics, conceptual ', but wanted ' government's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' democracy\n",
            "Context: In linguistics, concept ', but wanted ' \"democracy\" '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.64523394062552\n",
            "llama2-7b - (fasttext) Standard deviation:  0.1702938204386422\n",
            "\n",
            "Current few-shot sample: 10 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' democracy\n",
            "Context: In linguistics, concept ', but wanted ' Democracys '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' taxes\n",
            "Context: In linguistics, concept ', but wanted ' \"taxes\" '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' 2A\n",
            "Context: In linguistics, ', but wanted ' 2A. '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government\n",
            "Context: In linguistics, conceptual ', but wanted ' government's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' democracy\n",
            "Context: In linguistics, concept ', but wanted ' \"democracy\" '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.6271082875751999\n",
            "llama2-7b - (fasttext) Standard deviation:  0.16865302140819727\n",
            "\n",
            "Current few-shot sample: 11 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' democracy\n",
            "Context: In linguistics, concept ', but wanted ' Democracys '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' taxes\n",
            "Context: In linguistics, concept ', but wanted ' \"taxes\" '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' militia\n",
            "Context: In linguistics, concept ', but wanted ' 2A. '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government\n",
            "Context: In linguistics, conceptual ', but wanted ' government's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' democracy\n",
            "Context: In linguistics, concept ', but wanted ' \"democracy\" '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.635196803689956\n",
            "llama2-7b - (fasttext) Standard deviation:  0.17489205282205517\n",
            "\n",
            "Current few-shot sample: 12 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' democracy\n",
            "Context: In linguistics, concept ', but wanted ' Democracys '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' taxes\n",
            "Context: In linguistics, concept ', but wanted ' \"taxes\" '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' 2A\n",
            "Context: In linguistics, ', but wanted ' 2A. '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government\n",
            "Context: In linguistics, conceptual ', but wanted ' government's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' democracy\n",
            "Context: In linguistics, concept ', but wanted ' \"democracy\" '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.6273105435918064\n",
            "llama2-7b - (fasttext) Standard deviation:  0.19078188779239072\n",
            "\n",
            "Current few-shot sample: 13 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Democracy\n",
            "Context: In linguistics, concept ', but wanted ' Democracys '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' taxes\n",
            "Context: In linguistics, concept ', but wanted ' \"taxes\" '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' 2A\n",
            "Context: In linguistics, ', but wanted ' 2A. '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government\n",
            "Context: In linguistics, conceptual ', but wanted ' government's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' democracy\n",
            "Context: In linguistics, concept ', but wanted ' \"democracy\" '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.6407089234156491\n",
            "llama2-7b - (fasttext) Standard deviation:  0.16352095351609608\n",
            "\n",
            "Current few-shot sample: 14 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' democracy\n",
            "Context: In linguistics, concept ', but wanted ' Democracys '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' taxes\n",
            "Context: In linguistics, concept ', but wanted ' \"taxes\" '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' militia\n",
            "Context: In linguistics, concept ', but wanted ' 2A. '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government\n",
            "Context: In linguistics, conceptual ', but wanted ' government's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' democracy\n",
            "Context: In linguistics, concept ', but wanted ' \"democracy\" '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.6373645176374635\n",
            "llama2-7b - (fasttext) Standard deviation:  0.1751283262888874\n",
            "\n",
            "Current few-shot sample: 15 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Spring\n",
            "Context: In linguistics, conceptual ', but wanted ' Democracys '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' taxes\n",
            "Context: In linguistics, concept ', but wanted ' \"taxes\" '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' 2A\n",
            "Context: In linguistics, ', but wanted ' 2A. '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government\n",
            "Context: In linguistics, conceptual ', but wanted ' government's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' democracy\n",
            "Context: In linguistics, concept ', but wanted ' \"democracy\" '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.6358747739063273\n",
            "llama2-7b - (fasttext) Standard deviation:  0.17995886653013438\n",
            "Validation results: [\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.5833164977104685,\n",
            "        \"std_em\": 0.18498474957084268,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            200,\n",
            "            584\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.566414445714462,\n",
            "        \"std_em\": 0.21400931678627433,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            638,\n",
            "            307\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.612574428612323,\n",
            "        \"std_em\": 0.18957898762340633,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            628,\n",
            "            607\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.5928515749766903,\n",
            "        \"std_em\": 0.18457767726829274,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            200,\n",
            "            584,\n",
            "            807,\n",
            "            895\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.6171191958818845,\n",
            "        \"std_em\": 0.18570396861228614,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            627,\n",
            "            606,\n",
            "            245,\n",
            "            458\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.6220557362945793,\n",
            "        \"std_em\": 0.18096190858181266,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            467,\n",
            "            607,\n",
            "            490,\n",
            "            189\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.6127941406028735,\n",
            "        \"std_em\": 0.1802576981500189,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            200,\n",
            "            584,\n",
            "            807,\n",
            "            895,\n",
            "            336,\n",
            "            314\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.6167274018164811,\n",
            "        \"std_em\": 0.17893735659389082,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            640,\n",
            "            687,\n",
            "            1039,\n",
            "            190,\n",
            "            1089,\n",
            "            284\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.64523394062552,\n",
            "        \"std_em\": 0.1702938204386422,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            49,\n",
            "            1152,\n",
            "            309,\n",
            "            1026,\n",
            "            869,\n",
            "            826\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.6271082875751999,\n",
            "        \"std_em\": 0.16865302140819727,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            200,\n",
            "            584,\n",
            "            807,\n",
            "            895,\n",
            "            336,\n",
            "            314,\n",
            "            311,\n",
            "            198\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.635196803689956,\n",
            "        \"std_em\": 0.17489205282205517,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            469,\n",
            "            608,\n",
            "            492,\n",
            "            189,\n",
            "            1026,\n",
            "            943,\n",
            "            204,\n",
            "            1152\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.6273105435918064,\n",
            "        \"std_em\": 0.19078188779239072,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            49,\n",
            "            389,\n",
            "            308,\n",
            "            1024,\n",
            "            810,\n",
            "            1027,\n",
            "            316,\n",
            "            397\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.6407089234156491,\n",
            "        \"std_em\": 0.16352095351609608,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            200,\n",
            "            584,\n",
            "            807,\n",
            "            895,\n",
            "            336,\n",
            "            314,\n",
            "            311,\n",
            "            198,\n",
            "            1029,\n",
            "            189,\n",
            "            190,\n",
            "            49\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.6373645176374635,\n",
            "        \"std_em\": 0.1751283262888874,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            50,\n",
            "            1152,\n",
            "            312,\n",
            "            1027,\n",
            "            870,\n",
            "            827,\n",
            "            773,\n",
            "            915,\n",
            "            670,\n",
            "            608,\n",
            "            82,\n",
            "            887\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.0,\n",
            "        \"mean_em\": 0.6358747739063273,\n",
            "        \"std_em\": 0.17995886653013438,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            941,\n",
            "            305,\n",
            "            948,\n",
            "            333,\n",
            "            246,\n",
            "            145,\n",
            "            689,\n",
            "            1160,\n",
            "            606,\n",
            "            561,\n",
            "            1058,\n",
            "            564\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\"\n",
            "    }\n",
            "]\n",
            "\n",
            "Lenght of test: 345\n",
            "Getting completions...\n",
            "Evaluating test set performance...\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' hunting\n",
            "Context: In linguistics, conceptual ', but wanted ' 2A. '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' democracy\n",
            "Context: In linguistics, concept ', but wanted ' Democracys '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' health care bill\n",
            "Context: In linguistics, ', but wanted ' Senate's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' reading glasses\n",
            "Context: In linguistics, ', but wanted ' Government's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' NRA\n",
            "Context: In linguistics, concept ', but wanted ' NRAs '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government\n",
            "Context: In linguistics, conceptual ', but wanted ' government's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' message control\n",
            "Context: In linguistics, concept ', but wanted ' candidates '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' economic reform\n",
            "Context: In linguistics, concept ', but wanted ' government's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Hollywood\n",
            "Context: In linguistics, conceptual ', but wanted ' NRA's '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.6308411243169204\n",
            "llama2-7b - (fasttext) Standard deviation:  0.17242975125933896\n",
            "Test results: {\n",
            "    \"model\": \"llama2-7b\",\n",
            "    \"acc\": 0.0,\n",
            "    \"mean_em\": 0.6308411243169204,\n",
            "    \"std_em\": 0.17242975125933896,\n",
            "    \"few_shot_sample_indices\": [\n",
            "        49,\n",
            "        1152,\n",
            "        309,\n",
            "        1026,\n",
            "        869,\n",
            "        826\n",
            "    ],\n",
            "    \"few_shot_samples\": 6,\n",
            "    \"temperature\": 0.0,\n",
            "    \"eval_split\": \"test\",\n",
            "    \"dataset_name\": \"lcc_en_subset\",\n",
            "    \"fine_tuning\": false\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"$WORKDIR\" python -m src.main --llm llama2-7b --temperature 0 --dataset lcc_en_subset --task target_lexeme_prediction --seed 1 --evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIWI1oNhqeJy"
      },
      "source": [
        "## TroFi - Metaphor classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yoVYxBS543J",
        "outputId": "5afec4e0-80f8-42d5-bf0c-435b30665d4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-11-25 23:54:24.531497: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-25 23:54:24.531551: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-25 23:54:24.531589: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-25 23:54:25.601739: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n",
            "llm: llama2-7b\n",
            "fine_tuned_model_path: None\n",
            "dataset: trofi\n",
            "task: classification\n",
            "temperature: 0.0\n",
            "seed: 1\n",
            "evaluate: True\n",
            "fine_tuning: False\n",
            "\n",
            "\n",
            "config.json: 100% 609/609 [00:00<00:00, 464kB/s]\n",
            "model.safetensors.index.json: 100% 26.8k/26.8k [00:00<00:00, 21.9MB/s]\n",
            "Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00001-of-00002.safetensors:   0% 0.00/9.98G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 10.5M/9.98G [00:00<02:00, 83.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 41.9M/9.98G [00:00<00:55, 180MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 73.4M/9.98G [00:00<00:46, 215MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 105M/9.98G [00:00<00:47, 209MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 136M/9.98G [00:00<00:42, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 168M/9.98G [00:00<00:50, 194MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 189M/9.98G [00:00<00:50, 195MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 210M/9.98G [00:01<00:49, 199MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 231M/9.98G [00:01<00:48, 200MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 262M/9.98G [00:01<00:45, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 294M/9.98G [00:01<00:42, 225MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 325M/9.98G [00:01<00:41, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 357M/9.98G [00:01<00:39, 242MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 388M/9.98G [00:01<00:38, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 419M/9.98G [00:01<00:38, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 451M/9.98G [00:02<00:37, 252MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 482M/9.98G [00:02<00:37, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 514M/9.98G [00:02<00:37, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 545M/9.98G [00:02<00:38, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 577M/9.98G [00:02<00:37, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 608M/9.98G [00:02<00:37, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 640M/9.98G [00:02<00:38, 241MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 671M/9.98G [00:02<00:37, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 703M/9.98G [00:03<00:37, 244MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 734M/9.98G [00:03<00:37, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 765M/9.98G [00:03<00:37, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 797M/9.98G [00:03<00:38, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 828M/9.98G [00:03<00:36, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 860M/9.98G [00:03<00:35, 260MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 891M/9.98G [00:03<00:35, 259MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 923M/9.98G [00:03<00:34, 260MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 954M/9.98G [00:04<00:33, 267MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 986M/9.98G [00:04<00:33, 267MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 1.02G/9.98G [00:04<00:32, 278MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.05G/9.98G [00:04<00:31, 279MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.08G/9.98G [00:04<00:34, 257MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.11G/9.98G [00:04<00:36, 240MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.14G/9.98G [00:04<00:42, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 1.17G/9.98G [00:05<00:41, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 1.21G/9.98G [00:05<00:39, 222MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 1.24G/9.98G [00:05<00:36, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.27G/9.98G [00:05<00:35, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.30G/9.98G [00:05<00:34, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.33G/9.98G [00:05<00:33, 256MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 1.36G/9.98G [00:05<00:34, 253MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 1.39G/9.98G [00:05<00:32, 261MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 1.43G/9.98G [00:05<00:32, 262MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.46G/9.98G [00:06<00:32, 259MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.49G/9.98G [00:06<00:33, 255MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.52G/9.98G [00:06<00:33, 254MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 1.55G/9.98G [00:06<00:32, 256MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 1.58G/9.98G [00:06<00:33, 254MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 1.61G/9.98G [00:06<00:33, 252MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.65G/9.98G [00:06<00:33, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.68G/9.98G [00:06<00:32, 252MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.71G/9.98G [00:07<00:32, 258MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.74G/9.98G [00:07<00:31, 259MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.77G/9.98G [00:07<00:31, 258MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.80G/9.98G [00:07<00:33, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.84G/9.98G [00:07<00:35, 232MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 1.87G/9.98G [00:07<00:33, 242MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 1.90G/9.98G [00:07<00:33, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 1.93G/9.98G [00:08<00:34, 234MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.96G/9.98G [00:08<00:34, 232MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.99G/9.98G [00:08<00:34, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 2.02G/9.98G [00:08<00:34, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 2.06G/9.98G [00:08<00:32, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 2.09G/9.98G [00:08<00:32, 240MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 2.12G/9.98G [00:08<00:33, 235MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.15G/9.98G [00:08<00:33, 232MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.18G/9.98G [00:09<00:32, 240MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.21G/9.98G [00:09<00:31, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.24G/9.98G [00:09<00:33, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.28G/9.98G [00:09<00:34, 221MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.31G/9.98G [00:09<00:35, 216MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.34G/9.98G [00:09<00:35, 216MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.37G/9.98G [00:09<00:35, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.40G/9.98G [00:10<00:34, 217MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.43G/9.98G [00:10<00:33, 223MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.46G/9.98G [00:10<00:33, 225MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.50G/9.98G [00:10<00:36, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.53G/9.98G [00:10<00:33, 221MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.56G/9.98G [00:10<00:31, 236MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.59G/9.98G [00:10<00:33, 223MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.62G/9.98G [00:11<00:30, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.65G/9.98G [00:11<00:32, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.68G/9.98G [00:11<00:36, 200MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.72G/9.98G [00:11<00:35, 203MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.75G/9.98G [00:11<00:34, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.78G/9.98G [00:13<02:43, 44.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.81G/9.98G [00:13<02:02, 58.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.83G/9.98G [00:14<02:29, 47.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.86G/9.98G [00:14<01:49, 65.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.88G/9.98G [00:14<01:31, 77.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.92G/9.98G [00:14<01:09, 101MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.94G/9.98G [00:14<01:01, 115MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 2.96G/9.98G [00:15<00:54, 129MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 2.98G/9.98G [00:15<00:48, 143MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 3.01G/9.98G [00:15<00:41, 168MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 3.04G/9.98G [00:15<00:36, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.07G/9.98G [00:15<00:34, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.10G/9.98G [00:15<00:32, 213MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.14G/9.98G [00:15<00:31, 219MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.17G/9.98G [00:15<00:29, 229MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.20G/9.98G [00:16<00:32, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.23G/9.98G [00:16<00:32, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.26G/9.98G [00:16<00:31, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.29G/9.98G [00:16<00:31, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.32G/9.98G [00:16<00:31, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.36G/9.98G [00:16<00:32, 202MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.39G/9.98G [00:17<00:30, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.42G/9.98G [00:17<00:30, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.45G/9.98G [00:17<00:28, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.48G/9.98G [00:17<00:27, 235MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.51G/9.98G [00:17<00:29, 220MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.54G/9.98G [00:17<00:28, 229MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.58G/9.98G [00:17<00:26, 244MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.61G/9.98G [00:17<00:24, 257MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.64G/9.98G [00:18<00:24, 254MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.67G/9.98G [00:18<00:26, 239MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.70G/9.98G [00:18<00:26, 240MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.73G/9.98G [00:18<00:48, 130MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.76G/9.98G [00:18<00:40, 153MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.80G/9.98G [00:19<00:35, 174MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.83G/9.98G [00:19<00:32, 189MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.86G/9.98G [00:19<00:36, 166MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.88G/9.98G [00:19<00:36, 165MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.91G/9.98G [00:19<00:33, 183MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 3.94G/9.98G [00:19<00:31, 194MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 3.96G/9.98G [00:20<00:31, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 4.00G/9.98G [00:20<00:29, 204MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 4.03G/9.98G [00:24<04:19, 23.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.06G/9.98G [00:24<03:04, 32.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.09G/9.98G [00:24<02:14, 43.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.12G/9.98G [00:24<01:39, 58.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.15G/9.98G [00:24<01:15, 77.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.18G/9.98G [00:24<00:58, 99.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.22G/9.98G [00:24<00:46, 123MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.25G/9.98G [00:24<00:41, 136MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.28G/9.98G [00:25<00:36, 155MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.31G/9.98G [00:25<00:32, 176MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.34G/9.98G [00:25<00:29, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.37G/9.98G [00:25<00:27, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.40G/9.98G [00:25<00:25, 218MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.44G/9.98G [00:25<00:24, 226MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 4.47G/9.98G [00:25<00:23, 235MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 4.50G/9.98G [00:26<00:24, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 4.53G/9.98G [00:26<00:23, 234MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.56G/9.98G [00:26<00:22, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.59G/9.98G [00:26<00:22, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.62G/9.98G [00:26<00:22, 242MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.66G/9.98G [00:26<00:21, 245MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.69G/9.98G [00:26<00:21, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.72G/9.98G [00:26<00:21, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.75G/9.98G [00:27<00:21, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.78G/9.98G [00:27<00:20, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.81G/9.98G [00:27<00:20, 254MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.84G/9.98G [00:27<00:20, 256MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.88G/9.98G [00:27<00:20, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.91G/9.98G [00:27<00:20, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 4.94G/9.98G [00:27<00:20, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 4.97G/9.98G [00:27<00:21, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 5.00G/9.98G [00:28<00:21, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 5.03G/9.98G [00:28<00:21, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.06G/9.98G [00:28<00:21, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.10G/9.98G [00:28<00:21, 226MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.13G/9.98G [00:28<00:20, 239MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.16G/9.98G [00:28<00:23, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.19G/9.98G [00:28<00:23, 208MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.22G/9.98G [00:29<00:21, 218MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.25G/9.98G [00:29<00:20, 225MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.28G/9.98G [00:29<00:20, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.32G/9.98G [00:29<00:21, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 5.35G/9.98G [00:29<00:22, 208MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 5.38G/9.98G [00:29<00:21, 218MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 5.41G/9.98G [00:29<00:20, 223MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.44G/9.98G [00:30<00:21, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.47G/9.98G [00:30<00:22, 196MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.49G/9.98G [00:30<00:23, 193MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.52G/9.98G [00:30<00:22, 196MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.54G/9.98G [00:30<00:22, 197MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 5.57G/9.98G [00:30<00:21, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 5.59G/9.98G [00:30<00:22, 197MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 5.62G/9.98G [00:31<00:20, 208MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.65G/9.98G [00:31<00:20, 215MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.68G/9.98G [00:31<00:19, 221MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.71G/9.98G [00:31<00:18, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.75G/9.98G [00:31<00:18, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.78G/9.98G [00:31<00:17, 241MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.81G/9.98G [00:31<00:17, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.84G/9.98G [00:31<00:17, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.87G/9.98G [00:32<00:17, 239MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.90G/9.98G [00:32<00:17, 229MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.93G/9.98G [00:32<00:18, 224MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 5.97G/9.98G [00:32<00:18, 221MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 6.00G/9.98G [00:33<01:04, 61.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 6.02G/9.98G [00:33<00:54, 72.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.05G/9.98G [00:34<00:41, 93.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.08G/9.98G [00:34<00:33, 117MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.11G/9.98G [00:34<00:29, 129MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.13G/9.98G [00:34<00:28, 134MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.16G/9.98G [00:34<00:26, 147MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.18G/9.98G [00:34<00:26, 146MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.21G/9.98G [00:34<00:23, 162MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.23G/9.98G [00:35<00:22, 170MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.25G/9.98G [00:35<00:20, 178MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.28G/9.98G [00:35<00:19, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.31G/9.98G [00:35<00:18, 203MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 6.34G/9.98G [00:35<00:17, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 6.38G/9.98G [00:35<00:16, 218MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 6.41G/9.98G [00:35<00:16, 221MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.44G/9.98G [00:35<00:15, 229MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.47G/9.98G [00:36<00:15, 225MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.50G/9.98G [00:36<00:14, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.53G/9.98G [00:36<00:15, 224MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.56G/9.98G [00:36<00:16, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.60G/9.98G [00:36<00:22, 148MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.63G/9.98G [00:37<00:19, 168MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.65G/9.98G [00:38<01:19, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.68G/9.98G [00:38<00:57, 57.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.70G/9.98G [00:39<00:47, 68.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.72G/9.98G [00:39<00:41, 79.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 6.74G/9.98G [00:39<00:35, 91.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 6.76G/9.98G [00:39<00:30, 106MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 6.79G/9.98G [00:39<00:23, 133MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 6.83G/9.98G [00:39<00:20, 157MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.85G/9.98G [00:39<00:19, 164MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.88G/9.98G [00:40<00:17, 181MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.91G/9.98G [00:40<00:15, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 6.94G/9.98G [00:40<00:14, 213MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 6.97G/9.98G [00:40<00:13, 223MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 7.00G/9.98G [00:40<00:13, 224MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.04G/9.98G [00:40<00:12, 229MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.07G/9.98G [00:40<00:12, 228MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.10G/9.98G [00:40<00:12, 236MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.13G/9.98G [00:41<00:11, 240MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.16G/9.98G [00:41<00:11, 244MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.19G/9.98G [00:41<00:11, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.22G/9.98G [00:41<00:11, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.26G/9.98G [00:41<00:11, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.29G/9.98G [00:41<00:10, 253MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.32G/9.98G [00:41<00:10, 252MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.35G/9.98G [00:41<00:10, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.38G/9.98G [00:42<00:10, 257MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.41G/9.98G [00:42<00:10, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.44G/9.98G [00:42<00:10, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.48G/9.98G [00:42<00:10, 244MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.51G/9.98G [00:42<00:09, 253MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.54G/9.98G [00:42<00:09, 253MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.57G/9.98G [00:42<00:09, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.60G/9.98G [00:42<00:09, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.63G/9.98G [00:43<00:09, 253MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.67G/9.98G [00:43<00:08, 257MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.70G/9.98G [00:43<00:08, 260MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.73G/9.98G [00:43<00:08, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.76G/9.98G [00:43<00:08, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.79G/9.98G [00:43<00:08, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.82G/9.98G [00:43<00:08, 252MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.85G/9.98G [00:43<00:08, 256MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.89G/9.98G [00:44<00:07, 264MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.92G/9.98G [00:44<00:07, 267MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 7.95G/9.98G [00:44<00:08, 240MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 7.98G/9.98G [00:44<00:08, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 8.01G/9.98G [00:44<00:08, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.04G/9.98G [00:44<00:07, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.07G/9.98G [00:44<00:07, 244MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.11G/9.98G [00:44<00:07, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.14G/9.98G [00:45<00:07, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.17G/9.98G [00:45<00:07, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.20G/9.98G [00:45<00:07, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.23G/9.98G [00:45<00:06, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.26G/9.98G [00:45<00:07, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.29G/9.98G [00:45<00:06, 242MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.33G/9.98G [00:45<00:06, 255MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 8.36G/9.98G [00:45<00:06, 265MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 8.39G/9.98G [00:46<00:05, 269MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 8.42G/9.98G [00:46<00:05, 273MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.45G/9.98G [00:46<00:06, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.48G/9.98G [00:46<00:06, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.51G/9.98G [00:46<00:06, 241MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 8.55G/9.98G [00:46<00:05, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 8.58G/9.98G [00:46<00:05, 241MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 8.61G/9.98G [00:46<00:05, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.64G/9.98G [00:47<00:05, 242MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.67G/9.98G [00:47<00:05, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.70G/9.98G [00:47<00:05, 252MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.73G/9.98G [00:47<00:04, 255MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.77G/9.98G [00:47<00:04, 255MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.80G/9.98G [00:47<00:04, 255MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.83G/9.98G [00:47<00:04, 254MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 8.86G/9.98G [00:47<00:04, 261MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 8.89G/9.98G [00:48<00:04, 261MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 8.92G/9.98G [00:48<00:04, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 8.95G/9.98G [00:48<00:04, 234MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 8.99G/9.98G [00:48<00:04, 222MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 9.02G/9.98G [00:48<00:04, 224MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 9.05G/9.98G [00:48<00:04, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 9.08G/9.98G [00:48<00:04, 219MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 9.11G/9.98G [00:49<00:03, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.14G/9.98G [00:49<00:03, 216MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.18G/9.98G [00:49<00:03, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.21G/9.98G [00:49<00:03, 208MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.24G/9.98G [00:49<00:03, 203MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.27G/9.98G [00:49<00:03, 197MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.30G/9.98G [00:50<00:03, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.33G/9.98G [00:50<00:02, 222MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.36G/9.98G [00:50<00:02, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.40G/9.98G [00:50<00:02, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.43G/9.98G [00:50<00:02, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.46G/9.98G [00:50<00:02, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.49G/9.98G [00:53<00:16, 29.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.51G/9.98G [00:54<00:13, 35.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.53G/9.98G [00:54<00:10, 44.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.55G/9.98G [00:54<00:07, 55.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.58G/9.98G [00:54<00:05, 75.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.62G/9.98G [00:54<00:03, 100MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.65G/9.98G [00:54<00:02, 126MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.68G/9.98G [00:54<00:01, 151MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.71G/9.98G [00:54<00:01, 174MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.74G/9.98G [00:55<00:01, 173MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.77G/9.98G [00:55<00:01, 168MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.79G/9.98G [00:58<00:07, 23.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.83G/9.98G [00:59<00:04, 32.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.85G/9.98G [00:59<00:03, 40.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.87G/9.98G [00:59<00:02, 49.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.89G/9.98G [00:59<00:01, 61.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.91G/9.98G [00:59<00:00, 74.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 9.94G/9.98G [00:59<00:00, 102MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 9.98G/9.98G [00:59<00:00, 167MB/s]\n",
            "Downloading shards:  50% 1/2 [01:00<01:00, 60.07s/it]\n",
            "model-00002-of-00002.safetensors:   0% 0.00/3.50G [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   1% 31.5M/3.50G [00:00<00:14, 247MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   2% 62.9M/3.50G [00:03<04:09, 13.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   3% 94.4M/3.50G [00:04<02:19, 24.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   3% 115M/3.50G [00:04<01:43, 32.6MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:   4% 136M/3.50G [00:04<01:21, 41.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   5% 168M/3.50G [00:04<00:55, 60.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   6% 199M/3.50G [00:04<00:40, 81.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   7% 231M/3.50G [00:04<00:31, 105MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:   7% 252M/3.50G [00:04<00:27, 117MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   8% 283M/3.50G [00:05<00:22, 141MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   9% 315M/3.50G [00:05<00:19, 162MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  10% 346M/3.50G [00:05<00:17, 180MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  11% 377M/3.50G [00:05<00:15, 197MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  12% 409M/3.50G [00:05<00:14, 211MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  13% 440M/3.50G [00:05<00:13, 220MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  13% 472M/3.50G [00:05<00:13, 225MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  14% 503M/3.50G [00:05<00:12, 233MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  15% 535M/3.50G [00:06<00:12, 237MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  16% 566M/3.50G [00:06<00:12, 242MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  17% 598M/3.50G [00:06<00:11, 246MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  18% 629M/3.50G [00:06<00:11, 245MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  19% 661M/3.50G [00:06<00:11, 243MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  20% 692M/3.50G [00:06<00:11, 236MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  21% 724M/3.50G [00:06<00:11, 243MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  22% 755M/3.50G [00:06<00:11, 238MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  22% 786M/3.50G [00:07<00:11, 239MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  23% 818M/3.50G [00:07<00:11, 241MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  24% 849M/3.50G [00:07<00:10, 250MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  25% 881M/3.50G [00:07<00:11, 234MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  26% 912M/3.50G [00:07<00:11, 233MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  27% 944M/3.50G [00:07<00:10, 240MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  28% 975M/3.50G [00:07<00:10, 241MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  29% 1.01G/3.50G [00:08<00:10, 236MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  30% 1.04G/3.50G [00:08<00:11, 223MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  31% 1.07G/3.50G [00:08<00:11, 220MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  31% 1.10G/3.50G [00:08<00:10, 229MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  32% 1.13G/3.50G [00:08<00:09, 241MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  33% 1.16G/3.50G [00:08<00:09, 247MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  34% 1.20G/3.50G [00:08<00:09, 235MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  35% 1.23G/3.50G [00:09<00:10, 227MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  36% 1.26G/3.50G [00:09<00:09, 233MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  37% 1.29G/3.50G [00:09<00:09, 243MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  38% 1.32G/3.50G [00:09<00:08, 251MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  39% 1.35G/3.50G [00:09<00:08, 246MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  40% 1.38G/3.50G [00:09<00:10, 206MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  40% 1.42G/3.50G [00:09<00:10, 198MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  41% 1.45G/3.50G [00:10<00:09, 207MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  42% 1.48G/3.50G [00:10<00:09, 211MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  43% 1.51G/3.50G [00:10<00:08, 227MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  44% 1.54G/3.50G [00:10<00:08, 229MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  45% 1.57G/3.50G [00:10<00:08, 227MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  46% 1.60G/3.50G [00:10<00:08, 235MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  47% 1.64G/3.50G [00:10<00:08, 228MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  48% 1.67G/3.50G [00:10<00:08, 225MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  49% 1.70G/3.50G [00:11<00:07, 229MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  49% 1.73G/3.50G [00:11<00:08, 221MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  50% 1.76G/3.50G [00:11<00:08, 215MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  51% 1.79G/3.50G [00:11<00:07, 216MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  52% 1.82G/3.50G [00:13<00:40, 41.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  53% 1.86G/3.50G [00:13<00:30, 54.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  54% 1.88G/3.50G [00:14<00:34, 46.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  55% 1.91G/3.50G [00:14<00:25, 63.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  55% 1.94G/3.50G [00:14<00:19, 81.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  56% 1.96G/3.50G [00:14<00:16, 93.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  57% 1.98G/3.50G [00:15<00:14, 105MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  57% 2.00G/3.50G [00:15<00:12, 118MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  58% 2.03G/3.50G [00:15<00:10, 145MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  59% 2.07G/3.50G [00:15<00:08, 168MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  60% 2.10G/3.50G [00:15<00:07, 187MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  61% 2.13G/3.50G [00:15<00:06, 203MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  62% 2.16G/3.50G [00:15<00:06, 202MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  63% 2.19G/3.50G [00:16<00:07, 179MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  64% 2.22G/3.50G [00:16<00:06, 190MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  64% 2.24G/3.50G [00:19<00:42, 29.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  65% 2.26G/3.50G [00:19<00:33, 36.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  65% 2.29G/3.50G [00:19<00:26, 45.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  66% 2.31G/3.50G [00:19<00:20, 57.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  67% 2.33G/3.50G [00:19<00:16, 70.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  67% 2.36G/3.50G [00:19<00:11, 96.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  68% 2.39G/3.50G [00:19<00:09, 123MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  69% 2.42G/3.50G [00:19<00:07, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  70% 2.45G/3.50G [00:20<00:06, 158MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  71% 2.49G/3.50G [00:20<00:05, 175MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  72% 2.52G/3.50G [00:20<00:06, 162MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  73% 2.55G/3.50G [00:20<00:05, 182MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  74% 2.58G/3.50G [00:20<00:04, 203MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  75% 2.61G/3.50G [00:20<00:04, 207MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  75% 2.64G/3.50G [00:20<00:03, 215MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  76% 2.67G/3.50G [00:21<00:03, 222MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  77% 2.71G/3.50G [00:21<00:03, 220MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  78% 2.74G/3.50G [00:21<00:03, 228MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  79% 2.77G/3.50G [00:21<00:03, 221MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  80% 2.80G/3.50G [00:21<00:03, 227MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  81% 2.83G/3.50G [00:21<00:02, 229MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  82% 2.86G/3.50G [00:21<00:02, 240MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  83% 2.89G/3.50G [00:22<00:02, 241MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  84% 2.93G/3.50G [00:22<00:02, 243MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  84% 2.96G/3.50G [00:22<00:02, 240MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  85% 2.99G/3.50G [00:22<00:02, 241MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  86% 3.02G/3.50G [00:22<00:01, 241MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  87% 3.05G/3.50G [00:22<00:01, 244MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  88% 3.08G/3.50G [00:22<00:01, 246MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  89% 3.11G/3.50G [00:22<00:01, 246MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  90% 3.15G/3.50G [00:23<00:01, 247MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  91% 3.18G/3.50G [00:23<00:01, 252MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  92% 3.21G/3.50G [00:23<00:01, 250MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  93% 3.24G/3.50G [00:23<00:01, 250MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  93% 3.27G/3.50G [00:23<00:00, 250MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  94% 3.30G/3.50G [00:23<00:00, 255MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  95% 3.33G/3.50G [00:23<00:00, 259MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  96% 3.37G/3.50G [00:23<00:00, 262MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  97% 3.40G/3.50G [00:24<00:00, 264MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  98% 3.43G/3.50G [00:24<00:00, 268MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  99% 3.46G/3.50G [00:24<00:00, 272MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 3.50G/3.50G [00:24<00:00, 143MB/s]\n",
            "Downloading shards: 100% 2/2 [01:24<00:00, 42.28s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [01:08<00:00, 34.25s/it]\n",
            "generation_config.json: 100% 188/188 [00:00<00:00, 993kB/s]\n",
            "tokenizer_config.json: 100% 776/776 [00:00<00:00, 4.91MB/s]\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 446MB/s]\n",
            "tokenizer.json: 100% 1.84M/1.84M [00:00<00:00, 32.6MB/s]\n",
            "special_tokens_map.json: 100% 414/414 [00:00<00:00, 3.10MB/s]\n",
            "Lenght of train: 3838\n",
            "Lenght of valid: 548\n",
            "Train indices: [\n",
            "    [\n",
            "        100,\n",
            "        85\n",
            "    ],\n",
            "    [\n",
            "        102,\n",
            "        86\n",
            "    ],\n",
            "    [\n",
            "        89,\n",
            "        106\n",
            "    ],\n",
            "    [\n",
            "        85,\n",
            "        100,\n",
            "        2262,\n",
            "        2189\n",
            "    ],\n",
            "    [\n",
            "        102,\n",
            "        2267,\n",
            "        2192,\n",
            "        86\n",
            "    ],\n",
            "    [\n",
            "        89,\n",
            "        3811,\n",
            "        3817,\n",
            "        106\n",
            "    ],\n",
            "    [\n",
            "        2262,\n",
            "        2401,\n",
            "        100,\n",
            "        2436,\n",
            "        85,\n",
            "        2189\n",
            "    ],\n",
            "    [\n",
            "        86,\n",
            "        102,\n",
            "        3811,\n",
            "        3817,\n",
            "        423,\n",
            "        480\n",
            "    ],\n",
            "    [\n",
            "        288,\n",
            "        580,\n",
            "        3620,\n",
            "        658,\n",
            "        3595,\n",
            "        271\n",
            "    ],\n",
            "    [\n",
            "        354,\n",
            "        2436,\n",
            "        2262,\n",
            "        418,\n",
            "        2401,\n",
            "        85,\n",
            "        2189,\n",
            "        100\n",
            "    ],\n",
            "    [\n",
            "        102,\n",
            "        420,\n",
            "        3811,\n",
            "        482,\n",
            "        424,\n",
            "        86,\n",
            "        359,\n",
            "        3817\n",
            "    ],\n",
            "    [\n",
            "        288,\n",
            "        572,\n",
            "        3662,\n",
            "        583,\n",
            "        663,\n",
            "        507,\n",
            "        3677,\n",
            "        271\n",
            "    ],\n",
            "    [\n",
            "        2189,\n",
            "        2457,\n",
            "        2401,\n",
            "        793,\n",
            "        100,\n",
            "        85,\n",
            "        2262,\n",
            "        2436,\n",
            "        418,\n",
            "        2426,\n",
            "        354,\n",
            "        685\n",
            "    ],\n",
            "    [\n",
            "        407,\n",
            "        657,\n",
            "        3191,\n",
            "        3625,\n",
            "        3596,\n",
            "        502,\n",
            "        3262,\n",
            "        346,\n",
            "        270,\n",
            "        561,\n",
            "        578,\n",
            "        287\n",
            "    ],\n",
            "    [\n",
            "        2534,\n",
            "        572,\n",
            "        3727,\n",
            "        2568,\n",
            "        3265,\n",
            "        409,\n",
            "        288,\n",
            "        3721,\n",
            "        271,\n",
            "        507,\n",
            "        3197,\n",
            "        348\n",
            "    ]\n",
            "]\n",
            "\n",
            "Number of parameter combinations: 15 \n",
            "\n",
            "[{'few_shot_sample_indices': [100, 85]}, {'few_shot_sample_indices': [102, 86]}, {'few_shot_sample_indices': [89, 106]}, {'few_shot_sample_indices': [85, 100, 2262, 2189]}, {'few_shot_sample_indices': [102, 2267, 2192, 86]}, {'few_shot_sample_indices': [89, 3811, 3817, 106]}, {'few_shot_sample_indices': [2262, 2401, 100, 2436, 85, 2189]}, {'few_shot_sample_indices': [86, 102, 3811, 3817, 423, 480]}, {'few_shot_sample_indices': [288, 580, 3620, 658, 3595, 271]}, {'few_shot_sample_indices': [354, 2436, 2262, 418, 2401, 85, 2189, 100]}, {'few_shot_sample_indices': [102, 420, 3811, 482, 424, 86, 359, 3817]}, {'few_shot_sample_indices': [288, 572, 3662, 583, 663, 507, 3677, 271]}, {'few_shot_sample_indices': [2189, 2457, 2401, 793, 100, 85, 2262, 2436, 418, 2426, 354, 685]}, {'few_shot_sample_indices': [407, 657, 3191, 3625, 3596, 502, 3262, 346, 270, 561, 578, 287]}, {'few_shot_sample_indices': [2534, 572, 3727, 2568, 3265, 409, 288, 3721, 271, 507, 3197, 348]}]\n",
            "\n",
            "Current few-shot sample: 1 / 15\n",
            "Prompt 0: Sentence: The current junior team members missed out on Minkey , which began last year , but they did benefit from Olympic profits in the form of a one - time $ 1.2 million payment disbursed by the U.S. Olympic Committee\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: On the Cadillac Eldorado convertibles , water or melting snow dripping onto the window switch assembly when the driver 's door is open could cause an electrical short\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: Federal prosecutors in Texas , California and Florida are particularly burdened with bank fraud investigations , many targeting savings and loans that failed after speculative lending binges\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: \n",
            "Completion 0:  no \n",
            "\n",
            "\n",
            "Accuracy: 0.5\n",
            "F1 score: 0.4981684981684981\n",
            "Precision: 0.5\n",
            "Recall: 0.49635036496350365\n",
            "\n",
            "\n",
            "Current few-shot sample: 2 / 15\n",
            "Prompt 0: Sentence: - - In Texas , another must - win state , the Democratic Party has increased its planned spending to nearly $ 5 million for the inglorious work of knocking on doors and telephoning voters\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: Eastern 's cutbacks have benefited Continental in other ways , the affidavit claims: Roughly 4 % of Eastern 's flying capacity competes with Continental , it says , compared with 9.3 % in January 1987\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: Federal prosecutors in Texas , California and Florida are particularly burdened with bank fraud investigations , many targeting savings and loans that failed after speculative lending binges\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: \n",
            "Completion 0:  no \n",
            "\n",
            "\n",
            "Accuracy: 0.5036496350364964\n",
            "F1 score: 0.23163841807909605\n",
            "Precision: 0.5125\n",
            "Recall: 0.14963503649635038\n",
            "\n",
            "\n",
            "Current few-shot sample: 3 / 15\n",
            "Prompt 0: Sentence: Sparrows used to have a rep for selectively attacking yellow crocuses such as `` E.A\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: A similar regulation in New York was knocked out in court and another court fight is under way in Massachusetts\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: Federal prosecutors in Texas , California and Florida are particularly burdened with bank fraud investigations , many targeting savings and loans that failed after speculative lending binges\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: \n",
            "Completion 0:  yes \n",
            "\n",
            "\n",
            "Accuracy: 0.5364963503649635\n",
            "F1 score: 0.5916398713826366\n",
            "Precision: 0.5287356321839081\n",
            "Recall: 0.6715328467153284\n",
            "\n",
            "\n",
            "Current few-shot sample: 4 / 15\n",
            "Prompt 0: Sentence: On the Cadillac Eldorado convertibles , water or melting snow dripping onto the window switch assembly when the driver 's door is open could cause an electrical short\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: The current junior team members missed out on Minkey , which began last year , but they did benefit from Olympic profits in the form of a one - time $ 1.2 million payment disbursed by the U.S. Olympic Committee\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: About that time , the hog breeder stumbled across a body - building magazine with an article about the digestive system , which he found similar to that of a pig\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: `` The area is so blighted , no one wants to lend me anything , '' Mr. Gray says\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: Federal prosecutors in Texas , California and Florida are particularly burdened with bank fraud investigations , many targeting savings and loans that failed after speculative lending binges\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: \n",
            "Completion 0:  no \n",
            "\n",
            "\n",
            "Accuracy: 0.4908759124087591\n",
            "F1 score: 0.3586206896551724\n",
            "Precision: 0.484472049689441\n",
            "Recall: 0.2846715328467153\n",
            "\n",
            "\n",
            "Current few-shot sample: 5 / 15\n",
            "Prompt 0: Sentence: - - In Texas , another must - win state , the Democratic Party has increased its planned spending to nearly $ 5 million for the inglorious work of knocking on doors and telephoning voters\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: Soybean farmers are n't eligible for the program and the government already prevents 0 - 92 participants from planting soybeans on idled acreage\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: Revelers jam the Uzbekistan , dancing madly under flashing lights to the shriek of a Soviet synthesizer\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: Eastern 's cutbacks have benefited Continental in other ways , the affidavit claims: Roughly 4 % of Eastern 's flying capacity competes with Continental , it says , compared with 9.3 % in January 1987\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: Federal prosecutors in Texas , California and Florida are particularly burdened with bank fraud investigations , many targeting savings and loans that failed after speculative lending binges\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: \n",
            "Completion 0:  no \n",
            "\n",
            "\n",
            "Accuracy: 0.5218978102189781\n",
            "F1 score: 0.4696356275303643\n",
            "Precision: 0.5272727272727272\n",
            "Recall: 0.4233576642335766\n",
            "\n",
            "\n",
            "Current few-shot sample: 6 / 15\n",
            "Prompt 0: Sentence: Sparrows used to have a rep for selectively attacking yellow crocuses such as `` E.A\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: Last week , the company said it was ready to enter bankruptcy court to avoid complying with the federal order to pump holding company assets into its troubled banks\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: One person was killed - - an engineer on one of the trains\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: A similar regulation in New York was knocked out in court and another court fight is under way in Massachusetts\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: Federal prosecutors in Texas , California and Florida are particularly burdened with bank fraud investigations , many targeting savings and loans that failed after speculative lending binges\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: \n",
            "Completion 0:  no \n",
            "\n",
            "\n",
            "Accuracy: 0.49635036496350365\n",
            "F1 score: 0.08609271523178808\n",
            "Precision: 0.4642857142857143\n",
            "Recall: 0.04744525547445255\n",
            "\n",
            "\n",
            "Current few-shot sample: 7 / 15\n",
            "Prompt 0: Sentence: About that time , the hog breeder stumbled across a body - building magazine with an article about the digestive system , which he found similar to that of a pig\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: I 'm afraid I might somehow take a loss ! `` says Korobochka , a pig - headed woman struggling , in the best scene of the opera , to understand why the stranger is offering her money for a serf who drank so heavily that he exploded\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: The current junior team members missed out on Minkey , which began last year , but they did benefit from Olympic profits in the form of a one - time $ 1.2 million payment disbursed by the U.S. Olympic Committee\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: Mr. Tyson was in London on business and had to fly back this weekend\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: On the Cadillac Eldorado convertibles , water or melting snow dripping onto the window switch assembly when the driver 's door is open could cause an electrical short\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: `` The area is so blighted , no one wants to lend me anything , '' Mr. Gray says\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: Federal prosecutors in Texas , California and Florida are particularly burdened with bank fraud investigations , many targeting savings and loans that failed after speculative lending binges\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: \n",
            "Completion 0:  no \n",
            "\n",
            "\n",
            "Accuracy: 0.5018248175182481\n",
            "F1 score: 0.3781321184510251\n",
            "Precision: 0.503030303030303\n",
            "Recall: 0.3029197080291971\n",
            "\n",
            "\n",
            "Current few-shot sample: 8 / 15\n",
            "Prompt 0: Sentence: Eastern 's cutbacks have benefited Continental in other ways , the affidavit claims: Roughly 4 % of Eastern 's flying capacity competes with Continental , it says , compared with 9.3 % in January 1987\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: - - In Texas , another must - win state , the Democratic Party has increased its planned spending to nearly $ 5 million for the inglorious work of knocking on doors and telephoning voters\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: Last week , the company said it was ready to enter bankruptcy court to avoid complying with the federal order to pump holding company assets into its troubled banks\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: One person was killed - - an engineer on one of the trains\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: For 100 years Wyoming has been riding a roller coaster\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: More than one - third of smokers said they never ate breakfast , compared with 18 % of those who had never smoked\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: Federal prosecutors in Texas , California and Florida are particularly burdened with bank fraud investigations , many targeting savings and loans that failed after speculative lending binges\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: \n",
            "Completion 0:  no \n",
            "\n",
            "\n",
            "Accuracy: 0.5145985401459854\n",
            "F1 score: 0.29255319148936165\n",
            "Precision: 0.5392156862745098\n",
            "Recall: 0.20072992700729927\n",
            "\n",
            "\n",
            "Current few-shot sample: 9 / 15\n",
            "Prompt 0: Sentence: Sir Geoffrey Howe , the British foreign secretary , told a radio interviewer this week: `` We are not rushing in , pouring money down their throats , but seeking good business opportunities at the same time as pressing them to change their system .\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: After destroying two platforms , the Iranian gunboat the Joshan mounted a failed assault on the Navy ships and was quickly sunk\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: For an auto , Mr. Loehrke envisions the warm end of the pipe heated by the radiator and the condenser end cooled by the outside air\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: Sometimes it stumbled\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: But he did say that `` there are no heads that are going to roll .\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: A Soviet Foreign Ministry aide disputed claims by U.S. officials that an explosion last week destroyed the only plant producing rocket fuel for SS - 24 intercontinental missiles\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: Federal prosecutors in Texas , California and Florida are particularly burdened with bank fraud investigations , many targeting savings and loans that failed after speculative lending binges\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: \n",
            "Completion 0:  no \n",
            "\n",
            "\n",
            "Accuracy: 0.5018248175182481\n",
            "F1 score: 0.5063291139240507\n",
            "Precision: 0.5017921146953405\n",
            "Recall: 0.5109489051094891\n",
            "\n",
            "\n",
            "Current few-shot sample: 10 / 15\n",
            "Prompt 0: Sentence: Companies still spend billions of dollars printing and storing forms - - - and destroying them when , say , an address changes\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: Mr. Tyson was in London on business and had to fly back this weekend\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: About that time , the hog breeder stumbled across a body - building magazine with an article about the digestive system , which he found similar to that of a pig\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: `` Ten years ago , it was enough to latch onto something 100 % proven , '' says Shoji Kumagai , general manager of technical development at giant Sumitomo Corp . `` Today we have to grab it at the idea stage .\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: I 'm afraid I might somehow take a loss ! `` says Korobochka , a pig - headed woman struggling , in the best scene of the opera , to understand why the stranger is offering her money for a serf who drank so heavily that he exploded\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: On the Cadillac Eldorado convertibles , water or melting snow dripping onto the window switch assembly when the driver 's door is open could cause an electrical short\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: `` The area is so blighted , no one wants to lend me anything , '' Mr. Gray says\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: The current junior team members missed out on Minkey , which began last year , but they did benefit from Olympic profits in the form of a one - time $ 1.2 million payment disbursed by the U.S. Olympic Committee\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: Federal prosecutors in Texas , California and Florida are particularly burdened with bank fraud investigations , many targeting savings and loans that failed after speculative lending binges\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: \n",
            "Completion 0:  no \n",
            "\n",
            "\n",
            "Accuracy: 0.5018248175182481\n",
            "F1 score: 0.048780487804878044\n",
            "Precision: 0.5384615384615384\n",
            "Recall: 0.025547445255474453\n",
            "\n",
            "\n",
            "Current few-shot sample: 11 / 15\n",
            "Prompt 0: Sentence: - - In Texas , another must - win state , the Democratic Party has increased its planned spending to nearly $ 5 million for the inglorious work of knocking on doors and telephoning voters\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: If she had not been struck , as a woman , by the grotesque exudations streaming from the temporal glands and four - foot , S - shaped penises of certain adult male elephants , would she have been led to identify this `` disease '' as musth , the sexual frenzy of male estrus never before documented in African elephants ?/.\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: Last week , the company said it was ready to enter bankruptcy court to avoid complying with the federal order to pump holding company assets into its troubled banks\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: People close to Black & Decker , which had raised its bid two weeks ago from its initial $ 56 - a - share offer , said the company will probably stick to its latest offer\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: Some police forces , for example , have stepped up use of a 20 - year - old system called Vascar - LRB - Vehicle and Speed Computed and Recorded - RRB -\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: Eastern 's cutbacks have benefited Continental in other ways , the affidavit claims: Roughly 4 % of Eastern 's flying capacity competes with Continental , it says , compared with 9.3 % in January 1987\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: One lamenter of impeccable credentials is Peter G. Peterson , who in a recent Atlantic complains that we have let our infrastructure crumble , our productivity dwindle , our savings evaporate and our foreign markets dwindle\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: One person was killed - - an engineer on one of the trains\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: Federal prosecutors in Texas , California and Florida are particularly burdened with bank fraud investigations , many targeting savings and loans that failed after speculative lending binges\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: \n",
            "Completion 0:  no \n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Accuracy: 0.5\n",
            "F1 score: 0.0\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "\n",
            "\n",
            "Current few-shot sample: 12 / 15\n",
            "Prompt 0: Sentence: Sir Geoffrey Howe , the British foreign secretary , told a radio interviewer this week: `` We are not rushing in , pouring money down their throats , but seeking good business opportunities at the same time as pressing them to change their system .\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: The great 19th - century classics , which she danced in her prime , are beyond her present physical capacities\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: Centralization , on the other hand , kills motivation and crushes the human spirit\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: Two motorcycles , nine cars and vans , and two buses are rolling resolutely to the next stop , the Regency Shopping Mall next door to a muffler shop - - and , please , we already thought of the `` Midasize him ! `` line\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: Whether or not Drexel or the partnership was involved in any wrongdoing , how such suspicious trading escaped serious scrutiny is a story of regulatory ineptitude\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: The real estate division , which reports to Mr. Brown , has also lost seasoned leadership at a time when it has been aggressively lending to developers\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: It will be interesting to observe in Atlanta whether the party 's hardest - working left - wing activists stand by Jesse Jackson , or throw him over to ride the Dukakis train toward the White House\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: A Soviet Foreign Ministry aide disputed claims by U.S. officials that an explosion last week destroyed the only plant producing rocket fuel for SS - 24 intercontinental missiles\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: Federal prosecutors in Texas , California and Florida are particularly burdened with bank fraud investigations , many targeting savings and loans that failed after speculative lending binges\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: \n",
            "Completion 0:  no \n",
            "\n",
            "\n",
            "Accuracy: 0.4854014598540146\n",
            "F1 score: 0.2617801047120419\n",
            "Precision: 0.46296296296296297\n",
            "Recall: 0.18248175182481752\n",
            "\n",
            "\n",
            "Current few-shot sample: 13 / 15\n",
            "Prompt 0: Sentence: `` The area is so blighted , no one wants to lend me anything , '' Mr. Gray says\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: `` I hope this puts to rest the phony controversy which you have manufactured , '' Mr. Forstmann 's letter concluded\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: I 'm afraid I might somehow take a loss ! `` says Korobochka , a pig - headed woman struggling , in the best scene of the opera , to understand why the stranger is offering her money for a serf who drank so heavily that he exploded\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: MORTGAGE SUBSIDIES would be targeted to more of the needy\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: The current junior team members missed out on Minkey , which began last year , but they did benefit from Olympic profits in the form of a one - time $ 1.2 million payment disbursed by the U.S. Olympic Committee\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: On the Cadillac Eldorado convertibles , water or melting snow dripping onto the window switch assembly when the driver 's door is open could cause an electrical short\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: About that time , the hog breeder stumbled across a body - building magazine with an article about the digestive system , which he found similar to that of a pig\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: Mr. Tyson was in London on business and had to fly back this weekend\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: `` Ten years ago , it was enough to latch onto something 100 % proven , '' says Shoji Kumagai , general manager of technical development at giant Sumitomo Corp . `` Today we have to grab it at the idea stage .\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: Northrop 's money was supposed to help build a hotel , but the project was never begun and the funds are missing\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: Companies still spend billions of dollars printing and storing forms - - - and destroying them when , say , an address changes\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: Congress has kicked around a bill to strike a palladium coin , but it has n't generated much support\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: Federal prosecutors in Texas , California and Florida are particularly burdened with bank fraud investigations , many targeting savings and loans that failed after speculative lending binges\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: \n",
            "Completion 0:  no \n",
            "\n",
            "\n",
            "Accuracy: 0.46715328467153283\n",
            "F1 score: 0.3209302325581395\n",
            "Precision: 0.4423076923076923\n",
            "Recall: 0.2518248175182482\n",
            "\n",
            "\n",
            "Current few-shot sample: 14 / 15\n",
            "Prompt 0: Sentence: U.S. drug agents estimate that about 40 % of all the cocaine and marijuana pouring into America comes through the Bahamas ; of that , at times as much as half may have been run through Bimini , agents say\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: Finding such a fecund gold field came as a surprise to Reynolds , which stumbled across the precious metal when it was looking for bauxite , a claylike substance that holds alumina , the basic ingredient in aluminum ingot\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: Although some executives who lose their jobs may be dead wood truly deserving the ax , the fear thus engendered even in able officials may encourage them to grab for excessive compensation\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: `` This will fill out the labor agenda and the political agenda\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: The move struck some analysts as an interim one because of Mr. Thomas 's age and background\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: Alain Minc , Patrick Ponsolle and Maurice Lippens were flying from Paris to Brussels last Monday night when they uncorked a bottle of warm champagne and toasted the future of Societe Generale de Belgique S.A . , the giant Belgian holding company\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: News of the bid knocked Philip Morris stock down 4 1 2 points Tuesday and 1 1 2 yesterday to 94 , as analysts forecast the deal would reduce per - share earnings next year by anywhere from 40 cents to $ 1.50\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: The market pulled back during the afternoon amid profit - taking , traders said , and then began a fullscale retreat as buying interest evaporated\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: Led by the Workers ' Party and the Singapore Democratic Party , the opposition narrowly missed winning several more seats and trimmed the PAP 's portion of the popular vote by 1.1 percentage point to 61.8 % , the ruling party 's smallest total in six national elections since independence\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: By the 17th century , fashion had replaced utility , and cavalier Frenchmen donned ornate linen and lace cravats , knotted in the center with long flowing ends that accented their moustaches\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: Ad agency J. Walter Thompson Co . , moving to fill what is widely viewed as a critical management gap , hired a senior executive from rival Omnicom Group Inc. to become its top financial officer\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: An example: Last fall , Joseph Biden 's campaign was destroyed after a leaked videotape showed similarities between his speech and one given by British Labor Party leader Neil Kinnock\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: Federal prosecutors in Texas , California and Florida are particularly burdened with bank fraud investigations , many targeting savings and loans that failed after speculative lending binges\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: \n",
            "Completion 0:  no \n",
            "\n",
            "\n",
            "Accuracy: 0.5\n",
            "F1 score: 0.007246376811594202\n",
            "Precision: 0.5\n",
            "Recall: 0.0036496350364963502\n",
            "\n",
            "\n",
            "Current few-shot sample: 15 / 15\n",
            "Prompt 0: Sentence: THE NEW YORK OFFICES of Simulations Publications Inc. looked like a poorly financed college fraternity house: shabby furniture , maze - like corridors , rooms filled with mountains of paper\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: The great 19th - century classics , which she danced in her prime , are beyond her present physical capacities\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: Mr. Trudeau so enraged the vice president four years ago that Mr. Bush threatened to kick him in an appropriate place\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: Mr. Quinn , however , is stepping aside as president of Gannett News Service\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: The suit , filed against the unions representing pilots and machinists , stepped up the war over Eastern 's labor costs that has raged through the company , the Congress and the courts for more than a year\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: Last week after months of litigation , the company was officially dissolved , and the trademark was sold for $ 8 million to a Stamford , Conn . , investment firm\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: Sir Geoffrey Howe , the British foreign secretary , told a radio interviewer this week: `` We are not rushing in , pouring money down their throats , but seeking good business opportunities at the same time as pressing them to change their system .\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: In addition , the new classes often are difficult to grasp\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: A Soviet Foreign Ministry aide disputed claims by U.S. officials that an explosion last week destroyed the only plant producing rocket fuel for SS - 24 intercontinental missiles\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: The real estate division , which reports to Mr. Brown , has also lost seasoned leadership at a time when it has been aggressively lending to developers\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: The Washington - based NASD , which runs the Nasdaq , its automated quotations , over - the - counter stock market , was flooded with phone calls about its new requirement that any firm dealing in low - priced or lightly traded stocks quoted in the Pink Sheets report volume and price data in issues in which its aggregate activity exceeds 50 , 000 shares or $ 10 , 000\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: Elsewhere , the nation 's worst drought in a half - century may be searing crops and withering dreams , but farmers here on the High Plains and in a handful of other spots around the nation where rain is plentiful are rediscovering the truism that clouds can have silver linings\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: Federal prosecutors in Texas , California and Florida are particularly burdened with bank fraud investigations , many targeting savings and loans that failed after speculative lending binges\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: \n",
            "Completion 0:  no \n",
            "\n",
            "\n",
            "Accuracy: 0.49635036496350365\n",
            "F1 score: 0.014285714285714285\n",
            "Precision: 0.3333333333333333\n",
            "Recall: 0.0072992700729927005\n",
            "\n",
            "Validation results: [\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.5,\n",
            "        \"f1\": 0.4981684981684981,\n",
            "        \"precision\": 0.5,\n",
            "        \"recall\": 0.49635036496350365,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            100,\n",
            "            85\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"trofi\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.5036496350364964,\n",
            "        \"f1\": 0.23163841807909605,\n",
            "        \"precision\": 0.5125,\n",
            "        \"recall\": 0.14963503649635038,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            102,\n",
            "            86\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"trofi\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.5364963503649635,\n",
            "        \"f1\": 0.5916398713826366,\n",
            "        \"precision\": 0.5287356321839081,\n",
            "        \"recall\": 0.6715328467153284,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            89,\n",
            "            106\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"trofi\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.4908759124087591,\n",
            "        \"f1\": 0.3586206896551724,\n",
            "        \"precision\": 0.484472049689441,\n",
            "        \"recall\": 0.2846715328467153,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            85,\n",
            "            100,\n",
            "            2262,\n",
            "            2189\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"trofi\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.5218978102189781,\n",
            "        \"f1\": 0.4696356275303643,\n",
            "        \"precision\": 0.5272727272727272,\n",
            "        \"recall\": 0.4233576642335766,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            102,\n",
            "            2267,\n",
            "            2192,\n",
            "            86\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"trofi\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.49635036496350365,\n",
            "        \"f1\": 0.08609271523178808,\n",
            "        \"precision\": 0.4642857142857143,\n",
            "        \"recall\": 0.04744525547445255,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            89,\n",
            "            3811,\n",
            "            3817,\n",
            "            106\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"trofi\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.5018248175182481,\n",
            "        \"f1\": 0.3781321184510251,\n",
            "        \"precision\": 0.503030303030303,\n",
            "        \"recall\": 0.3029197080291971,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            2262,\n",
            "            2401,\n",
            "            100,\n",
            "            2436,\n",
            "            85,\n",
            "            2189\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"trofi\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.5145985401459854,\n",
            "        \"f1\": 0.29255319148936165,\n",
            "        \"precision\": 0.5392156862745098,\n",
            "        \"recall\": 0.20072992700729927,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            86,\n",
            "            102,\n",
            "            3811,\n",
            "            3817,\n",
            "            423,\n",
            "            480\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"trofi\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.5018248175182481,\n",
            "        \"f1\": 0.5063291139240507,\n",
            "        \"precision\": 0.5017921146953405,\n",
            "        \"recall\": 0.5109489051094891,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            288,\n",
            "            580,\n",
            "            3620,\n",
            "            658,\n",
            "            3595,\n",
            "            271\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"trofi\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.5018248175182481,\n",
            "        \"f1\": 0.048780487804878044,\n",
            "        \"precision\": 0.5384615384615384,\n",
            "        \"recall\": 0.025547445255474453,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            354,\n",
            "            2436,\n",
            "            2262,\n",
            "            418,\n",
            "            2401,\n",
            "            85,\n",
            "            2189,\n",
            "            100\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"trofi\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.5,\n",
            "        \"f1\": 0.0,\n",
            "        \"precision\": 0.0,\n",
            "        \"recall\": 0.0,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            102,\n",
            "            420,\n",
            "            3811,\n",
            "            482,\n",
            "            424,\n",
            "            86,\n",
            "            359,\n",
            "            3817\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"trofi\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.4854014598540146,\n",
            "        \"f1\": 0.2617801047120419,\n",
            "        \"precision\": 0.46296296296296297,\n",
            "        \"recall\": 0.18248175182481752,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            288,\n",
            "            572,\n",
            "            3662,\n",
            "            583,\n",
            "            663,\n",
            "            507,\n",
            "            3677,\n",
            "            271\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"trofi\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.46715328467153283,\n",
            "        \"f1\": 0.3209302325581395,\n",
            "        \"precision\": 0.4423076923076923,\n",
            "        \"recall\": 0.2518248175182482,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            2189,\n",
            "            2457,\n",
            "            2401,\n",
            "            793,\n",
            "            100,\n",
            "            85,\n",
            "            2262,\n",
            "            2436,\n",
            "            418,\n",
            "            2426,\n",
            "            354,\n",
            "            685\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"trofi\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.5,\n",
            "        \"f1\": 0.007246376811594202,\n",
            "        \"precision\": 0.5,\n",
            "        \"recall\": 0.0036496350364963502,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            407,\n",
            "            657,\n",
            "            3191,\n",
            "            3625,\n",
            "            3596,\n",
            "            502,\n",
            "            3262,\n",
            "            346,\n",
            "            270,\n",
            "            561,\n",
            "            578,\n",
            "            287\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"trofi\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.49635036496350365,\n",
            "        \"f1\": 0.014285714285714285,\n",
            "        \"precision\": 0.3333333333333333,\n",
            "        \"recall\": 0.0072992700729927005,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            2534,\n",
            "            572,\n",
            "            3727,\n",
            "            2568,\n",
            "            3265,\n",
            "            409,\n",
            "            288,\n",
            "            3721,\n",
            "            271,\n",
            "            507,\n",
            "            3197,\n",
            "            348\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"trofi\"\n",
            "    }\n",
            "]\n",
            "\n",
            "Lenght of test: 1096\n",
            "Getting completions...\n",
            "Prompt 0: Sentence: Sparrows used to have a rep for selectively attacking yellow crocuses such as `` E.A\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: no\n",
            "Sentence: A similar regulation in New York was knocked out in court and another court fight is under way in Massachusetts\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: yes\n",
            "Sentence: Jeremy says he spends every night of the week at the mall , where he usually eats dinner\n",
            "Question: Is the sentence metaphoric?\n",
            "Answer: \n",
            "Completion 0:  no \n",
            "\n",
            "\n",
            "Evaluating test set performance...\n",
            "Accuracy: 0.5611313868613139\n",
            "F1 score: 0.6148919135308247\n",
            "Precision: 0.5477888730385164\n",
            "Recall: 0.7007299270072993\n",
            "\n",
            "Test results: {\n",
            "    \"model\": \"llama2-7b\",\n",
            "    \"acc\": 0.5611313868613139,\n",
            "    \"f1\": 0.6148919135308247,\n",
            "    \"precision\": 0.5477888730385164,\n",
            "    \"recall\": 0.7007299270072993,\n",
            "    \"few_shot_sample_indices\": [\n",
            "        89,\n",
            "        106\n",
            "    ],\n",
            "    \"few_shot_samples\": 2,\n",
            "    \"temperature\": 0.0,\n",
            "    \"eval_split\": \"test\",\n",
            "    \"dataset_name\": \"trofi\",\n",
            "    \"fine_tuning\": false\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"$WORKDIR\" python -m src.main --llm llama2-7b --temperature 0 --dataset trofi --task classification --seed 1 --evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_bxDN61qi4b"
      },
      "source": [
        "## VUA POS - Metaphor classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-STlRVXu82op",
        "outputId": "16ea3511-7eff-477d-f5b1-abf9e75dd1a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-11-28 00:39:20.681784: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-28 00:39:20.681852: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-28 00:39:20.681894: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-28 00:39:22.422430: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "User is already logged in.\n",
            "\n",
            "llm: llama2-7b\n",
            "fine_tuned_model_path: None\n",
            "dataset: vua_pos\n",
            "task: classification\n",
            "temperature: 0.0\n",
            "seed: 1\n",
            "evaluate: True\n",
            "fine_tuning: False\n",
            "\n",
            "\n",
            "Loading checkpoint shards: 100% 2/2 [01:06<00:00, 33.44s/it]\n",
            "Lenght of train: 3506\n",
            "Lenght of valid: 502\n",
            "Train indices: [\n",
            "    [\n",
            "        2179,\n",
            "        2162\n",
            "    ],\n",
            "    [\n",
            "        2178,\n",
            "        2161\n",
            "    ],\n",
            "    [\n",
            "        3414,\n",
            "        3416\n",
            "    ],\n",
            "    [\n",
            "        2162,\n",
            "        2179,\n",
            "        1941,\n",
            "        1932\n",
            "    ],\n",
            "    [\n",
            "        3416,\n",
            "        3181,\n",
            "        3162,\n",
            "        3414\n",
            "    ],\n",
            "    [\n",
            "        3412,\n",
            "        3179,\n",
            "        3159,\n",
            "        3413\n",
            "    ],\n",
            "    [\n",
            "        1941,\n",
            "        89,\n",
            "        2179,\n",
            "        98,\n",
            "        2162,\n",
            "        1932\n",
            "    ],\n",
            "    [\n",
            "        3414,\n",
            "        3416,\n",
            "        3401,\n",
            "        3386,\n",
            "        92,\n",
            "        99\n",
            "    ],\n",
            "    [\n",
            "        3179,\n",
            "        2030,\n",
            "        94,\n",
            "        2026,\n",
            "        100,\n",
            "        3159\n",
            "    ],\n",
            "    [\n",
            "        3021,\n",
            "        98,\n",
            "        1941,\n",
            "        3057,\n",
            "        89,\n",
            "        2162,\n",
            "        1932,\n",
            "        2179\n",
            "    ],\n",
            "    [\n",
            "        3416,\n",
            "        624,\n",
            "        3181,\n",
            "        99,\n",
            "        92,\n",
            "        3414,\n",
            "        584,\n",
            "        3162\n",
            "    ],\n",
            "    [\n",
            "        3180,\n",
            "        627,\n",
            "        100,\n",
            "        2032,\n",
            "        2027,\n",
            "        587,\n",
            "        94,\n",
            "        3160\n",
            "    ],\n",
            "    [\n",
            "        1932,\n",
            "        550,\n",
            "        89,\n",
            "        1094,\n",
            "        2179,\n",
            "        2162,\n",
            "        1941,\n",
            "        98,\n",
            "        3057,\n",
            "        488,\n",
            "        3021,\n",
            "        1045\n",
            "    ],\n",
            "    [\n",
            "        1099,\n",
            "        2027,\n",
            "        2246,\n",
            "        92,\n",
            "        99,\n",
            "        585,\n",
            "        2285,\n",
            "        1053,\n",
            "        3162,\n",
            "        626,\n",
            "        2032,\n",
            "        3181\n",
            "    ],\n",
            "    [\n",
            "        3472,\n",
            "        3238,\n",
            "        2066,\n",
            "        3476,\n",
            "        3150,\n",
            "        828,\n",
            "        566,\n",
            "        2073,\n",
            "        508,\n",
            "        3211,\n",
            "        3116,\n",
            "        795\n",
            "    ]\n",
            "]\n",
            "\n",
            "Number of parameter combinations: 15 \n",
            "\n",
            "[{'few_shot_sample_indices': [2179, 2162]}, {'few_shot_sample_indices': [2178, 2161]}, {'few_shot_sample_indices': [3414, 3416]}, {'few_shot_sample_indices': [2162, 2179, 1941, 1932]}, {'few_shot_sample_indices': [3416, 3181, 3162, 3414]}, {'few_shot_sample_indices': [3412, 3179, 3159, 3413]}, {'few_shot_sample_indices': [1941, 89, 2179, 98, 2162, 1932]}, {'few_shot_sample_indices': [3414, 3416, 3401, 3386, 92, 99]}, {'few_shot_sample_indices': [3179, 2030, 94, 2026, 100, 3159]}, {'few_shot_sample_indices': [3021, 98, 1941, 3057, 89, 2162, 1932, 2179]}, {'few_shot_sample_indices': [3416, 624, 3181, 99, 92, 3414, 584, 3162]}, {'few_shot_sample_indices': [3180, 627, 100, 2032, 2027, 587, 94, 3160]}, {'few_shot_sample_indices': [1932, 550, 89, 1094, 2179, 2162, 1941, 98, 3057, 488, 3021, 1045]}, {'few_shot_sample_indices': [1099, 2027, 2246, 92, 99, 585, 2285, 1053, 3162, 626, 2032, 3181]}, {'few_shot_sample_indices': [3472, 3238, 2066, 3476, 3150, 828, 566, 2073, 508, 3211, 3116, 795]}]\n",
            "\n",
            "Current few-shot sample: 1 / 15\n",
            "Accuracy: 0.5318725099601593\n",
            "F1 score: 0.48123620309050774\n",
            "Precision: 0.5396039603960396\n",
            "Recall: 0.4342629482071713\n",
            "\n",
            "\n",
            "Current few-shot sample: 2 / 15\n",
            "Accuracy: 0.48804780876494025\n",
            "F1 score: 0.44731182795698926\n",
            "Precision: 0.48598130841121495\n",
            "Recall: 0.41434262948207173\n",
            "\n",
            "\n",
            "Current few-shot sample: 3 / 15\n",
            "Accuracy: 0.50199203187251\n",
            "F1 score: 0.35567010309278346\n",
            "Precision: 0.5036496350364964\n",
            "Recall: 0.2749003984063745\n",
            "\n",
            "\n",
            "Current few-shot sample: 4 / 15\n",
            "Accuracy: 0.5318725099601593\n",
            "F1 score: 0.31884057971014496\n",
            "Precision: 0.5851063829787234\n",
            "Recall: 0.21912350597609562\n",
            "\n",
            "\n",
            "Current few-shot sample: 5 / 15\n",
            "Accuracy: 0.48406374501992033\n",
            "F1 score: 0.33419023136246784\n",
            "Precision: 0.47101449275362317\n",
            "Recall: 0.2589641434262948\n",
            "\n",
            "\n",
            "Current few-shot sample: 6 / 15\n",
            "Accuracy: 0.49800796812749004\n",
            "F1 score: 0.007874015748031496\n",
            "Precision: 0.3333333333333333\n",
            "Recall: 0.00398406374501992\n",
            "\n",
            "\n",
            "Current few-shot sample: 7 / 15\n",
            "Accuracy: 0.5199203187250996\n",
            "F1 score: 0.23974763406940064\n",
            "Precision: 0.5757575757575758\n",
            "Recall: 0.15139442231075698\n",
            "\n",
            "\n",
            "Current few-shot sample: 8 / 15\n",
            "Accuracy: 0.5\n",
            "F1 score: 0.03088803088803089\n",
            "Precision: 0.5\n",
            "Recall: 0.01593625498007968\n",
            "\n",
            "\n",
            "Current few-shot sample: 9 / 15\n",
            "Accuracy: 0.5079681274900398\n",
            "F1 score: 0.5451197053406998\n",
            "Precision: 0.5068493150684932\n",
            "Recall: 0.5896414342629482\n",
            "\n",
            "\n",
            "Current few-shot sample: 10 / 15\n",
            "Accuracy: 0.5039840637450199\n",
            "F1 score: 0.13240418118466898\n",
            "Precision: 0.5277777777777778\n",
            "Recall: 0.07569721115537849\n",
            "\n",
            "\n",
            "Current few-shot sample: 11 / 15\n",
            "Accuracy: 0.49800796812749004\n",
            "F1 score: 0.0\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "\n",
            "\n",
            "Current few-shot sample: 12 / 15\n",
            "Accuracy: 0.49800796812749004\n",
            "F1 score: 0.0\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "\n",
            "\n",
            "Current few-shot sample: 13 / 15\n",
            "Accuracy: 0.547808764940239\n",
            "F1 score: 0.4310776942355889\n",
            "Precision: 0.581081081081081\n",
            "Recall: 0.3426294820717131\n",
            "\n",
            "\n",
            "Current few-shot sample: 14 / 15\n",
            "Accuracy: 0.50199203187251\n",
            "F1 score: 0.031007751937984492\n",
            "Precision: 0.5714285714285714\n",
            "Recall: 0.01593625498007968\n",
            "\n",
            "\n",
            "Current few-shot sample: 15 / 15\n",
            "Accuracy: 0.49800796812749004\n",
            "F1 score: 0.0\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "\n",
            "Validation results: [\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.5318725099601593,\n",
            "        \"f1\": 0.48123620309050774,\n",
            "        \"precision\": 0.5396039603960396,\n",
            "        \"recall\": 0.4342629482071713,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            2179,\n",
            "            2162\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_pos\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.48804780876494025,\n",
            "        \"f1\": 0.44731182795698926,\n",
            "        \"precision\": 0.48598130841121495,\n",
            "        \"recall\": 0.41434262948207173,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            2178,\n",
            "            2161\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_pos\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.50199203187251,\n",
            "        \"f1\": 0.35567010309278346,\n",
            "        \"precision\": 0.5036496350364964,\n",
            "        \"recall\": 0.2749003984063745,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            3414,\n",
            "            3416\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_pos\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.5318725099601593,\n",
            "        \"f1\": 0.31884057971014496,\n",
            "        \"precision\": 0.5851063829787234,\n",
            "        \"recall\": 0.21912350597609562,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            2162,\n",
            "            2179,\n",
            "            1941,\n",
            "            1932\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_pos\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.48406374501992033,\n",
            "        \"f1\": 0.33419023136246784,\n",
            "        \"precision\": 0.47101449275362317,\n",
            "        \"recall\": 0.2589641434262948,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            3416,\n",
            "            3181,\n",
            "            3162,\n",
            "            3414\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_pos\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.49800796812749004,\n",
            "        \"f1\": 0.007874015748031496,\n",
            "        \"precision\": 0.3333333333333333,\n",
            "        \"recall\": 0.00398406374501992,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            3412,\n",
            "            3179,\n",
            "            3159,\n",
            "            3413\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_pos\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.5199203187250996,\n",
            "        \"f1\": 0.23974763406940064,\n",
            "        \"precision\": 0.5757575757575758,\n",
            "        \"recall\": 0.15139442231075698,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            1941,\n",
            "            89,\n",
            "            2179,\n",
            "            98,\n",
            "            2162,\n",
            "            1932\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_pos\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.5,\n",
            "        \"f1\": 0.03088803088803089,\n",
            "        \"precision\": 0.5,\n",
            "        \"recall\": 0.01593625498007968,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            3414,\n",
            "            3416,\n",
            "            3401,\n",
            "            3386,\n",
            "            92,\n",
            "            99\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_pos\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.5079681274900398,\n",
            "        \"f1\": 0.5451197053406998,\n",
            "        \"precision\": 0.5068493150684932,\n",
            "        \"recall\": 0.5896414342629482,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            3179,\n",
            "            2030,\n",
            "            94,\n",
            "            2026,\n",
            "            100,\n",
            "            3159\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_pos\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.5039840637450199,\n",
            "        \"f1\": 0.13240418118466898,\n",
            "        \"precision\": 0.5277777777777778,\n",
            "        \"recall\": 0.07569721115537849,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            3021,\n",
            "            98,\n",
            "            1941,\n",
            "            3057,\n",
            "            89,\n",
            "            2162,\n",
            "            1932,\n",
            "            2179\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_pos\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.49800796812749004,\n",
            "        \"f1\": 0.0,\n",
            "        \"precision\": 0.0,\n",
            "        \"recall\": 0.0,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            3416,\n",
            "            624,\n",
            "            3181,\n",
            "            99,\n",
            "            92,\n",
            "            3414,\n",
            "            584,\n",
            "            3162\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_pos\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.49800796812749004,\n",
            "        \"f1\": 0.0,\n",
            "        \"precision\": 0.0,\n",
            "        \"recall\": 0.0,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            3180,\n",
            "            627,\n",
            "            100,\n",
            "            2032,\n",
            "            2027,\n",
            "            587,\n",
            "            94,\n",
            "            3160\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_pos\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.547808764940239,\n",
            "        \"f1\": 0.4310776942355889,\n",
            "        \"precision\": 0.581081081081081,\n",
            "        \"recall\": 0.3426294820717131,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            1932,\n",
            "            550,\n",
            "            89,\n",
            "            1094,\n",
            "            2179,\n",
            "            2162,\n",
            "            1941,\n",
            "            98,\n",
            "            3057,\n",
            "            488,\n",
            "            3021,\n",
            "            1045\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_pos\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.50199203187251,\n",
            "        \"f1\": 0.031007751937984492,\n",
            "        \"precision\": 0.5714285714285714,\n",
            "        \"recall\": 0.01593625498007968,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            1099,\n",
            "            2027,\n",
            "            2246,\n",
            "            92,\n",
            "            99,\n",
            "            585,\n",
            "            2285,\n",
            "            1053,\n",
            "            3162,\n",
            "            626,\n",
            "            2032,\n",
            "            3181\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_pos\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.49800796812749004,\n",
            "        \"f1\": 0.0,\n",
            "        \"precision\": 0.0,\n",
            "        \"recall\": 0.0,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            3472,\n",
            "            3238,\n",
            "            2066,\n",
            "            3476,\n",
            "            3150,\n",
            "            828,\n",
            "            566,\n",
            "            2073,\n",
            "            508,\n",
            "            3211,\n",
            "            3116,\n",
            "            795\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_pos\"\n",
            "    }\n",
            "]\n",
            "\n",
            "Lenght of test: 1002\n",
            "Getting completions...\n",
            "Evaluating test set performance...\n",
            "Accuracy: 0.5209580838323353\n",
            "F1 score: 0.5497185741088181\n",
            "Precision: 0.5185840707964602\n",
            "Recall: 0.5848303393213573\n",
            "\n",
            "Test results: {\n",
            "    \"model\": \"llama2-7b\",\n",
            "    \"acc\": 0.5209580838323353,\n",
            "    \"f1\": 0.5497185741088181,\n",
            "    \"precision\": 0.5185840707964602,\n",
            "    \"recall\": 0.5848303393213573,\n",
            "    \"few_shot_sample_indices\": [\n",
            "        3179,\n",
            "        2030,\n",
            "        94,\n",
            "        2026,\n",
            "        100,\n",
            "        3159\n",
            "    ],\n",
            "    \"few_shot_samples\": 6,\n",
            "    \"temperature\": 0.0,\n",
            "    \"eval_split\": \"test\",\n",
            "    \"dataset_name\": \"vua_pos\",\n",
            "    \"fine_tuning\": false\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"$WORKDIR\" python -m src.main --llm llama2-7b --temperature 0 --dataset vua_pos --task classification --seed 1 --evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_kaVwdaqnSz"
      },
      "source": [
        "## VUA Verb - Metaphor classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOZ1-Q1swjg1",
        "outputId": "c66670f7-351c-4f55-ef22-5c7cba950046"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-11-27 23:49:42.614171: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-27 23:49:42.614235: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-27 23:49:42.614274: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-27 23:49:43.854336: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n",
            "\n",
            "llm: llama2-7b\n",
            "fine_tuned_model_path: None\n",
            "dataset: vua_verb\n",
            "task: classification\n",
            "temperature: 0.0\n",
            "seed: 1\n",
            "evaluate: True\n",
            "fine_tuning: False\n",
            "\n",
            "\n",
            "config.json: 100% 609/609 [00:00<00:00, 2.57MB/s]\n",
            "model.safetensors.index.json: 100% 26.8k/26.8k [00:00<00:00, 96.7MB/s]\n",
            "Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00001-of-00002.safetensors:   0% 0.00/9.98G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 21.0M/9.98G [00:00<01:04, 154MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 52.4M/9.98G [00:00<00:45, 216MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 83.9M/9.98G [00:00<00:41, 240MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 115M/9.98G [00:00<00:39, 252MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 147M/9.98G [00:00<00:38, 259MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 178M/9.98G [00:00<00:40, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 210M/9.98G [00:00<00:41, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 241M/9.98G [00:01<00:40, 239MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 273M/9.98G [00:01<00:39, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 304M/9.98G [00:02<03:07, 51.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 336M/9.98G [00:02<02:24, 66.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 357M/9.98G [00:03<02:16, 70.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 377M/9.98G [00:03<01:55, 83.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 409M/9.98G [00:03<01:28, 108MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 440M/9.98G [00:03<01:15, 127MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 461M/9.98G [00:03<01:14, 127MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 493M/9.98G [00:03<01:02, 153MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 524M/9.98G [00:04<00:55, 169MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 556M/9.98G [00:04<00:49, 189MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 587M/9.98G [00:04<00:46, 204MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 619M/9.98G [00:04<00:43, 215MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 650M/9.98G [00:04<00:41, 224MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 682M/9.98G [00:04<00:40, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 713M/9.98G [00:04<00:39, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 744M/9.98G [00:04<00:38, 241MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 776M/9.98G [00:05<00:37, 244MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 807M/9.98G [00:05<00:37, 245MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 839M/9.98G [00:05<00:37, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 870M/9.98G [00:05<00:36, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 902M/9.98G [00:05<00:36, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 933M/9.98G [00:05<00:36, 245MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 965M/9.98G [00:05<00:36, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 996M/9.98G [00:05<00:35, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 1.03G/9.98G [00:06<00:35, 252MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.06G/9.98G [00:06<00:35, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.09G/9.98G [00:06<00:35, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.12G/9.98G [00:06<00:35, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 1.15G/9.98G [00:06<00:35, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 1.18G/9.98G [00:06<00:34, 254MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 1.22G/9.98G [00:06<00:35, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.25G/9.98G [00:06<00:36, 241MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.28G/9.98G [00:07<00:36, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.31G/9.98G [00:07<01:20, 107MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.33G/9.98G [00:07<01:14, 116MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 1.35G/9.98G [00:08<01:19, 108MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 1.38G/9.98G [00:08<01:03, 136MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 1.42G/9.98G [00:08<00:52, 162MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.45G/9.98G [00:08<00:49, 172MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.47G/9.98G [00:08<00:49, 170MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.50G/9.98G [00:08<00:46, 182MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.52G/9.98G [00:08<00:45, 184MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 1.55G/9.98G [00:09<00:43, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 1.58G/9.98G [00:09<00:40, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 1.61G/9.98G [00:09<00:39, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.65G/9.98G [00:09<00:37, 223MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.68G/9.98G [00:09<00:36, 229MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.71G/9.98G [00:09<00:35, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.74G/9.98G [00:09<00:40, 203MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.77G/9.98G [00:10<00:40, 203MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.79G/9.98G [00:10<00:40, 202MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.81G/9.98G [00:10<00:41, 199MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.85G/9.98G [00:10<00:40, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 1.87G/9.98G [00:10<00:40, 199MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 1.89G/9.98G [00:10<00:40, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 1.92G/9.98G [00:10<00:39, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.95G/9.98G [00:10<00:37, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.98G/9.98G [00:11<00:37, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 2.01G/9.98G [00:11<00:36, 220MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 2.04G/9.98G [00:11<00:35, 226MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 2.08G/9.98G [00:11<00:34, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 2.11G/9.98G [00:11<00:36, 216MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 2.14G/9.98G [00:11<00:37, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.17G/9.98G [00:11<00:38, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.19G/9.98G [00:12<01:37, 79.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.21G/9.98G [00:12<01:23, 93.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.23G/9.98G [00:13<01:12, 107MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.26G/9.98G [00:13<00:57, 134MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.30G/9.98G [00:13<00:53, 143MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.32G/9.98G [00:13<00:50, 151MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.35G/9.98G [00:13<00:44, 172MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.38G/9.98G [00:13<00:41, 185MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.40G/9.98G [00:13<00:41, 182MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.42G/9.98G [00:13<00:41, 181MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.45G/9.98G [00:14<00:39, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.49G/9.98G [00:14<00:53, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.52G/9.98G [00:14<00:44, 166MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.55G/9.98G [00:14<00:39, 189MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.58G/9.98G [00:14<00:35, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.61G/9.98G [00:14<00:34, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.64G/9.98G [00:15<00:34, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.67G/9.98G [00:15<00:33, 220MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.71G/9.98G [00:17<03:20, 36.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.74G/9.98G [00:17<02:28, 48.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.76G/9.98G [00:17<02:03, 58.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.78G/9.98G [00:18<01:48, 66.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.80G/9.98G [00:18<01:31, 78.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.83G/9.98G [00:18<01:10, 101MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.86G/9.98G [00:18<01:00, 118MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.89G/9.98G [00:18<00:51, 137MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.93G/9.98G [00:18<00:44, 158MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 2.96G/9.98G [00:19<00:39, 177MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 2.99G/9.98G [00:19<00:37, 189MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 3.02G/9.98G [00:19<00:34, 203MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.05G/9.98G [00:19<00:32, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.08G/9.98G [00:19<00:31, 221MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.11G/9.98G [00:19<00:30, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.15G/9.98G [00:19<00:29, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.18G/9.98G [00:19<00:29, 234MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.21G/9.98G [00:20<00:28, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.24G/9.98G [00:20<00:27, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.27G/9.98G [00:20<00:26, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.30G/9.98G [00:20<00:26, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.33G/9.98G [00:20<00:26, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.37G/9.98G [00:20<00:27, 244MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.40G/9.98G [00:20<00:27, 241MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.43G/9.98G [00:21<00:27, 235MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.46G/9.98G [00:21<00:27, 240MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.49G/9.98G [00:21<00:27, 239MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.52G/9.98G [00:21<00:27, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.55G/9.98G [00:21<00:26, 242MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.59G/9.98G [00:21<00:25, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.62G/9.98G [00:21<00:25, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.65G/9.98G [00:21<00:25, 252MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.68G/9.98G [00:22<00:25, 242MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.71G/9.98G [00:22<00:25, 244MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.74G/9.98G [00:22<00:24, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.77G/9.98G [00:22<00:25, 245MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.81G/9.98G [00:22<00:26, 236MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.84G/9.98G [00:22<00:25, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.87G/9.98G [00:22<00:24, 245MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.90G/9.98G [00:22<00:24, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.93G/9.98G [00:23<00:23, 252MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 3.96G/9.98G [00:23<00:23, 255MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 4.00G/9.98G [00:23<00:25, 234MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 4.03G/9.98G [00:23<00:26, 225MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.06G/9.98G [00:23<00:26, 225MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.09G/9.98G [00:23<00:25, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.12G/9.98G [00:23<00:25, 226MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.15G/9.98G [00:24<00:25, 229MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.18G/9.98G [00:24<00:24, 232MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.22G/9.98G [00:24<00:24, 232MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.25G/9.98G [00:24<00:25, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.28G/9.98G [00:24<00:24, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.31G/9.98G [00:24<00:24, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.34G/9.98G [00:24<00:24, 234MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.37G/9.98G [00:25<00:27, 204MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.40G/9.98G [00:25<00:28, 197MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.42G/9.98G [00:25<00:28, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 4.45G/9.98G [00:25<00:27, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 4.47G/9.98G [00:27<02:57, 31.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 4.49G/9.98G [00:27<02:16, 40.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 4.52G/9.98G [00:27<01:35, 57.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.55G/9.98G [00:28<01:10, 77.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.57G/9.98G [00:28<01:02, 86.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.59G/9.98G [00:28<00:55, 96.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.62G/9.98G [00:28<00:44, 121MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.66G/9.98G [00:28<00:38, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.68G/9.98G [00:28<00:36, 144MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.70G/9.98G [00:28<00:35, 150MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.73G/9.98G [00:29<00:30, 173MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.76G/9.98G [00:29<00:27, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.79G/9.98G [00:29<00:25, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.82G/9.98G [00:29<00:24, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.85G/9.98G [00:29<00:22, 226MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.89G/9.98G [00:29<00:21, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.92G/9.98G [00:30<00:31, 163MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 4.95G/9.98G [00:30<00:27, 184MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 4.98G/9.98G [00:30<00:26, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 5.01G/9.98G [00:30<00:24, 200MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.04G/9.98G [00:30<00:23, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.08G/9.98G [00:32<01:56, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.11G/9.98G [00:32<01:27, 55.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.13G/9.98G [00:33<01:16, 63.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.15G/9.98G [00:33<01:06, 73.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.17G/9.98G [00:33<00:55, 86.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.19G/9.98G [00:33<00:47, 102MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.22G/9.98G [00:33<00:36, 129MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.24G/9.98G [00:33<00:34, 136MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.27G/9.98G [00:33<00:29, 161MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.31G/9.98G [00:33<00:25, 180MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.34G/9.98G [00:34<00:23, 194MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 5.37G/9.98G [00:34<00:22, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 5.40G/9.98G [00:34<00:20, 218MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 5.43G/9.98G [00:34<00:19, 228MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.46G/9.98G [00:34<00:19, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.49G/9.98G [00:34<00:18, 239MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.53G/9.98G [00:34<00:18, 239MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 5.56G/9.98G [00:34<00:18, 241MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 5.59G/9.98G [00:35<00:18, 242MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 5.62G/9.98G [00:35<00:18, 242MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.65G/9.98G [00:35<00:17, 241MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.68G/9.98G [00:35<00:17, 245MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.71G/9.98G [00:35<00:17, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.75G/9.98G [00:35<00:17, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.78G/9.98G [00:35<00:17, 244MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.81G/9.98G [00:36<00:16, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.84G/9.98G [00:36<00:16, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.87G/9.98G [00:36<00:16, 245MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.90G/9.98G [00:36<00:16, 245MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.93G/9.98G [00:36<00:16, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 5.97G/9.98G [00:36<00:16, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 6.00G/9.98G [00:36<00:16, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 6.03G/9.98G [00:36<00:16, 235MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.06G/9.98G [00:37<00:16, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.09G/9.98G [00:37<00:39, 99.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.11G/9.98G [00:37<00:35, 107MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.13G/9.98G [00:38<00:33, 116MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.16G/9.98G [00:38<00:31, 122MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.18G/9.98G [00:38<00:27, 136MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.21G/9.98G [00:38<00:23, 162MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.24G/9.98G [00:38<00:22, 168MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.26G/9.98G [00:38<00:21, 171MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.29G/9.98G [00:38<00:19, 189MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.32G/9.98G [00:39<00:18, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 6.35G/9.98G [00:39<00:17, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 6.39G/9.98G [00:39<00:17, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 6.42G/9.98G [00:39<00:17, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.45G/9.98G [00:39<00:16, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.48G/9.98G [00:39<00:15, 219MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.51G/9.98G [00:39<00:16, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.53G/9.98G [00:40<00:16, 204MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.55G/9.98G [00:40<00:16, 204MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.57G/9.98G [00:40<00:16, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.60G/9.98G [00:40<00:22, 151MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.62G/9.98G [00:42<01:59, 28.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.64G/9.98G [00:42<01:29, 37.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.66G/9.98G [00:43<01:08, 48.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.69G/9.98G [00:43<00:47, 69.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.71G/9.98G [00:43<00:39, 83.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.73G/9.98G [00:43<00:32, 99.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 6.76G/9.98G [00:43<00:25, 126MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 6.79G/9.98G [00:43<00:21, 150MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 6.83G/9.98G [00:43<00:20, 156MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.85G/9.98G [00:43<00:19, 164MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.88G/9.98G [00:44<00:17, 179MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.91G/9.98G [00:47<02:08, 23.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 6.94G/9.98G [00:47<01:30, 33.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 6.97G/9.98G [00:48<01:05, 46.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 6.99G/9.98G [00:48<00:53, 56.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 7.01G/9.98G [00:48<00:46, 64.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.04G/9.98G [00:48<00:38, 75.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.07G/9.98G [00:48<00:29, 100MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.09G/9.98G [00:48<00:25, 114MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.11G/9.98G [00:48<00:22, 129MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.13G/9.98G [00:48<00:20, 142MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.15G/9.98G [00:49<00:25, 110MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.18G/9.98G [00:49<00:19, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.21G/9.98G [00:49<00:16, 168MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.25G/9.98G [00:49<00:14, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.28G/9.98G [00:49<00:13, 199MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.31G/9.98G [00:49<00:13, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.34G/9.98G [00:49<00:12, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.37G/9.98G [00:52<01:16, 33.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.39G/9.98G [00:53<01:21, 31.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.41G/9.98G [00:53<01:04, 39.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.43G/9.98G [00:53<00:51, 49.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.47G/9.98G [00:53<00:37, 67.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.50G/9.98G [00:54<00:28, 86.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.52G/9.98G [00:54<00:25, 97.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.54G/9.98G [00:54<00:22, 110MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.56G/9.98G [00:54<00:19, 124MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.58G/9.98G [00:54<00:17, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.60G/9.98G [00:54<00:15, 150MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.63G/9.98G [00:54<00:14, 160MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.65G/9.98G [00:54<00:13, 166MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.69G/9.98G [00:55<00:12, 180MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.72G/9.98G [00:55<00:11, 195MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.75G/9.98G [00:55<00:10, 204MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.78G/9.98G [00:55<00:10, 215MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.81G/9.98G [00:55<00:10, 202MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.83G/9.98G [00:55<00:10, 199MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.85G/9.98G [00:55<00:10, 199MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.87G/9.98G [00:55<00:10, 200MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.90G/9.98G [00:56<00:10, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.92G/9.98G [00:57<00:56, 36.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 7.94G/9.98G [00:57<00:42, 47.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 7.96G/9.98G [00:58<00:33, 61.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 7.98G/9.98G [00:58<00:26, 76.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 8.01G/9.98G [00:58<00:18, 104MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.04G/9.98G [00:58<00:14, 130MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.07G/9.98G [00:58<00:12, 153MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.11G/9.98G [00:58<00:10, 174MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.14G/9.98G [00:58<00:10, 172MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.16G/9.98G [00:59<00:11, 163MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.19G/9.98G [00:59<00:10, 179MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.22G/9.98G [00:59<00:08, 196MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.25G/9.98G [00:59<00:08, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.28G/9.98G [00:59<00:07, 215MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.32G/9.98G [00:59<00:07, 221MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 8.35G/9.98G [00:59<00:07, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 8.38G/9.98G [00:59<00:06, 232MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 8.41G/9.98G [01:00<00:06, 232MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.44G/9.98G [01:00<00:06, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.47G/9.98G [01:00<00:06, 241MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.50G/9.98G [01:00<00:06, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 8.54G/9.98G [01:00<00:05, 245MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 8.57G/9.98G [01:00<00:05, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 8.60G/9.98G [01:00<00:05, 252MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.63G/9.98G [01:00<00:05, 253MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.66G/9.98G [01:01<00:05, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.69G/9.98G [01:01<00:05, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.72G/9.98G [01:01<00:04, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.76G/9.98G [01:01<00:04, 245MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.79G/9.98G [01:01<00:04, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.82G/9.98G [01:01<00:04, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 8.85G/9.98G [01:01<00:04, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 8.88G/9.98G [01:01<00:04, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 8.91G/9.98G [01:02<00:04, 245MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 8.94G/9.98G [01:02<00:04, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 8.98G/9.98G [01:02<00:04, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 9.01G/9.98G [01:02<00:03, 252MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 9.04G/9.98G [01:02<00:03, 253MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 9.07G/9.98G [01:02<00:03, 254MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 9.10G/9.98G [01:02<00:03, 252MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.13G/9.98G [01:02<00:03, 255MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.16G/9.98G [01:03<00:03, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.20G/9.98G [01:03<00:03, 253MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.23G/9.98G [01:03<00:02, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.26G/9.98G [01:03<00:02, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.29G/9.98G [01:03<00:04, 165MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.32G/9.98G [01:03<00:03, 187MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.35G/9.98G [01:04<00:03, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.38G/9.98G [01:04<00:02, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.42G/9.98G [01:04<00:02, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.45G/9.98G [01:04<00:02, 215MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.48G/9.98G [01:04<00:02, 218MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.51G/9.98G [01:04<00:02, 219MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.54G/9.98G [01:04<00:01, 226MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.57G/9.98G [01:05<00:01, 224MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.60G/9.98G [01:05<00:01, 222MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.64G/9.98G [01:05<00:01, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.67G/9.98G [01:05<00:01, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.70G/9.98G [01:05<00:01, 235MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.73G/9.98G [01:05<00:01, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.76G/9.98G [01:05<00:00, 244MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.79G/9.98G [01:05<00:00, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.83G/9.98G [01:06<00:00, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.86G/9.98G [01:06<00:00, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.89G/9.98G [01:06<00:00, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.92G/9.98G [01:06<00:00, 253MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 9.98G/9.98G [01:06<00:00, 150MB/s]\n",
            "Downloading shards:  50% 1/2 [01:06<01:06, 66.87s/it]\n",
            "model-00002-of-00002.safetensors:   0% 0.00/3.50G [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   1% 31.5M/3.50G [00:00<00:13, 264MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   2% 62.9M/3.50G [00:00<00:14, 230MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   3% 94.4M/3.50G [00:00<00:14, 237MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   4% 126M/3.50G [00:00<00:14, 234MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:   4% 157M/3.50G [00:00<00:26, 124MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   5% 189M/3.50G [00:01<00:23, 140MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   6% 210M/3.50G [00:01<00:23, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   7% 231M/3.50G [00:01<00:22, 144MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   7% 252M/3.50G [00:01<00:20, 158MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   8% 283M/3.50G [00:01<00:18, 178MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   9% 315M/3.50G [00:01<00:17, 179MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  10% 336M/3.50G [00:01<00:17, 185MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  10% 367M/3.50G [00:02<00:16, 193MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  11% 398M/3.50G [00:02<00:15, 201MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  12% 430M/3.50G [00:02<00:14, 211MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  13% 461M/3.50G [00:02<00:14, 211MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  14% 493M/3.50G [00:02<00:13, 219MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  15% 524M/3.50G [00:02<00:13, 214MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  16% 556M/3.50G [00:02<00:13, 219MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  17% 587M/3.50G [00:03<00:13, 224MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  18% 619M/3.50G [00:03<00:12, 225MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  19% 650M/3.50G [00:03<00:13, 213MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  19% 682M/3.50G [00:03<00:12, 222MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  20% 713M/3.50G [00:03<00:12, 226MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  21% 744M/3.50G [00:03<00:11, 232MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  22% 776M/3.50G [00:03<00:12, 219MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  23% 807M/3.50G [00:04<00:13, 206MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  24% 839M/3.50G [00:04<00:12, 208MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  25% 870M/3.50G [00:04<00:12, 203MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  25% 891M/3.50G [00:06<00:54, 48.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  26% 923M/3.50G [00:06<00:39, 65.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  27% 954M/3.50G [00:06<00:30, 84.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  28% 986M/3.50G [00:06<00:24, 104MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  29% 1.01G/3.50G [00:06<00:22, 111MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  29% 1.03G/3.50G [00:06<00:20, 122MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  30% 1.05G/3.50G [00:06<00:18, 131MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  31% 1.07G/3.50G [00:06<00:17, 140MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  31% 1.09G/3.50G [00:07<00:16, 148MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  32% 1.11G/3.50G [00:07<00:15, 155MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  33% 1.14G/3.50G [00:07<00:13, 177MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  34% 1.17G/3.50G [00:07<00:11, 196MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  34% 1.21G/3.50G [00:07<00:11, 206MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  35% 1.24G/3.50G [00:07<00:10, 209MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  36% 1.27G/3.50G [00:07<00:10, 223MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  37% 1.30G/3.50G [00:07<00:09, 235MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  38% 1.33G/3.50G [00:08<00:08, 242MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  39% 1.36G/3.50G [00:08<00:09, 234MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  40% 1.39G/3.50G [00:08<00:08, 237MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  41% 1.43G/3.50G [00:08<00:08, 245MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  42% 1.46G/3.50G [00:08<00:08, 250MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  43% 1.49G/3.50G [00:08<00:08, 238MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  43% 1.52G/3.50G [00:08<00:08, 234MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  44% 1.55G/3.50G [00:09<00:08, 233MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  45% 1.58G/3.50G [00:09<00:08, 234MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  46% 1.61G/3.50G [00:11<00:39, 47.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  47% 1.65G/3.50G [00:11<00:29, 63.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  48% 1.68G/3.50G [00:11<00:23, 79.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  49% 1.70G/3.50G [00:11<00:20, 88.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  49% 1.72G/3.50G [00:11<00:17, 99.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  50% 1.74G/3.50G [00:11<00:15, 114MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  50% 1.76G/3.50G [00:11<00:13, 126MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  51% 1.78G/3.50G [00:11<00:12, 133MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  52% 1.81G/3.50G [00:12<00:10, 157MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  53% 1.85G/3.50G [00:12<00:09, 175MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  54% 1.88G/3.50G [00:12<00:08, 185MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  55% 1.91G/3.50G [00:12<00:07, 201MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  55% 1.94G/3.50G [00:12<00:07, 211MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  56% 1.97G/3.50G [00:12<00:07, 212MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  57% 2.00G/3.50G [00:12<00:06, 218MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  58% 2.03G/3.50G [00:13<00:06, 228MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  59% 2.07G/3.50G [00:13<00:06, 224MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  60% 2.10G/3.50G [00:13<00:05, 234MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  61% 2.13G/3.50G [00:13<00:05, 240MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  62% 2.16G/3.50G [00:13<00:05, 247MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  63% 2.19G/3.50G [00:13<00:05, 241MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  64% 2.22G/3.50G [00:13<00:05, 241MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  64% 2.25G/3.50G [00:13<00:05, 245MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  65% 2.29G/3.50G [00:14<00:05, 235MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  66% 2.32G/3.50G [00:14<00:05, 229MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  67% 2.35G/3.50G [00:14<00:05, 223MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  68% 2.38G/3.50G [00:15<00:19, 58.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  69% 2.41G/3.50G [00:15<00:14, 76.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  70% 2.44G/3.50G [00:16<00:11, 93.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  70% 2.46G/3.50G [00:16<00:10, 102MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  71% 2.49G/3.50G [00:16<00:09, 112MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  72% 2.52G/3.50G [00:16<00:07, 134MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  72% 2.54G/3.50G [00:16<00:06, 140MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  73% 2.56G/3.50G [00:16<00:06, 151MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  74% 2.58G/3.50G [00:16<00:05, 162MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  75% 2.61G/3.50G [00:17<00:04, 180MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  75% 2.64G/3.50G [00:17<00:04, 191MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  76% 2.67G/3.50G [00:17<00:04, 196MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  77% 2.69G/3.50G [00:17<00:04, 195MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  78% 2.73G/3.50G [00:17<00:03, 209MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  79% 2.76G/3.50G [00:17<00:03, 212MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  80% 2.79G/3.50G [00:17<00:03, 214MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  81% 2.82G/3.50G [00:18<00:03, 218MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  81% 2.85G/3.50G [00:18<00:02, 222MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  82% 2.88G/3.50G [00:18<00:02, 210MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  83% 2.92G/3.50G [00:18<00:02, 196MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  84% 2.94G/3.50G [00:18<00:02, 193MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  84% 2.96G/3.50G [00:18<00:02, 194MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  85% 2.99G/3.50G [00:20<00:09, 55.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  86% 3.01G/3.50G [00:21<00:12, 39.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  87% 3.03G/3.50G [00:21<00:09, 49.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  87% 3.05G/3.50G [00:21<00:08, 53.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  88% 3.08G/3.50G [00:21<00:05, 74.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  89% 3.10G/3.50G [00:21<00:04, 88.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  90% 3.14G/3.50G [00:21<00:03, 113MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  90% 3.16G/3.50G [00:21<00:02, 128MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  91% 3.19G/3.50G [00:22<00:02, 154MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  92% 3.22G/3.50G [00:22<00:01, 177MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  93% 3.25G/3.50G [00:22<00:01, 192MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  94% 3.28G/3.50G [00:22<00:01, 210MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  95% 3.31G/3.50G [00:22<00:00, 217MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  96% 3.34G/3.50G [00:22<00:00, 230MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  96% 3.38G/3.50G [00:22<00:00, 224MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  97% 3.41G/3.50G [00:23<00:00, 227MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  98% 3.44G/3.50G [00:23<00:00, 227MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  99% 3.47G/3.50G [00:23<00:00, 225MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 3.50G/3.50G [00:23<00:00, 149MB/s]\n",
            "Downloading shards: 100% 2/2 [01:30<00:00, 45.22s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [01:06<00:00, 33.33s/it]\n",
            "generation_config.json: 100% 188/188 [00:00<00:00, 826kB/s]\n",
            "tokenizer_config.json: 100% 776/776 [00:00<00:00, 3.24MB/s]\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 329MB/s]\n",
            "tokenizer.json: 100% 1.84M/1.84M [00:00<00:00, 7.02MB/s]\n",
            "special_tokens_map.json: 100% 414/414 [00:00<00:00, 2.01MB/s]\n",
            "Lenght of train: 2294\n",
            "Lenght of valid: 328\n",
            "Train indices: [\n",
            "    [\n",
            "        1877,\n",
            "        1858\n",
            "    ],\n",
            "    [\n",
            "        1468,\n",
            "        1474\n",
            "    ],\n",
            "    [\n",
            "        750,\n",
            "        782\n",
            "    ],\n",
            "    [\n",
            "        1858,\n",
            "        1877,\n",
            "        233,\n",
            "        254\n",
            "    ],\n",
            "    [\n",
            "        784,\n",
            "        1358,\n",
            "        1355,\n",
            "        751\n",
            "    ],\n",
            "    [\n",
            "        613,\n",
            "        1400,\n",
            "        1403,\n",
            "        640\n",
            "    ],\n",
            "    [\n",
            "        233,\n",
            "        1388,\n",
            "        1877,\n",
            "        1389,\n",
            "        1858,\n",
            "        254\n",
            "    ],\n",
            "    [\n",
            "        751,\n",
            "        784,\n",
            "        1358,\n",
            "        1355,\n",
            "        1034,\n",
            "        1036\n",
            "    ],\n",
            "    [\n",
            "        1182,\n",
            "        613,\n",
            "        1280,\n",
            "        640,\n",
            "        1268,\n",
            "        1183\n",
            "    ],\n",
            "    [\n",
            "        1928,\n",
            "        1389,\n",
            "        233,\n",
            "        1938,\n",
            "        1388,\n",
            "        1858,\n",
            "        254,\n",
            "        1877\n",
            "    ],\n",
            "    [\n",
            "        640,\n",
            "        2283,\n",
            "        1399,\n",
            "        1708,\n",
            "        1683,\n",
            "        613,\n",
            "        2276,\n",
            "        1402\n",
            "    ],\n",
            "    [\n",
            "        2266,\n",
            "        797,\n",
            "        1173,\n",
            "        1661,\n",
            "        1690,\n",
            "        763,\n",
            "        1170,\n",
            "        2252\n",
            "    ],\n",
            "    [\n",
            "        254,\n",
            "        2223,\n",
            "        1388,\n",
            "        2199,\n",
            "        1877,\n",
            "        1858,\n",
            "        233,\n",
            "        1389,\n",
            "        1938,\n",
            "        2230,\n",
            "        1928,\n",
            "        2206\n",
            "    ],\n",
            "    [\n",
            "        2214,\n",
            "        640,\n",
            "        672,\n",
            "        1277,\n",
            "        1260,\n",
            "        1922,\n",
            "        699,\n",
            "        2222,\n",
            "        1179,\n",
            "        1918,\n",
            "        613,\n",
            "        1176\n",
            "    ],\n",
            "    [\n",
            "        2225,\n",
            "        175,\n",
            "        795,\n",
            "        2220,\n",
            "        1887,\n",
            "        830,\n",
            "        1572,\n",
            "        758,\n",
            "        1549,\n",
            "        201,\n",
            "        1876,\n",
            "        793\n",
            "    ]\n",
            "]\n",
            "\n",
            "Number of parameter combinations: 15 \n",
            "\n",
            "[{'few_shot_sample_indices': [1877, 1858]}, {'few_shot_sample_indices': [1468, 1474]}, {'few_shot_sample_indices': [750, 782]}, {'few_shot_sample_indices': [1858, 1877, 233, 254]}, {'few_shot_sample_indices': [784, 1358, 1355, 751]}, {'few_shot_sample_indices': [613, 1400, 1403, 640]}, {'few_shot_sample_indices': [233, 1388, 1877, 1389, 1858, 254]}, {'few_shot_sample_indices': [751, 784, 1358, 1355, 1034, 1036]}, {'few_shot_sample_indices': [1182, 613, 1280, 640, 1268, 1183]}, {'few_shot_sample_indices': [1928, 1389, 233, 1938, 1388, 1858, 254, 1877]}, {'few_shot_sample_indices': [640, 2283, 1399, 1708, 1683, 613, 2276, 1402]}, {'few_shot_sample_indices': [2266, 797, 1173, 1661, 1690, 763, 1170, 2252]}, {'few_shot_sample_indices': [254, 2223, 1388, 2199, 1877, 1858, 233, 1389, 1938, 2230, 1928, 2206]}, {'few_shot_sample_indices': [2214, 640, 672, 1277, 1260, 1922, 699, 2222, 1179, 1918, 613, 1176]}, {'few_shot_sample_indices': [2225, 175, 795, 2220, 1887, 830, 1572, 758, 1549, 201, 1876, 793]}]\n",
            "\n",
            "Current few-shot sample: 1 / 15\n",
            "Accuracy: 0.5396341463414634\n",
            "F1 score: 0.24875621890547264\n",
            "Precision: 0.6756756756756757\n",
            "Recall: 0.1524390243902439\n",
            "\n",
            "\n",
            "Current few-shot sample: 2 / 15\n",
            "Accuracy: 0.5121951219512195\n",
            "F1 score: 0.0588235294117647\n",
            "Precision: 0.8333333333333334\n",
            "Recall: 0.03048780487804878\n",
            "\n",
            "\n",
            "Current few-shot sample: 3 / 15\n",
            "Accuracy: 0.6067073170731707\n",
            "F1 score: 0.6303724928366763\n",
            "Precision: 0.5945945945945946\n",
            "Recall: 0.6707317073170732\n",
            "\n",
            "\n",
            "Current few-shot sample: 4 / 15\n",
            "Accuracy: 0.5853658536585366\n",
            "F1 score: 0.43333333333333335\n",
            "Precision: 0.6842105263157895\n",
            "Recall: 0.3170731707317073\n",
            "\n",
            "\n",
            "Current few-shot sample: 5 / 15\n",
            "Accuracy: 0.524390243902439\n",
            "F1 score: 0.13333333333333333\n",
            "Precision: 0.75\n",
            "Recall: 0.07317073170731707\n",
            "\n",
            "\n",
            "Current few-shot sample: 6 / 15\n",
            "Accuracy: 0.49085365853658536\n",
            "F1 score: 0.01183431952662722\n",
            "Precision: 0.2\n",
            "Recall: 0.006097560975609756\n",
            "\n",
            "\n",
            "Current few-shot sample: 7 / 15\n",
            "Accuracy: 0.5121951219512195\n",
            "F1 score: 0.5454545454545454\n",
            "Precision: 0.5106382978723404\n",
            "Recall: 0.5853658536585366\n",
            "\n",
            "\n",
            "Current few-shot sample: 8 / 15\n",
            "Accuracy: 0.4969512195121951\n",
            "F1 score: 0.03508771929824561\n",
            "Precision: 0.42857142857142855\n",
            "Recall: 0.018292682926829267\n",
            "\n",
            "\n",
            "Current few-shot sample: 9 / 15\n",
            "Accuracy: 0.49390243902439024\n",
            "F1 score: 0.6157407407407408\n",
            "Precision: 0.4962686567164179\n",
            "Recall: 0.8109756097560976\n",
            "\n",
            "\n",
            "Current few-shot sample: 10 / 15\n",
            "Accuracy: 0.5182926829268293\n",
            "F1 score: 0.18556701030927836\n",
            "Precision: 0.6\n",
            "Recall: 0.10975609756097561\n",
            "\n",
            "\n",
            "Current few-shot sample: 11 / 15\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Accuracy: 0.5\n",
            "F1 score: 0.0\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "\n",
            "\n",
            "Current few-shot sample: 12 / 15\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Accuracy: 0.5\n",
            "F1 score: 0.0\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "\n",
            "\n",
            "Current few-shot sample: 13 / 15\n",
            "Accuracy: 0.5792682926829268\n",
            "F1 score: 0.5576923076923077\n",
            "Precision: 0.5878378378378378\n",
            "Recall: 0.5304878048780488\n",
            "\n",
            "\n",
            "Current few-shot sample: 14 / 15\n",
            "Accuracy: 0.4969512195121951\n",
            "F1 score: 0.05714285714285714\n",
            "Precision: 0.45454545454545453\n",
            "Recall: 0.03048780487804878\n",
            "\n",
            "\n",
            "Current few-shot sample: 15 / 15\n",
            "Accuracy: 0.5121951219512195\n",
            "F1 score: 0.047619047619047616\n",
            "Precision: 1.0\n",
            "Recall: 0.024390243902439025\n",
            "\n",
            "Validation results: [\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.5396341463414634,\n",
            "        \"f1\": 0.24875621890547264,\n",
            "        \"precision\": 0.6756756756756757,\n",
            "        \"recall\": 0.1524390243902439,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            1877,\n",
            "            1858\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_verb\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.5121951219512195,\n",
            "        \"f1\": 0.0588235294117647,\n",
            "        \"precision\": 0.8333333333333334,\n",
            "        \"recall\": 0.03048780487804878,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            1468,\n",
            "            1474\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_verb\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.6067073170731707,\n",
            "        \"f1\": 0.6303724928366763,\n",
            "        \"precision\": 0.5945945945945946,\n",
            "        \"recall\": 0.6707317073170732,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            750,\n",
            "            782\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_verb\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.5853658536585366,\n",
            "        \"f1\": 0.43333333333333335,\n",
            "        \"precision\": 0.6842105263157895,\n",
            "        \"recall\": 0.3170731707317073,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            1858,\n",
            "            1877,\n",
            "            233,\n",
            "            254\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_verb\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.524390243902439,\n",
            "        \"f1\": 0.13333333333333333,\n",
            "        \"precision\": 0.75,\n",
            "        \"recall\": 0.07317073170731707,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            784,\n",
            "            1358,\n",
            "            1355,\n",
            "            751\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_verb\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.49085365853658536,\n",
            "        \"f1\": 0.01183431952662722,\n",
            "        \"precision\": 0.2,\n",
            "        \"recall\": 0.006097560975609756,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            613,\n",
            "            1400,\n",
            "            1403,\n",
            "            640\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_verb\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.5121951219512195,\n",
            "        \"f1\": 0.5454545454545454,\n",
            "        \"precision\": 0.5106382978723404,\n",
            "        \"recall\": 0.5853658536585366,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            233,\n",
            "            1388,\n",
            "            1877,\n",
            "            1389,\n",
            "            1858,\n",
            "            254\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_verb\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.4969512195121951,\n",
            "        \"f1\": 0.03508771929824561,\n",
            "        \"precision\": 0.42857142857142855,\n",
            "        \"recall\": 0.018292682926829267,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            751,\n",
            "            784,\n",
            "            1358,\n",
            "            1355,\n",
            "            1034,\n",
            "            1036\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_verb\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.49390243902439024,\n",
            "        \"f1\": 0.6157407407407408,\n",
            "        \"precision\": 0.4962686567164179,\n",
            "        \"recall\": 0.8109756097560976,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            1182,\n",
            "            613,\n",
            "            1280,\n",
            "            640,\n",
            "            1268,\n",
            "            1183\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_verb\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.5182926829268293,\n",
            "        \"f1\": 0.18556701030927836,\n",
            "        \"precision\": 0.6,\n",
            "        \"recall\": 0.10975609756097561,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            1928,\n",
            "            1389,\n",
            "            233,\n",
            "            1938,\n",
            "            1388,\n",
            "            1858,\n",
            "            254,\n",
            "            1877\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_verb\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.5,\n",
            "        \"f1\": 0.0,\n",
            "        \"precision\": 0.0,\n",
            "        \"recall\": 0.0,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            640,\n",
            "            2283,\n",
            "            1399,\n",
            "            1708,\n",
            "            1683,\n",
            "            613,\n",
            "            2276,\n",
            "            1402\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_verb\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.5,\n",
            "        \"f1\": 0.0,\n",
            "        \"precision\": 0.0,\n",
            "        \"recall\": 0.0,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            2266,\n",
            "            797,\n",
            "            1173,\n",
            "            1661,\n",
            "            1690,\n",
            "            763,\n",
            "            1170,\n",
            "            2252\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_verb\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.5792682926829268,\n",
            "        \"f1\": 0.5576923076923077,\n",
            "        \"precision\": 0.5878378378378378,\n",
            "        \"recall\": 0.5304878048780488,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            254,\n",
            "            2223,\n",
            "            1388,\n",
            "            2199,\n",
            "            1877,\n",
            "            1858,\n",
            "            233,\n",
            "            1389,\n",
            "            1938,\n",
            "            2230,\n",
            "            1928,\n",
            "            2206\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_verb\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.4969512195121951,\n",
            "        \"f1\": 0.05714285714285714,\n",
            "        \"precision\": 0.45454545454545453,\n",
            "        \"recall\": 0.03048780487804878,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            2214,\n",
            "            640,\n",
            "            672,\n",
            "            1277,\n",
            "            1260,\n",
            "            1922,\n",
            "            699,\n",
            "            2222,\n",
            "            1179,\n",
            "            1918,\n",
            "            613,\n",
            "            1176\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_verb\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"llama2-7b\",\n",
            "        \"acc\": 0.5121951219512195,\n",
            "        \"f1\": 0.047619047619047616,\n",
            "        \"precision\": 1.0,\n",
            "        \"recall\": 0.024390243902439025,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            2225,\n",
            "            175,\n",
            "            795,\n",
            "            2220,\n",
            "            1887,\n",
            "            830,\n",
            "            1572,\n",
            "            758,\n",
            "            1549,\n",
            "            201,\n",
            "            1876,\n",
            "            793\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_verb\"\n",
            "    }\n",
            "]\n",
            "\n",
            "Lenght of test: 656\n",
            "Getting completions...\n",
            "Evaluating test set performance...\n",
            "Accuracy: 0.5792682926829268\n",
            "F1 score: 0.5964912280701754\n",
            "Precision: 0.5730337078651685\n",
            "Recall: 0.6219512195121951\n",
            "\n",
            "Test results: {\n",
            "    \"model\": \"llama2-7b\",\n",
            "    \"acc\": 0.5792682926829268,\n",
            "    \"f1\": 0.5964912280701754,\n",
            "    \"precision\": 0.5730337078651685,\n",
            "    \"recall\": 0.6219512195121951,\n",
            "    \"few_shot_sample_indices\": [\n",
            "        750,\n",
            "        782\n",
            "    ],\n",
            "    \"few_shot_samples\": 2,\n",
            "    \"temperature\": 0.0,\n",
            "    \"eval_split\": \"test\",\n",
            "    \"dataset_name\": \"vua_verb\",\n",
            "    \"fine_tuning\": false\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"$WORKDIR\" python -m src.main --llm llama2-7b --temperature 0 --dataset vua_verb --task classification --seed 1 --evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhnlXWg0ltcz"
      },
      "source": [
        "# (GPT-3) Few-shot prompting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZheHA4OlxsN"
      },
      "source": [
        "## Metaphor List - Source domain prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMkZ2-KbmZ2x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d67029a7-a62f-4647-ca75-bdc61179147c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-29 11:51:22.613201: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-29 11:51:22.613264: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-29 11:51:22.613299: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-29 11:51:23.626195: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n",
            "\n",
            "llm: gpt3.5\n",
            "fine_tuned_model_path: None\n",
            "dataset: metaphor_list\n",
            "task: source_domain_prediction\n",
            "temperature: 0.0\n",
            "seed: 1\n",
            "evaluate: True\n",
            "fine_tuning: False\n",
            "\n",
            "\n",
            "Lenght of train: 132\n",
            "Lenght of valid: 120\n",
            "Train indices: [\n",
            "    [\n",
            "        75,\n",
            "        35\n",
            "    ],\n",
            "    [\n",
            "        110,\n",
            "        107\n",
            "    ],\n",
            "    [\n",
            "        125,\n",
            "        106\n",
            "    ],\n",
            "    [\n",
            "        75,\n",
            "        35,\n",
            "        51,\n",
            "        5\n",
            "    ],\n",
            "    [\n",
            "        125,\n",
            "        108,\n",
            "        58,\n",
            "        59\n",
            "    ],\n",
            "    [\n",
            "        50,\n",
            "        121,\n",
            "        79,\n",
            "        113\n",
            "    ],\n",
            "    [\n",
            "        75,\n",
            "        35,\n",
            "        51,\n",
            "        5,\n",
            "        36,\n",
            "        120\n",
            "    ],\n",
            "    [\n",
            "        126,\n",
            "        49,\n",
            "        78,\n",
            "        95,\n",
            "        107,\n",
            "        57\n",
            "    ],\n",
            "    [\n",
            "        104,\n",
            "        60,\n",
            "        65,\n",
            "        129,\n",
            "        85,\n",
            "        50\n",
            "    ],\n",
            "    [\n",
            "        75,\n",
            "        35,\n",
            "        51,\n",
            "        5,\n",
            "        36,\n",
            "        120,\n",
            "        54,\n",
            "        17\n",
            "    ],\n",
            "    [\n",
            "        53,\n",
            "        122,\n",
            "        80,\n",
            "        113,\n",
            "        49,\n",
            "        33,\n",
            "        73,\n",
            "        50\n",
            "    ],\n",
            "    [\n",
            "        108,\n",
            "        52,\n",
            "        66,\n",
            "        110,\n",
            "        82,\n",
            "        130,\n",
            "        86,\n",
            "        68\n",
            "    ],\n",
            "    [\n",
            "        75,\n",
            "        35,\n",
            "        51,\n",
            "        5,\n",
            "        36,\n",
            "        120,\n",
            "        54,\n",
            "        17,\n",
            "        121,\n",
            "        119,\n",
            "        66,\n",
            "        114\n",
            "    ],\n",
            "    [\n",
            "        103,\n",
            "        60,\n",
            "        65,\n",
            "        129,\n",
            "        85,\n",
            "        50,\n",
            "        33,\n",
            "        89,\n",
            "        53,\n",
            "        106,\n",
            "        105,\n",
            "        107\n",
            "    ],\n",
            "    [\n",
            "        123,\n",
            "        109,\n",
            "        111,\n",
            "        108,\n",
            "        124,\n",
            "        67,\n",
            "        104,\n",
            "        64,\n",
            "        57,\n",
            "        79,\n",
            "        70,\n",
            "        2\n",
            "    ]\n",
            "]\n",
            "\n",
            "Number of parameter combinations: 15 \n",
            "\n",
            "[{'few_shot_sample_indices': [75, 35]}, {'few_shot_sample_indices': [110, 107]}, {'few_shot_sample_indices': [125, 106]}, {'few_shot_sample_indices': [75, 35, 51, 5]}, {'few_shot_sample_indices': [125, 108, 58, 59]}, {'few_shot_sample_indices': [50, 121, 79, 113]}, {'few_shot_sample_indices': [75, 35, 51, 5, 36, 120]}, {'few_shot_sample_indices': [126, 49, 78, 95, 107, 57]}, {'few_shot_sample_indices': [104, 60, 65, 129, 85, 50]}, {'few_shot_sample_indices': [75, 35, 51, 5, 36, 120, 54, 17]}, {'few_shot_sample_indices': [53, 122, 80, 113, 49, 33, 73, 50]}, {'few_shot_sample_indices': [108, 52, 66, 110, 82, 130, 86, 68]}, {'few_shot_sample_indices': [75, 35, 51, 5, 36, 120, 54, 17, 121, 119, 66, 114]}, {'few_shot_sample_indices': [103, 60, 65, 129, 85, 50, 33, 89, 53, 106, 105, 107]}, {'few_shot_sample_indices': [123, 109, 111, 108, 124, 67, 104, 64, 57, 79, 70, 2]}]\n",
            "\n",
            "Current few-shot sample: 1 / 15\n",
            "[==================================================] 100.0% 958.5/958.4MB downloaded\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' alcohol/drugs ', but wanted ' destruction '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' growth/development ', but wanted ' plants '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' progress/advancement ', but wanted ' competition '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' progress/advancement ', but wanted ' container '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' work/study ', but wanted ' not metaphoric '\n",
            "gpt3.5 Accuracy:  0.058333333333333334\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.4615737821906805\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.1972377959855509\n",
            "\n",
            "Current few-shot sample: 2 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' travel/progression ', but wanted ' areas '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' movement/progression ', but wanted ' moving object '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' touch/sensation ', but wanted ' solid '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' movement/direction ', but wanted ' location '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' covering/enclosure ', but wanted ' cover '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' life/death ', but wanted ' alive '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' travel/destination ', but wanted ' goal '\n",
            "gpt3.5 Accuracy:  0.125\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.49697295439740025\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.2492147852047454\n",
            "\n",
            "Current few-shot sample: 3 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' growth/development ', but wanted ' plants '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sports/games ', but wanted ' race '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' pressure/steam ', but wanted ' heat '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sports/games ', but wanted ' fight '\n",
            "gpt3.5 Accuracy:  0.14166666666666666\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.5132641372581322\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.23447826482953402\n",
            "\n",
            "Current few-shot sample: 4 / 15\n",
            "gpt3.5 Accuracy:  0.15\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.5387889603773753\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.22434849964943449\n",
            "\n",
            "Current few-shot sample: 5 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' growth/development ', but wanted ' plants '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' vehicle/machine ', but wanted ' machine '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' touch/sensation ', but wanted ' solid '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' war/battle ', but wanted ' war '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' progress/advancement ', but wanted ' container '\n",
            "gpt3.5 Accuracy:  0.10833333333333334\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.49823723832766215\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.22920395450570252\n",
            "\n",
            "Current few-shot sample: 6 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' movement/progress ', but wanted ' moving object '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' touch/sensation ', but wanted ' solid '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' land/territory ', but wanted ' war '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' water/sea ', but wanted ' journey '\n",
            "gpt3.5 Accuracy:  0.14166666666666666\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.5120218612253666\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.23690536789976685\n",
            "\n",
            "Current few-shot sample: 7 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' touch/sensation ', but wanted ' solid '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' life/death ', but wanted ' goal '\n",
            "gpt3.5 Accuracy:  0.16666666666666666\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.535268922150135\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.24036561947269758\n",
            "\n",
            "Current few-shot sample: 8 / 15\n",
            "gpt3.5 Accuracy:  0.11666666666666667\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.5311485921343168\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.2137375902967446\n",
            "\n",
            "Current few-shot sample: 9 / 15\n",
            "gpt3.5 Accuracy:  0.075\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.4723018539448579\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.18284803378882436\n",
            "\n",
            "Current few-shot sample: 10 / 15\n",
            "gpt3.5 Accuracy:  0.18333333333333332\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.5476404249668121\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.23854375781274115\n",
            "\n",
            "Current few-shot sample: 11 / 15\n",
            "gpt3.5 Accuracy:  0.11666666666666667\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.5153149624665578\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.20818116219278585\n",
            "\n",
            "Current few-shot sample: 12 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' progress/advancement ', but wanted ' competition '\n",
            "gpt3.5 Accuracy:  0.14166666666666666\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.5195105606069167\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.2258197263407739\n",
            "\n",
            "Current few-shot sample: 13 / 15\n",
            "gpt3.5 Accuracy:  0.21666666666666667\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.559059851616621\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.2530425736189238\n",
            "\n",
            "Current few-shot sample: 14 / 15\n",
            "gpt3.5 Accuracy:  0.11666666666666667\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.503939609353741\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.21080433503341534\n",
            "\n",
            "Current few-shot sample: 15 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' building/construction ', but wanted ' object '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' movement/progress ', but wanted ' moving object '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' movement/direction ', but wanted ' location '\n",
            "gpt3.5 Accuracy:  0.15833333333333333\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.5475555285811424\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.24710563227613022\n",
            "Validation results: [\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.058333333333333334,\n",
            "        \"mean_em\": 0.4615737821906805,\n",
            "        \"std_em\": 0.1972377959855509,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            75,\n",
            "            35\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.125,\n",
            "        \"mean_em\": 0.49697295439740025,\n",
            "        \"std_em\": 0.2492147852047454,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            110,\n",
            "            107\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.14166666666666666,\n",
            "        \"mean_em\": 0.5132641372581322,\n",
            "        \"std_em\": 0.23447826482953402,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            125,\n",
            "            106\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.15,\n",
            "        \"mean_em\": 0.5387889603773753,\n",
            "        \"std_em\": 0.22434849964943449,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            75,\n",
            "            35,\n",
            "            51,\n",
            "            5\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.10833333333333334,\n",
            "        \"mean_em\": 0.49823723832766215,\n",
            "        \"std_em\": 0.22920395450570252,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            125,\n",
            "            108,\n",
            "            58,\n",
            "            59\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.14166666666666666,\n",
            "        \"mean_em\": 0.5120218612253666,\n",
            "        \"std_em\": 0.23690536789976685,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            50,\n",
            "            121,\n",
            "            79,\n",
            "            113\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.16666666666666666,\n",
            "        \"mean_em\": 0.535268922150135,\n",
            "        \"std_em\": 0.24036561947269758,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            75,\n",
            "            35,\n",
            "            51,\n",
            "            5,\n",
            "            36,\n",
            "            120\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.11666666666666667,\n",
            "        \"mean_em\": 0.5311485921343168,\n",
            "        \"std_em\": 0.2137375902967446,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            126,\n",
            "            49,\n",
            "            78,\n",
            "            95,\n",
            "            107,\n",
            "            57\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.075,\n",
            "        \"mean_em\": 0.4723018539448579,\n",
            "        \"std_em\": 0.18284803378882436,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            104,\n",
            "            60,\n",
            "            65,\n",
            "            129,\n",
            "            85,\n",
            "            50\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.18333333333333332,\n",
            "        \"mean_em\": 0.5476404249668121,\n",
            "        \"std_em\": 0.23854375781274115,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            75,\n",
            "            35,\n",
            "            51,\n",
            "            5,\n",
            "            36,\n",
            "            120,\n",
            "            54,\n",
            "            17\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.11666666666666667,\n",
            "        \"mean_em\": 0.5153149624665578,\n",
            "        \"std_em\": 0.20818116219278585,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            53,\n",
            "            122,\n",
            "            80,\n",
            "            113,\n",
            "            49,\n",
            "            33,\n",
            "            73,\n",
            "            50\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.14166666666666666,\n",
            "        \"mean_em\": 0.5195105606069167,\n",
            "        \"std_em\": 0.2258197263407739,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            108,\n",
            "            52,\n",
            "            66,\n",
            "            110,\n",
            "            82,\n",
            "            130,\n",
            "            86,\n",
            "            68\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.21666666666666667,\n",
            "        \"mean_em\": 0.559059851616621,\n",
            "        \"std_em\": 0.2530425736189238,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            75,\n",
            "            35,\n",
            "            51,\n",
            "            5,\n",
            "            36,\n",
            "            120,\n",
            "            54,\n",
            "            17,\n",
            "            121,\n",
            "            119,\n",
            "            66,\n",
            "            114\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.11666666666666667,\n",
            "        \"mean_em\": 0.503939609353741,\n",
            "        \"std_em\": 0.21080433503341534,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            103,\n",
            "            60,\n",
            "            65,\n",
            "            129,\n",
            "            85,\n",
            "            50,\n",
            "            33,\n",
            "            89,\n",
            "            53,\n",
            "            106,\n",
            "            105,\n",
            "            107\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.15833333333333333,\n",
            "        \"mean_em\": 0.5475555285811424,\n",
            "        \"std_em\": 0.24710563227613022,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            123,\n",
            "            109,\n",
            "            111,\n",
            "            108,\n",
            "            124,\n",
            "            67,\n",
            "            104,\n",
            "            64,\n",
            "            57,\n",
            "            79,\n",
            "            70,\n",
            "            2\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    }\n",
            "]\n",
            "\n",
            "Lenght of test: 244\n",
            "Getting completions...\n",
            "Evaluating test set performance...\n",
            "gpt3.5 Accuracy:  0.11885245901639344\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.5050514100394288\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.20895112786745743\n",
            "Test results: {\n",
            "    \"model\": \"gpt3.5\",\n",
            "    \"acc\": 0.11885245901639344,\n",
            "    \"mean_em\": 0.5050514100394288,\n",
            "    \"std_em\": 0.20895112786745743,\n",
            "    \"few_shot_sample_indices\": [\n",
            "        75,\n",
            "        35,\n",
            "        51,\n",
            "        5,\n",
            "        36,\n",
            "        120,\n",
            "        54,\n",
            "        17,\n",
            "        121,\n",
            "        119,\n",
            "        66,\n",
            "        114\n",
            "    ],\n",
            "    \"few_shot_samples\": 12,\n",
            "    \"temperature\": 0.0,\n",
            "    \"eval_split\": \"test\",\n",
            "    \"dataset_name\": \"metaphor_list\",\n",
            "    \"fine_tuning\": false\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"$WORKDIR\" python -m src.main --llm gpt3.5 --temperature 0 --dataset metaphor_list --task source_domain_prediction --seed 1 --evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7YWEoprlx4R"
      },
      "source": [
        "## Metaphor List - Target domain prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlNFBcbsmapB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15505cdd-16f3-4c50-cc49-55d14c3d98d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-29 12:18:16.583774: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-29 12:18:16.583830: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-29 12:18:16.583865: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-29 12:18:17.731368: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "User is already logged in.\n",
            "\n",
            "llm: gpt3.5\n",
            "fine_tuned_model_path: None\n",
            "dataset: metaphor_list\n",
            "task: target_domain_prediction\n",
            "temperature: 0.0\n",
            "seed: 1\n",
            "evaluate: True\n",
            "fine_tuning: False\n",
            "\n",
            "\n",
            "Lenght of train: 132\n",
            "Lenght of valid: 120\n",
            "Train indices: [\n",
            "    [\n",
            "        75,\n",
            "        35\n",
            "    ],\n",
            "    [\n",
            "        110,\n",
            "        107\n",
            "    ],\n",
            "    [\n",
            "        125,\n",
            "        106\n",
            "    ],\n",
            "    [\n",
            "        75,\n",
            "        35,\n",
            "        51,\n",
            "        5\n",
            "    ],\n",
            "    [\n",
            "        125,\n",
            "        108,\n",
            "        58,\n",
            "        59\n",
            "    ],\n",
            "    [\n",
            "        50,\n",
            "        121,\n",
            "        79,\n",
            "        113\n",
            "    ],\n",
            "    [\n",
            "        75,\n",
            "        35,\n",
            "        51,\n",
            "        5,\n",
            "        36,\n",
            "        120\n",
            "    ],\n",
            "    [\n",
            "        126,\n",
            "        49,\n",
            "        78,\n",
            "        95,\n",
            "        107,\n",
            "        57\n",
            "    ],\n",
            "    [\n",
            "        104,\n",
            "        60,\n",
            "        65,\n",
            "        129,\n",
            "        85,\n",
            "        50\n",
            "    ],\n",
            "    [\n",
            "        75,\n",
            "        35,\n",
            "        51,\n",
            "        5,\n",
            "        36,\n",
            "        120,\n",
            "        54,\n",
            "        17\n",
            "    ],\n",
            "    [\n",
            "        53,\n",
            "        122,\n",
            "        80,\n",
            "        113,\n",
            "        49,\n",
            "        33,\n",
            "        73,\n",
            "        50\n",
            "    ],\n",
            "    [\n",
            "        108,\n",
            "        52,\n",
            "        66,\n",
            "        110,\n",
            "        82,\n",
            "        130,\n",
            "        86,\n",
            "        68\n",
            "    ],\n",
            "    [\n",
            "        75,\n",
            "        35,\n",
            "        51,\n",
            "        5,\n",
            "        36,\n",
            "        120,\n",
            "        54,\n",
            "        17,\n",
            "        121,\n",
            "        119,\n",
            "        66,\n",
            "        114\n",
            "    ],\n",
            "    [\n",
            "        103,\n",
            "        60,\n",
            "        65,\n",
            "        129,\n",
            "        85,\n",
            "        50,\n",
            "        33,\n",
            "        89,\n",
            "        53,\n",
            "        106,\n",
            "        105,\n",
            "        107\n",
            "    ],\n",
            "    [\n",
            "        123,\n",
            "        109,\n",
            "        111,\n",
            "        108,\n",
            "        124,\n",
            "        67,\n",
            "        104,\n",
            "        64,\n",
            "        57,\n",
            "        79,\n",
            "        70,\n",
            "        2\n",
            "    ]\n",
            "]\n",
            "\n",
            "Number of parameter combinations: 15 \n",
            "\n",
            "[{'few_shot_sample_indices': [75, 35]}, {'few_shot_sample_indices': [110, 107]}, {'few_shot_sample_indices': [125, 106]}, {'few_shot_sample_indices': [75, 35, 51, 5]}, {'few_shot_sample_indices': [125, 108, 58, 59]}, {'few_shot_sample_indices': [50, 121, 79, 113]}, {'few_shot_sample_indices': [75, 35, 51, 5, 36, 120]}, {'few_shot_sample_indices': [126, 49, 78, 95, 107, 57]}, {'few_shot_sample_indices': [104, 60, 65, 129, 85, 50]}, {'few_shot_sample_indices': [75, 35, 51, 5, 36, 120, 54, 17]}, {'few_shot_sample_indices': [53, 122, 80, 113, 49, 33, 73, 50]}, {'few_shot_sample_indices': [108, 52, 66, 110, 82, 130, 86, 68]}, {'few_shot_sample_indices': [75, 35, 51, 5, 36, 120, 54, 17, 121, 119, 66, 114]}, {'few_shot_sample_indices': [103, 60, 65, 129, 85, 50, 33, 89, 53, 106, 105, 107]}, {'few_shot_sample_indices': [123, 109, 111, 108, 124, 67, 104, 64, 57, 79, 70, 2]}]\n",
            "\n",
            "Current few-shot sample: 1 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' growth/development ', but wanted ' beliefs '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' growth/development ', but wanted ' people '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' progress/advancement ', but wanted ' sex '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' thought/idea ', but wanted ' ideas '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' location/direction ', but wanted ' entrance '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' food/eating ', but wanted ' eating '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' search ', but wanted ' missing  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sound ', but wanted ' bells  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' time ', but wanted ' time  '\n",
            "gpt3.5 Accuracy:  0.11666666666666667\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.5145618829876184\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.2518417964740259\n",
            "\n",
            "Current few-shot sample: 2 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' ideas/beliefs ', but wanted ' beliefs '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' ideas/thoughts ', but wanted ' beliefs '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' progress/achievement ', but wanted ' success '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' progress/achievement ', but wanted ' subjects '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' emotions/behavior ', but wanted ' disgust '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' progress/advancement ', but wanted ' harm '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' morality/ethics ', but wanted ' morality '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' wealth/morality ', but wanted ' creation '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' talent/creativity ', but wanted ' people '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' time/progress ', but wanted ' schedule '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' heart/health ', but wanted ' people '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' persuasion/influence ', but wanted ' force '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' ideas/beliefs ', but wanted ' beliefs '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' pain/health ', but wanted ' existence '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' knowledge/understanding ', but wanted ' darkness '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sports/competition ', but wanted ' competition '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' illness/disease ', but wanted ' illness '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' language/communication ', but wanted ' words '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' difficulties/problems ', but wanted ' harm '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' recognition/achievement ', but wanted ' responsibilities '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sports/competition ', but wanted ' harm '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' emotions/feelings ', but wanted ' conceit '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' assessment/evaluation ', but wanted ' perception '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' pregnancy/childbirth ', but wanted ' existence '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' collaboration/partnership ', but wanted ' difficulties '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' restrictions/limitations ', but wanted ' obligations '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' finance/economics ', but wanted ' money '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' difficulty/challenge ', but wanted ' problem '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' understanding/knowledge ', but wanted ' intelligence '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' love/affection ', but wanted ' love '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' strategy/games ', but wanted ' competition '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sunlight/heat ', but wanted ' light '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' thoughts/ideas ', but wanted ' ideas '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' attraction/relationships ', but wanted ' desire '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' perception/interpretation ', but wanted ' communication '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' location/direction ', but wanted ' entrance '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' childhood/parenting ', but wanted ' sitting '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' food/eating ', but wanted ' eating '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' office/workplace ', but wanted ' desk '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' science or research ', but wanted ' missing  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sound ', but wanted ' bells  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' time ', but wanted ' time  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' listening/attention ', but wanted ' listening '\n",
            "gpt3.5 Accuracy:  0.06666666666666667\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.36676665022969246\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.3189085834757746\n",
            "\n",
            "Current few-shot sample: 3 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' amount/quantity ', but wanted ' amount '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' ideas/beliefs ', but wanted ' beliefs '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' ideas/thoughts ', but wanted ' beliefs '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' progress/achievement ', but wanted ' success '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' profession/occupation ', but wanted ' subjects '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' progress/advancement ', but wanted ' subjects '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' emotions/feelings ', but wanted ' disgust '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' progress/advancement ', but wanted ' harm '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' morality/ethics ', but wanted ' morality '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' control/influence ', but wanted ' force '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' ideas/beliefs ', but wanted ' beliefs '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sports/football ', but wanted ' competition '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' illness/disease ', but wanted ' illness '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' words/language ', but wanted ' words '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' recognition/achievement ', but wanted ' responsibilities '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' emotions/feelings ', but wanted ' conceit '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' personality/identity ', but wanted ' change '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' obligations/commitments ', but wanted ' obligations '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' light/darkness ', but wanted ' darkness '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' finance/economics ', but wanted ' money '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' emotions/feelings ', but wanted ' people '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' time/calendar ', but wanted ' time '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' love/affection ', but wanted ' love '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' lifespan/health ', but wanted ' final state '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' game/sport ', but wanted ' competition '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' thoughts/ideas ', but wanted ' ideas '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' time/chronology ', but wanted ' eating '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' size/measurements ', but wanted ' rooms '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' search or investigation ', but wanted ' missing  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sound ', but wanted ' bells  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' time ', but wanted ' time  '\n",
            "gpt3.5 Accuracy:  0.08333333333333333\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.4275389698644479\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.3109855807385942\n",
            "\n",
            "Current few-shot sample: 4 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' ideas/thoughts ', but wanted ' beliefs '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' talent/creativity ', but wanted ' people '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' progress/advancement ', but wanted ' sex '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' scientist ', but wanted ' missing  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sound ', but wanted ' bells  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' time ', but wanted ' time  '\n",
            "gpt3.5 Accuracy:  0.15833333333333333\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.5509819348653158\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.2575263940415442\n",
            "\n",
            "Current few-shot sample: 5 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' amount/quantity ', but wanted ' amount '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' progress/advancement ', but wanted ' harm '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' talent/creativity ', but wanted ' people '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' time/progress ', but wanted ' schedule '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' energy/enthusiasm ', but wanted ' lust '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' problem/solution ', but wanted ' problem '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' pain/health ', but wanted ' existence '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sports/competition ', but wanted ' competition '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' illness/disease ', but wanted ' illness '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' pregnancy/childbirth ', but wanted ' existence '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' unity/cooperation ', but wanted ' difficulties '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' restriction/limitation ', but wanted ' obligations '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' control/possession ', but wanted ' mind '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' location/position ', but wanted ' importance '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' struggle/survival ', but wanted ' defeat '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' understanding/knowledge ', but wanted ' intelligence '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' relaxation/leisure ', but wanted ' light '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' thought/consideration ', but wanted ' ideas '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' search/missing person ', but wanted ' missing  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sound ', but wanted ' bells  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' time/education ', but wanted ' time  '\n",
            "gpt3.5 Accuracy:  0.15833333333333333\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.4828156903386116\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.30856773849213853\n",
            "\n",
            "Current few-shot sample: 6 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' amount/quantity ', but wanted ' amount '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' progress/achievement ', but wanted ' success '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' profession/industry/subject ', but wanted ' subjects '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' progress/advancement ', but wanted ' subjects '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' morality/ethics ', but wanted ' morality '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' progress/success ', but wanted ' schedule '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' power/influence ', but wanted ' force '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' precariousness/danger ', but wanted ' harm '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sports/football ', but wanted ' competition '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' illness/disease ', but wanted ' illness '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' recognition/achievement ', but wanted ' responsibilities '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' problems/issues ', but wanted ' thinking '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' progress/direction ', but wanted ' problem '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' progress/advancement ', but wanted ' sex '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' obligations/commitments ', but wanted ' obligations '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' energy/activity ', but wanted ' active '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' emotions/feelings ', but wanted ' people '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' location/position ', but wanted ' importance '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' understanding/knowledge ', but wanted ' intelligence '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' progress/development ', but wanted ' love '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' frustration/anger ', but wanted ' anger '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' idea/thought ', but wanted ' ideas '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' scientist ', but wanted ' missing  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' doorbell ', but wanted ' bells  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' time ', but wanted ' time  '\n",
            "gpt3.5 Accuracy:  0.125\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.44870080798864365\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.3093343684371543\n",
            "\n",
            "Current few-shot sample: 7 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' ideas/beliefs ', but wanted ' beliefs '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' ideas/thoughts ', but wanted ' beliefs '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' light/darkness ', but wanted ' darkness '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' thought/idea ', but wanted ' ideas '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' scientists ', but wanted ' missing  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sounds ', but wanted ' bells  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' time ', but wanted ' time  '\n",
            "gpt3.5 Accuracy:  0.18333333333333332\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.5625479752818744\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.26728179432529303\n",
            "\n",
            "Current few-shot sample: 8 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' ideas/beliefs ', but wanted ' beliefs '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' possession/territory ', but wanted ' competition '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' progress/direction ', but wanted ' problem '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' possession/control ', but wanted ' mind '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' ideas/thoughts ', but wanted ' ideas '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' finding a person ', but wanted ' missing  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sound ', but wanted ' bells  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' time ', but wanted ' time  '\n",
            "gpt3.5 Accuracy:  0.18333333333333332\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.5785405337810516\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.26965771253312937\n",
            "\n",
            "Current few-shot sample: 9 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' profession/occupation ', but wanted ' subjects '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' talent/creativity ', but wanted ' people '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' progress/advancement ', but wanted ' sex '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' thoughts/ideas ', but wanted ' ideas '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' scientist ', but wanted ' missing  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sound ', but wanted ' bells  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' instruction ', but wanted ' time  '\n",
            "gpt3.5 Accuracy:  0.21666666666666667\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.5672243997454643\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.2781472942775005\n",
            "\n",
            "Current few-shot sample: 10 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' profession/industry ', but wanted ' subjects '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' progress/advancement ', but wanted ' sex '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' life/death ', but wanted ' final state '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' scientists ', but wanted ' missing  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sound ', but wanted ' bells  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' time ', but wanted ' time  '\n",
            "gpt3.5 Accuracy:  0.20833333333333334\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.5747990772128105\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.27221172478515554\n",
            "\n",
            "Current few-shot sample: 11 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' profession/industry ', but wanted ' subjects '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' talent/creativity ', but wanted ' people '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' progress/advancement ', but wanted ' sex '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' motivation/inspiration ', but wanted ' people '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' thought/idea ', but wanted ' ideas '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' search ', but wanted ' missing  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sound ', but wanted ' bells  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' time ', but wanted ' time  '\n",
            "gpt3.5 Accuracy:  0.2\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.5565122393270333\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.28030927884654416\n",
            "\n",
            "Current few-shot sample: 12 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' profession/industry ', but wanted ' subjects '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' support/love ', but wanted ' lover '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sports/competition ', but wanted ' competition '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' progress/advancement ', but wanted ' sex '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' excitement/enthusiasm ', but wanted ' people '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' frustration/anger ', but wanted ' anger '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' thought/idea ', but wanted ' ideas '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' scientist ', but wanted ' missing  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sound ', but wanted ' bells  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' instruction ', but wanted ' time  '\n",
            "gpt3.5 Accuracy:  0.21666666666666667\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.5591328456997872\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.28715168532411434\n",
            "\n",
            "Current few-shot sample: 13 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' thoughts/ideas ', but wanted ' ideas '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' scientists ', but wanted ' missing  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' doorbell ', but wanted ' bells  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' hours ', but wanted ' time  '\n",
            "gpt3.5 Accuracy:  0.24166666666666667\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.5970600749055545\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.2719443877496986\n",
            "\n",
            "Current few-shot sample: 14 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' progress/advancement ', but wanted ' sex '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' scientist ', but wanted ' missing  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sound ', but wanted ' bells  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' instruction ', but wanted ' time  '\n",
            "gpt3.5 Accuracy:  0.19166666666666668\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.5760494197408358\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.24963005042193198\n",
            "\n",
            "Current few-shot sample: 15 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' love/affection ', but wanted ' lover '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' thoughts/ideas ', but wanted ' ideas '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' scientist ', but wanted ' missing  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sound ', but wanted ' bells  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' time ', but wanted ' time  '\n",
            "gpt3.5 Accuracy:  0.175\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.5803900644183159\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.25656586805895054\n",
            "Validation results: [\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.11666666666666667,\n",
            "        \"mean_em\": 0.5145618829876184,\n",
            "        \"std_em\": 0.2518417964740259,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            75,\n",
            "            35\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.06666666666666667,\n",
            "        \"mean_em\": 0.36676665022969246,\n",
            "        \"std_em\": 0.3189085834757746,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            110,\n",
            "            107\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.08333333333333333,\n",
            "        \"mean_em\": 0.4275389698644479,\n",
            "        \"std_em\": 0.3109855807385942,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            125,\n",
            "            106\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.15833333333333333,\n",
            "        \"mean_em\": 0.5509819348653158,\n",
            "        \"std_em\": 0.2575263940415442,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            75,\n",
            "            35,\n",
            "            51,\n",
            "            5\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.15833333333333333,\n",
            "        \"mean_em\": 0.4828156903386116,\n",
            "        \"std_em\": 0.30856773849213853,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            125,\n",
            "            108,\n",
            "            58,\n",
            "            59\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.125,\n",
            "        \"mean_em\": 0.44870080798864365,\n",
            "        \"std_em\": 0.3093343684371543,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            50,\n",
            "            121,\n",
            "            79,\n",
            "            113\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.18333333333333332,\n",
            "        \"mean_em\": 0.5625479752818744,\n",
            "        \"std_em\": 0.26728179432529303,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            75,\n",
            "            35,\n",
            "            51,\n",
            "            5,\n",
            "            36,\n",
            "            120\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.18333333333333332,\n",
            "        \"mean_em\": 0.5785405337810516,\n",
            "        \"std_em\": 0.26965771253312937,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            126,\n",
            "            49,\n",
            "            78,\n",
            "            95,\n",
            "            107,\n",
            "            57\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.21666666666666667,\n",
            "        \"mean_em\": 0.5672243997454643,\n",
            "        \"std_em\": 0.2781472942775005,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            104,\n",
            "            60,\n",
            "            65,\n",
            "            129,\n",
            "            85,\n",
            "            50\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.20833333333333334,\n",
            "        \"mean_em\": 0.5747990772128105,\n",
            "        \"std_em\": 0.27221172478515554,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            75,\n",
            "            35,\n",
            "            51,\n",
            "            5,\n",
            "            36,\n",
            "            120,\n",
            "            54,\n",
            "            17\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.2,\n",
            "        \"mean_em\": 0.5565122393270333,\n",
            "        \"std_em\": 0.28030927884654416,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            53,\n",
            "            122,\n",
            "            80,\n",
            "            113,\n",
            "            49,\n",
            "            33,\n",
            "            73,\n",
            "            50\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.21666666666666667,\n",
            "        \"mean_em\": 0.5591328456997872,\n",
            "        \"std_em\": 0.28715168532411434,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            108,\n",
            "            52,\n",
            "            66,\n",
            "            110,\n",
            "            82,\n",
            "            130,\n",
            "            86,\n",
            "            68\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.24166666666666667,\n",
            "        \"mean_em\": 0.5970600749055545,\n",
            "        \"std_em\": 0.2719443877496986,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            75,\n",
            "            35,\n",
            "            51,\n",
            "            5,\n",
            "            36,\n",
            "            120,\n",
            "            54,\n",
            "            17,\n",
            "            121,\n",
            "            119,\n",
            "            66,\n",
            "            114\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.19166666666666668,\n",
            "        \"mean_em\": 0.5760494197408358,\n",
            "        \"std_em\": 0.24963005042193198,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            103,\n",
            "            60,\n",
            "            65,\n",
            "            129,\n",
            "            85,\n",
            "            50,\n",
            "            33,\n",
            "            89,\n",
            "            53,\n",
            "            106,\n",
            "            105,\n",
            "            107\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.175,\n",
            "        \"mean_em\": 0.5803900644183159,\n",
            "        \"std_em\": 0.25656586805895054,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            123,\n",
            "            109,\n",
            "            111,\n",
            "            108,\n",
            "            124,\n",
            "            67,\n",
            "            104,\n",
            "            64,\n",
            "            57,\n",
            "            79,\n",
            "            70,\n",
            "            2\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"metaphor_list\"\n",
            "    }\n",
            "]\n",
            "\n",
            "Lenght of test: 244\n",
            "Getting completions...\n",
            "Evaluating test set performance...\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' issue/problem ', but wanted ' problem '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' direction ', but wanted ' scanning  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' person ', but wanted ' arriving  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' routes ', but wanted ' paths   '\n",
            "gpt3.5 Accuracy:  0.1885245901639344\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.5966382319809961\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.2387762086396725\n",
            "Test results: {\n",
            "    \"model\": \"gpt3.5\",\n",
            "    \"acc\": 0.1885245901639344,\n",
            "    \"mean_em\": 0.5966382319809961,\n",
            "    \"std_em\": 0.2387762086396725,\n",
            "    \"few_shot_sample_indices\": [\n",
            "        75,\n",
            "        35,\n",
            "        51,\n",
            "        5,\n",
            "        36,\n",
            "        120,\n",
            "        54,\n",
            "        17,\n",
            "        121,\n",
            "        119,\n",
            "        66,\n",
            "        114\n",
            "    ],\n",
            "    \"few_shot_samples\": 12,\n",
            "    \"temperature\": 0.0,\n",
            "    \"eval_split\": \"test\",\n",
            "    \"dataset_name\": \"metaphor_list\",\n",
            "    \"fine_tuning\": false\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"$WORKDIR\" python -m src.main --llm gpt3.5 --temperature 0 --dataset metaphor_list --task target_domain_prediction --seed 1 --evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKzZF95slx7M"
      },
      "source": [
        "## LCC (EN) - Source domain prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EdAZLCDjmbdj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "730e03a1-b777-4d22-ae92-c52b6801dd55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-10 00:36:12.455378: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-10 00:36:12.455438: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-10 00:36:12.455472: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-10 00:36:14.319499: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "User is already logged in.\n",
            "\n",
            "llm: gpt3.5\n",
            "fine_tuned_model_path: None\n",
            "dataset: lcc_en_subset\n",
            "task: source_domain_prediction\n",
            "temperature: 0.0\n",
            "seed: 1\n",
            "evaluate: True\n",
            "fine_tuning: False\n",
            "\n",
            "\n",
            "Lenght of train: 1206\n",
            "Lenght of valid: 172\n",
            "Train indices: [\n",
            "    [\n",
            "        200,\n",
            "        584\n",
            "    ],\n",
            "    [\n",
            "        638,\n",
            "        307\n",
            "    ],\n",
            "    [\n",
            "        628,\n",
            "        607\n",
            "    ],\n",
            "    [\n",
            "        200,\n",
            "        584,\n",
            "        807,\n",
            "        895\n",
            "    ],\n",
            "    [\n",
            "        627,\n",
            "        606,\n",
            "        245,\n",
            "        458\n",
            "    ],\n",
            "    [\n",
            "        467,\n",
            "        607,\n",
            "        490,\n",
            "        189\n",
            "    ],\n",
            "    [\n",
            "        200,\n",
            "        584,\n",
            "        807,\n",
            "        895,\n",
            "        336,\n",
            "        314\n",
            "    ],\n",
            "    [\n",
            "        640,\n",
            "        687,\n",
            "        1039,\n",
            "        190,\n",
            "        1089,\n",
            "        284\n",
            "    ],\n",
            "    [\n",
            "        49,\n",
            "        1152,\n",
            "        309,\n",
            "        1026,\n",
            "        869,\n",
            "        826\n",
            "    ],\n",
            "    [\n",
            "        200,\n",
            "        584,\n",
            "        807,\n",
            "        895,\n",
            "        336,\n",
            "        314,\n",
            "        311,\n",
            "        198\n",
            "    ],\n",
            "    [\n",
            "        469,\n",
            "        608,\n",
            "        492,\n",
            "        189,\n",
            "        1026,\n",
            "        943,\n",
            "        204,\n",
            "        1152\n",
            "    ],\n",
            "    [\n",
            "        49,\n",
            "        389,\n",
            "        308,\n",
            "        1024,\n",
            "        810,\n",
            "        1027,\n",
            "        316,\n",
            "        397\n",
            "    ],\n",
            "    [\n",
            "        200,\n",
            "        584,\n",
            "        807,\n",
            "        895,\n",
            "        336,\n",
            "        314,\n",
            "        311,\n",
            "        198,\n",
            "        1029,\n",
            "        189,\n",
            "        190,\n",
            "        49\n",
            "    ],\n",
            "    [\n",
            "        50,\n",
            "        1152,\n",
            "        312,\n",
            "        1027,\n",
            "        870,\n",
            "        827,\n",
            "        773,\n",
            "        915,\n",
            "        670,\n",
            "        608,\n",
            "        82,\n",
            "        887\n",
            "    ],\n",
            "    [\n",
            "        941,\n",
            "        305,\n",
            "        948,\n",
            "        333,\n",
            "        246,\n",
            "        145,\n",
            "        689,\n",
            "        1160,\n",
            "        606,\n",
            "        561,\n",
            "        1058,\n",
            "        564\n",
            "    ]\n",
            "]\n",
            "\n",
            "Number of parameter combinations: 15 \n",
            "\n",
            "[{'few_shot_sample_indices': [200, 584]}, {'few_shot_sample_indices': [638, 307]}, {'few_shot_sample_indices': [628, 607]}, {'few_shot_sample_indices': [200, 584, 807, 895]}, {'few_shot_sample_indices': [627, 606, 245, 458]}, {'few_shot_sample_indices': [467, 607, 490, 189]}, {'few_shot_sample_indices': [200, 584, 807, 895, 336, 314]}, {'few_shot_sample_indices': [640, 687, 1039, 190, 1089, 284]}, {'few_shot_sample_indices': [49, 1152, 309, 1026, 869, 826]}, {'few_shot_sample_indices': [200, 584, 807, 895, 336, 314, 311, 198]}, {'few_shot_sample_indices': [469, 608, 492, 189, 1026, 943, 204, 1152]}, {'few_shot_sample_indices': [49, 389, 308, 1024, 810, 1027, 316, 397]}, {'few_shot_sample_indices': [200, 584, 807, 895, 336, 314, 311, 198, 1029, 189, 190, 49]}, {'few_shot_sample_indices': [50, 1152, 312, 1027, 870, 827, 773, 915, 670, 608, 82, 887]}, {'few_shot_sample_indices': [941, 305, 948, 333, 246, 145, 689, 1160, 606, 561, 1058, 564]}]\n",
            "\n",
            "Current few-shot sample: 1 / 15\n",
            "[==================================================] 100.0% 958.5/958.4MB downloaded\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sports/game ', but wanted ' game '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' leadership/royalty ', but wanted ' human body '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' entertainment/media ', but wanted ' story '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' disease/contamination ', but wanted ' emotion experiencer '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' clothing/fashion ', but wanted ' clothing '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' illness/disease ', but wanted ' disease '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' clothing/accessories ', but wanted ' clothing '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' prison/escape ', but wanted ' crime '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' war/battle ', but wanted ' war '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sports/competition ', but wanted ' game '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' disease/illness ', but wanted ' crop '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' magic/witchcraft ', but wanted ' magic '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sunrise/dawn ', but wanted ' light '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' clothing/accessories ', but wanted ' clothing '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' illness/disease ', but wanted ' disease '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' disease/health ', but wanted ' disease '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' illness/disease ', but wanted ' crime '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' ocean/waves ', but wanted ' body of water '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' disease/illness ', but wanted ' war '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' tools/weapons ', but wanted ' emotion experiencer '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' race/running ', but wanted ' game '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sports/competition ', but wanted ' game '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' illness/disease ', but wanted ' disease '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' battle/war ', but wanted ' war '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' fireworks/explosions ', but wanted ' crop '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' battle/warfare ', but wanted ' struggle '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' magic/trickery ', but wanted ' magic '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' protection/guardianship ', but wanted ' protection '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' journey/travel ', but wanted ' story '\n",
            "gpt3.5 Accuracy:  0.11046511627906977\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.5238023343127828\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.3053928542981824\n",
            "\n",
            "Current few-shot sample: 2 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' building/construction ', but wanted ' story '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sports/competition ', but wanted ' game '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' construction/industry ', but wanted ' tool '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sports/competition ', but wanted ' game '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' disease/illness ', but wanted ' disease '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' building/construction ', but wanted ' building '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' battle/warfare ', but wanted ' body of water '\n",
            "gpt3.5 Accuracy:  0.14534883720930233\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.5656120888888836\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.2533644303809278\n",
            "\n",
            "Current few-shot sample: 3 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' money/finance ', but wanted ' body of water '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government/politics ', but wanted ' protection '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sports/competition ', but wanted ' game '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' illness/affliction ', but wanted ' disease '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' gardening/landscaping ', but wanted ' machine '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' prison/escape ', but wanted ' crime '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government/politics ', but wanted ' resource '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' money/finance ', but wanted ' building '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' money/finance ', but wanted ' physical burden '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' magic/witchcraft ', but wanted ' magic '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' clothing/accessories ', but wanted ' clothing '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government/politics ', but wanted ' plant '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' machines/mechanics ', but wanted ' machine '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' illness/disease ', but wanted ' disease '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' economics/finance ', but wanted ' struggle '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government/politics ', but wanted ' resource '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' finance/business ', but wanted ' body of water '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government/politics ', but wanted ' protection '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' building/construction ', but wanted ' building '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' finance/economics ', but wanted ' physical burden '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' disease/illness ', but wanted ' disease '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' finance/economics ', but wanted ' physical burden '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government/politics ', but wanted ' resource '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government/politics ', but wanted ' clothing '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' building/house ', but wanted ' building '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sports/athletics ', but wanted ' game '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' economics/finance ', but wanted ' story '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government/politics ', but wanted ' body of water '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' disease/illness ', but wanted ' disease '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' machinery/levers ', but wanted ' machine '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' money/finance ', but wanted ' building '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' medicine/healthcare ', but wanted ' struggle '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government/politics ', but wanted ' building '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government/politics ', but wanted ' game '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' disease/epidemic ', but wanted ' story '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' money/finance ', but wanted ' body of water '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government/politics ', but wanted ' light '\n",
            "gpt3.5 Accuracy:  0.09302325581395349\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.4521868031385333\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.300570336322054\n",
            "\n",
            "Current few-shot sample: 4 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' structure/building ', but wanted ' building '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' clothing/accessories ', but wanted ' clothing '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' battle/warfare ', but wanted ' struggle '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' battle/war ', but wanted ' game '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' disease/illness ', but wanted ' disease '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' battle/war ', but wanted ' war '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' battle/war ', but wanted ' struggle '\n",
            "gpt3.5 Accuracy:  0.20930232558139536\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.6133651595649331\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.2655081172556925\n",
            "\n",
            "Current few-shot sample: 5 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' game/sport ', but wanted ' game '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' battle/war ', but wanted ' building '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' battle/war ', but wanted ' war '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sports/competition ', but wanted ' game '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' structure/building ', but wanted ' building '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' building/construction ', but wanted ' building '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' clothing/accessories ', but wanted ' clothing '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' shield/protection ', but wanted ' protection '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' building/construction ', but wanted ' building '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' building/construction ', but wanted ' plant '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' battle/war ', but wanted ' struggle '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' life/death ', but wanted ' physical harm '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' race/competition ', but wanted ' game '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' battle/war ', but wanted ' war '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' battle/war ', but wanted ' struggle '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' building/construction ', but wanted ' building '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' ocean/waves ', but wanted ' body of water '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' battle/war ', but wanted ' body of water '\n",
            "gpt3.5 Accuracy:  0.1744186046511628\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.5582302642423053\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.292175162384972\n",
            "\n",
            "Current few-shot sample: 6 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' clothing/accessories ', but wanted ' clothing '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' war/battle ', but wanted ' war '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' clothing/accessories ', but wanted ' clothing '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' building/construction ', but wanted ' building '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' direction/location ', but wanted ' vision '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' foundation/support ', but wanted ' building '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' food/nutrition ', but wanted ' clothing '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sports/competition ', but wanted ' game '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' illness/disease ', but wanted ' disease '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' war/battle ', but wanted ' war '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' battle/war ', but wanted ' struggle '\n",
            "gpt3.5 Accuracy:  0.11046511627906977\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.5906653761170632\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.2530164192103677\n",
            "\n",
            "Current few-shot sample: 7 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' game/sport ', but wanted ' game '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' life/death ', but wanted ' physical harm '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' race/competition ', but wanted ' game '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' disease/illness ', but wanted ' disease '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' fire/explosions ', but wanted ' crop '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' magic/trickery ', but wanted ' magic '\n",
            "gpt3.5 Accuracy:  0.21511627906976744\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.6297119444366112\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.25792306680940236\n",
            "\n",
            "Current few-shot sample: 8 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' giving/receiving ', but wanted ' body of water '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' tools/weapons ', but wanted ' crime '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' battle/warfare ', but wanted ' struggle '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' story/narrative ', but wanted ' story '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' life/death ', but wanted ' physical harm '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' race/competition ', but wanted ' game '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' battle/war ', but wanted ' struggle '\n",
            "gpt3.5 Accuracy:  0.2558139534883721\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.6251513689409854\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.2693411161487279\n",
            "\n",
            "Current few-shot sample: 9 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' clothing/accessories ', but wanted ' clothing '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' battle/war ', but wanted ' struggle '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' battle/war ', but wanted ' game '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' battle/war ', but wanted ' struggle '\n",
            "gpt3.5 Accuracy:  0.10465116279069768\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.5172001125161038\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.23824387118059423\n",
            "\n",
            "Current few-shot sample: 10 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' game/sport ', but wanted ' game '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' building/construction ', but wanted ' building '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' dream/nightmare ', but wanted ' emotion experiencer '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' disease/illness ', but wanted ' disease '\n",
            "gpt3.5 Accuracy:  0.19767441860465115\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.6074142833781797\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.24272018943055879\n",
            "\n",
            "Current few-shot sample: 11 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' structure/building ', but wanted ' building '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' clothing/accessories ', but wanted ' clothing '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' dream/nightmare ', but wanted ' emotion experiencer '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' journey/travel ', but wanted ' vision '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' race/competition ', but wanted ' game '\n",
            "gpt3.5 Accuracy:  0.1744186046511628\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.58974312826298\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.24034193112324514\n",
            "\n",
            "Current few-shot sample: 12 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' giving/receiving ', but wanted ' body of water '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' building/construction ', but wanted ' building '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sickness/illness ', but wanted ' crime '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' battle/war ', but wanted ' struggle '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' magic/mystery ', but wanted ' magic '\n",
            "gpt3.5 Accuracy:  0.1686046511627907\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.5789877776121504\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.2598601388059603\n",
            "\n",
            "Current few-shot sample: 13 / 15\n",
            "gpt3.5 Accuracy:  0.20930232558139536\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.6223963020845901\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.2263268678286586\n",
            "\n",
            "Current few-shot sample: 14 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' performance/entertainment ', but wanted ' story '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' battle/war ', but wanted ' struggle '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' clothing/accessories ', but wanted ' clothing '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' dream/nightmare ', but wanted ' emotion experiencer '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' battle/war ', but wanted ' struggle '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' race/competition ', but wanted ' game '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' battle/war ', but wanted ' war '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' fire/explosions ', but wanted ' crop '\n",
            "gpt3.5 Accuracy:  0.29069767441860467\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.6342709087875\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.28612767470859035\n",
            "\n",
            "Current few-shot sample: 15 / 15\n",
            "gpt3.5 Accuracy:  0.29651162790697677\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.6347739173229351\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.25855721395201026\n",
            "Validation results: [\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.11046511627906977,\n",
            "        \"mean_em\": 0.5238023343127828,\n",
            "        \"std_em\": 0.3053928542981824,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            200,\n",
            "            584\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"source_domain_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.14534883720930233,\n",
            "        \"mean_em\": 0.5656120888888836,\n",
            "        \"std_em\": 0.2533644303809278,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            638,\n",
            "            307\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"source_domain_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.09302325581395349,\n",
            "        \"mean_em\": 0.4521868031385333,\n",
            "        \"std_em\": 0.300570336322054,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            628,\n",
            "            607\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"source_domain_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.20930232558139536,\n",
            "        \"mean_em\": 0.6133651595649331,\n",
            "        \"std_em\": 0.2655081172556925,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            200,\n",
            "            584,\n",
            "            807,\n",
            "            895\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"source_domain_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.1744186046511628,\n",
            "        \"mean_em\": 0.5582302642423053,\n",
            "        \"std_em\": 0.292175162384972,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            627,\n",
            "            606,\n",
            "            245,\n",
            "            458\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"source_domain_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.11046511627906977,\n",
            "        \"mean_em\": 0.5906653761170632,\n",
            "        \"std_em\": 0.2530164192103677,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            467,\n",
            "            607,\n",
            "            490,\n",
            "            189\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"source_domain_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.21511627906976744,\n",
            "        \"mean_em\": 0.6297119444366112,\n",
            "        \"std_em\": 0.25792306680940236,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            200,\n",
            "            584,\n",
            "            807,\n",
            "            895,\n",
            "            336,\n",
            "            314\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"source_domain_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.2558139534883721,\n",
            "        \"mean_em\": 0.6251513689409854,\n",
            "        \"std_em\": 0.2693411161487279,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            640,\n",
            "            687,\n",
            "            1039,\n",
            "            190,\n",
            "            1089,\n",
            "            284\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"source_domain_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.10465116279069768,\n",
            "        \"mean_em\": 0.5172001125161038,\n",
            "        \"std_em\": 0.23824387118059423,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            49,\n",
            "            1152,\n",
            "            309,\n",
            "            1026,\n",
            "            869,\n",
            "            826\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"source_domain_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.19767441860465115,\n",
            "        \"mean_em\": 0.6074142833781797,\n",
            "        \"std_em\": 0.24272018943055879,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            200,\n",
            "            584,\n",
            "            807,\n",
            "            895,\n",
            "            336,\n",
            "            314,\n",
            "            311,\n",
            "            198\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"source_domain_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.1744186046511628,\n",
            "        \"mean_em\": 0.58974312826298,\n",
            "        \"std_em\": 0.24034193112324514,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            469,\n",
            "            608,\n",
            "            492,\n",
            "            189,\n",
            "            1026,\n",
            "            943,\n",
            "            204,\n",
            "            1152\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"source_domain_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.1686046511627907,\n",
            "        \"mean_em\": 0.5789877776121504,\n",
            "        \"std_em\": 0.2598601388059603,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            49,\n",
            "            389,\n",
            "            308,\n",
            "            1024,\n",
            "            810,\n",
            "            1027,\n",
            "            316,\n",
            "            397\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"source_domain_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.20930232558139536,\n",
            "        \"mean_em\": 0.6223963020845901,\n",
            "        \"std_em\": 0.2263268678286586,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            200,\n",
            "            584,\n",
            "            807,\n",
            "            895,\n",
            "            336,\n",
            "            314,\n",
            "            311,\n",
            "            198,\n",
            "            1029,\n",
            "            189,\n",
            "            190,\n",
            "            49\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"source_domain_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.29069767441860467,\n",
            "        \"mean_em\": 0.6342709087875,\n",
            "        \"std_em\": 0.28612767470859035,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            50,\n",
            "            1152,\n",
            "            312,\n",
            "            1027,\n",
            "            870,\n",
            "            827,\n",
            "            773,\n",
            "            915,\n",
            "            670,\n",
            "            608,\n",
            "            82,\n",
            "            887\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"source_domain_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.29651162790697677,\n",
            "        \"mean_em\": 0.6347739173229351,\n",
            "        \"std_em\": 0.25855721395201026,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            941,\n",
            "            305,\n",
            "            948,\n",
            "            333,\n",
            "            246,\n",
            "            145,\n",
            "            689,\n",
            "            1160,\n",
            "            606,\n",
            "            561,\n",
            "            1058,\n",
            "            564\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"source_domain_prediction\"\n",
            "    }\n",
            "]\n",
            "\n",
            "Lenght of test: 345\n",
            "Getting completions...\n",
            "Evaluating test set performance...\n",
            "gpt3.5 Accuracy:  0.3159420289855073\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.6481577589891959\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.2630968937816888\n",
            "Test results: {\n",
            "    \"model\": \"gpt3.5\",\n",
            "    \"acc\": 0.3159420289855073,\n",
            "    \"mean_em\": 0.6481577589891959,\n",
            "    \"std_em\": 0.2630968937816888,\n",
            "    \"few_shot_sample_indices\": [\n",
            "        941,\n",
            "        305,\n",
            "        948,\n",
            "        333,\n",
            "        246,\n",
            "        145,\n",
            "        689,\n",
            "        1160,\n",
            "        606,\n",
            "        561,\n",
            "        1058,\n",
            "        564\n",
            "    ],\n",
            "    \"few_shot_samples\": 12,\n",
            "    \"temperature\": 0.0,\n",
            "    \"eval_split\": \"test\",\n",
            "    \"dataset_name\": \"lcc_en_subset\",\n",
            "    \"fine_tuning\": false,\n",
            "    \"task_name\": \"source_domain_prediction\"\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"$WORKDIR\" python -m src.main --llm gpt3.5 --temperature 0 --dataset lcc_en_subset --task source_domain_prediction --seed 1 --evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRjZPk8glx-E"
      },
      "source": [
        "## LCC (EN) - Target domain prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "onQaTVGQmcVn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9ad09c9-76ae-417d-d88f-de01ef1d6425"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-10 01:00:47.088615: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-10 01:00:47.088683: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-10 01:00:47.088728: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-10 01:00:48.180964: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "User is already logged in.\n",
            "\n",
            "llm: gpt3.5\n",
            "fine_tuned_model_path: None\n",
            "dataset: lcc_en_subset\n",
            "task: target_domain_prediction\n",
            "temperature: 0.0\n",
            "seed: 1\n",
            "evaluate: True\n",
            "fine_tuning: False\n",
            "\n",
            "\n",
            "Lenght of train: 1206\n",
            "Lenght of valid: 172\n",
            "Train indices: [\n",
            "    [\n",
            "        200,\n",
            "        584\n",
            "    ],\n",
            "    [\n",
            "        638,\n",
            "        307\n",
            "    ],\n",
            "    [\n",
            "        628,\n",
            "        607\n",
            "    ],\n",
            "    [\n",
            "        200,\n",
            "        584,\n",
            "        807,\n",
            "        895\n",
            "    ],\n",
            "    [\n",
            "        627,\n",
            "        606,\n",
            "        245,\n",
            "        458\n",
            "    ],\n",
            "    [\n",
            "        467,\n",
            "        607,\n",
            "        490,\n",
            "        189\n",
            "    ],\n",
            "    [\n",
            "        200,\n",
            "        584,\n",
            "        807,\n",
            "        895,\n",
            "        336,\n",
            "        314\n",
            "    ],\n",
            "    [\n",
            "        640,\n",
            "        687,\n",
            "        1039,\n",
            "        190,\n",
            "        1089,\n",
            "        284\n",
            "    ],\n",
            "    [\n",
            "        49,\n",
            "        1152,\n",
            "        309,\n",
            "        1026,\n",
            "        869,\n",
            "        826\n",
            "    ],\n",
            "    [\n",
            "        200,\n",
            "        584,\n",
            "        807,\n",
            "        895,\n",
            "        336,\n",
            "        314,\n",
            "        311,\n",
            "        198\n",
            "    ],\n",
            "    [\n",
            "        469,\n",
            "        608,\n",
            "        492,\n",
            "        189,\n",
            "        1026,\n",
            "        943,\n",
            "        204,\n",
            "        1152\n",
            "    ],\n",
            "    [\n",
            "        49,\n",
            "        389,\n",
            "        308,\n",
            "        1024,\n",
            "        810,\n",
            "        1027,\n",
            "        316,\n",
            "        397\n",
            "    ],\n",
            "    [\n",
            "        200,\n",
            "        584,\n",
            "        807,\n",
            "        895,\n",
            "        336,\n",
            "        314,\n",
            "        311,\n",
            "        198,\n",
            "        1029,\n",
            "        189,\n",
            "        190,\n",
            "        49\n",
            "    ],\n",
            "    [\n",
            "        50,\n",
            "        1152,\n",
            "        312,\n",
            "        1027,\n",
            "        870,\n",
            "        827,\n",
            "        773,\n",
            "        915,\n",
            "        670,\n",
            "        608,\n",
            "        82,\n",
            "        887\n",
            "    ],\n",
            "    [\n",
            "        941,\n",
            "        305,\n",
            "        948,\n",
            "        333,\n",
            "        246,\n",
            "        145,\n",
            "        689,\n",
            "        1160,\n",
            "        606,\n",
            "        561,\n",
            "        1058,\n",
            "        564\n",
            "    ]\n",
            "]\n",
            "\n",
            "Number of parameter combinations: 15 \n",
            "\n",
            "[{'few_shot_sample_indices': [200, 584]}, {'few_shot_sample_indices': [638, 307]}, {'few_shot_sample_indices': [628, 607]}, {'few_shot_sample_indices': [200, 584, 807, 895]}, {'few_shot_sample_indices': [627, 606, 245, 458]}, {'few_shot_sample_indices': [467, 607, 490, 189]}, {'few_shot_sample_indices': [200, 584, 807, 895, 336, 314]}, {'few_shot_sample_indices': [640, 687, 1039, 190, 1089, 284]}, {'few_shot_sample_indices': [49, 1152, 309, 1026, 869, 826]}, {'few_shot_sample_indices': [200, 584, 807, 895, 336, 314, 311, 198]}, {'few_shot_sample_indices': [469, 608, 492, 189, 1026, 943, 204, 1152]}, {'few_shot_sample_indices': [49, 389, 308, 1024, 810, 1027, 316, 397]}, {'few_shot_sample_indices': [200, 584, 807, 895, 336, 314, 311, 198, 1029, 189, 190, 49]}, {'few_shot_sample_indices': [50, 1152, 312, 1027, 870, 827, 773, 915, 670, 608, 82, 887]}, {'few_shot_sample_indices': [941, 305, 948, 333, 246, 145, 689, 1160, 606, 561, 1058, 564]}]\n",
            "\n",
            "Current few-shot sample: 1 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' cost/wealth ', but wanted ' wealth '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' health/aging ', but wanted ' disease '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' life/death ', but wanted ' democracy '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' politics/campaigning ', but wanted ' bureaucracy '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' politics/law ', but wanted ' gun debate groups '\n",
            "gpt3.5 Accuracy:  0.4186046511627907\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.7310597997938477\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.2900123150543965\n",
            "\n",
            "Current few-shot sample: 2 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' politics/government ', but wanted ' democracy '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government/leadership ', but wanted ' government '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' guns/weapons ', but wanted ' guns '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government/society ', but wanted ' government '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' politics/government ', but wanted ' democracy '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' politics/campaigning ', but wanted ' bureaucracy '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government/levers ', but wanted ' government '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government/regulation ', but wanted ' government '\n",
            "gpt3.5 Accuracy:  0.4011627906976744\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.6880410207045633\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.3148646242682987\n",
            "\n",
            "Current few-shot sample: 3 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government/leadership ', but wanted ' government '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' business/wealth ', but wanted ' wealth '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' politics/elections ', but wanted ' elections '\n",
            "gpt3.5 Accuracy:  0.29069767441860467\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.7385894831183345\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.2393576874031351\n",
            "\n",
            "Current few-shot sample: 4 / 15\n",
            "gpt3.5 Accuracy:  0.5174418604651163\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.8061135548145272\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.23831579385995924\n",
            "\n",
            "Current few-shot sample: 5 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government/leadership ', but wanted ' government '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' law/government ', but wanted ' gun rights '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government/politics ', but wanted ' democracy '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government/regulation ', but wanted ' government '\n",
            "gpt3.5 Accuracy:  0.4941860465116279\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.7836825767921847\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.2678601494029725\n",
            "\n",
            "Current few-shot sample: 6 / 15\n",
            "gpt3.5 Accuracy:  0.45930232558139533\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.8091876033780186\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.22313637263529693\n",
            "\n",
            "Current few-shot sample: 7 / 15\n",
            "gpt3.5 Accuracy:  0.563953488372093\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.8234319654834825\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.23803724398375437\n",
            "\n",
            "Current few-shot sample: 8 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' food/feeding ', but wanted ' bureaucracy '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' arms/guns ', but wanted ' guns '\n",
            "gpt3.5 Accuracy:  0.4883720930232558\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.77348488352673\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.2670177014180012\n",
            "\n",
            "Current few-shot sample: 9 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' economy/wealth ', but wanted ' wealth '\n",
            "gpt3.5 Accuracy:  0.563953488372093\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.8378580987973269\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.22243064170509763\n",
            "\n",
            "Current few-shot sample: 10 / 15\n",
            "gpt3.5 Accuracy:  0.563953488372093\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.808341505569081\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.2479279557287638\n",
            "\n",
            "Current few-shot sample: 11 / 15\n",
            "gpt3.5 Accuracy:  0.5988372093023255\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.8229731126406858\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.25042598417206385\n",
            "\n",
            "Current few-shot sample: 12 / 15\n",
            "gpt3.5 Accuracy:  0.5406976744186046\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.8265496400553126\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.22549749845522152\n",
            "\n",
            "Current few-shot sample: 13 / 15\n",
            "gpt3.5 Accuracy:  0.5581395348837209\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.7947358749806881\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.264958500365465\n",
            "\n",
            "Current few-shot sample: 14 / 15\n",
            "gpt3.5 Accuracy:  0.6976744186046512\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.8676378825722739\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.223663034262874\n",
            "\n",
            "Current few-shot sample: 15 / 15\n",
            "gpt3.5 Accuracy:  0.6046511627906976\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.8546828622388285\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.21615747209260575\n",
            "Validation results: [\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.4186046511627907,\n",
            "        \"mean_em\": 0.7310597997938477,\n",
            "        \"std_em\": 0.2900123150543965,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            200,\n",
            "            584\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"target_domain_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.4011627906976744,\n",
            "        \"mean_em\": 0.6880410207045633,\n",
            "        \"std_em\": 0.3148646242682987,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            638,\n",
            "            307\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"target_domain_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.29069767441860467,\n",
            "        \"mean_em\": 0.7385894831183345,\n",
            "        \"std_em\": 0.2393576874031351,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            628,\n",
            "            607\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"target_domain_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5174418604651163,\n",
            "        \"mean_em\": 0.8061135548145272,\n",
            "        \"std_em\": 0.23831579385995924,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            200,\n",
            "            584,\n",
            "            807,\n",
            "            895\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"target_domain_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.4941860465116279,\n",
            "        \"mean_em\": 0.7836825767921847,\n",
            "        \"std_em\": 0.2678601494029725,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            627,\n",
            "            606,\n",
            "            245,\n",
            "            458\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"target_domain_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.45930232558139533,\n",
            "        \"mean_em\": 0.8091876033780186,\n",
            "        \"std_em\": 0.22313637263529693,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            467,\n",
            "            607,\n",
            "            490,\n",
            "            189\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"target_domain_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.563953488372093,\n",
            "        \"mean_em\": 0.8234319654834825,\n",
            "        \"std_em\": 0.23803724398375437,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            200,\n",
            "            584,\n",
            "            807,\n",
            "            895,\n",
            "            336,\n",
            "            314\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"target_domain_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.4883720930232558,\n",
            "        \"mean_em\": 0.77348488352673,\n",
            "        \"std_em\": 0.2670177014180012,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            640,\n",
            "            687,\n",
            "            1039,\n",
            "            190,\n",
            "            1089,\n",
            "            284\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"target_domain_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.563953488372093,\n",
            "        \"mean_em\": 0.8378580987973269,\n",
            "        \"std_em\": 0.22243064170509763,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            49,\n",
            "            1152,\n",
            "            309,\n",
            "            1026,\n",
            "            869,\n",
            "            826\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"target_domain_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.563953488372093,\n",
            "        \"mean_em\": 0.808341505569081,\n",
            "        \"std_em\": 0.2479279557287638,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            200,\n",
            "            584,\n",
            "            807,\n",
            "            895,\n",
            "            336,\n",
            "            314,\n",
            "            311,\n",
            "            198\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"target_domain_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5988372093023255,\n",
            "        \"mean_em\": 0.8229731126406858,\n",
            "        \"std_em\": 0.25042598417206385,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            469,\n",
            "            608,\n",
            "            492,\n",
            "            189,\n",
            "            1026,\n",
            "            943,\n",
            "            204,\n",
            "            1152\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"target_domain_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5406976744186046,\n",
            "        \"mean_em\": 0.8265496400553126,\n",
            "        \"std_em\": 0.22549749845522152,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            49,\n",
            "            389,\n",
            "            308,\n",
            "            1024,\n",
            "            810,\n",
            "            1027,\n",
            "            316,\n",
            "            397\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"target_domain_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5581395348837209,\n",
            "        \"mean_em\": 0.7947358749806881,\n",
            "        \"std_em\": 0.264958500365465,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            200,\n",
            "            584,\n",
            "            807,\n",
            "            895,\n",
            "            336,\n",
            "            314,\n",
            "            311,\n",
            "            198,\n",
            "            1029,\n",
            "            189,\n",
            "            190,\n",
            "            49\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"target_domain_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.6976744186046512,\n",
            "        \"mean_em\": 0.8676378825722739,\n",
            "        \"std_em\": 0.223663034262874,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            50,\n",
            "            1152,\n",
            "            312,\n",
            "            1027,\n",
            "            870,\n",
            "            827,\n",
            "            773,\n",
            "            915,\n",
            "            670,\n",
            "            608,\n",
            "            82,\n",
            "            887\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"target_domain_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.6046511627906976,\n",
            "        \"mean_em\": 0.8546828622388285,\n",
            "        \"std_em\": 0.21615747209260575,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            941,\n",
            "            305,\n",
            "            948,\n",
            "            333,\n",
            "            246,\n",
            "            145,\n",
            "            689,\n",
            "            1160,\n",
            "            606,\n",
            "            561,\n",
            "            1058,\n",
            "            564\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"target_domain_prediction\"\n",
            "    }\n",
            "]\n",
            "\n",
            "Lenght of test: 345\n",
            "Getting completions...\n",
            "Evaluating test set performance...\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' trade/tariffs ', but wanted ' taxation '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' emotions/feelings ', but wanted ' wealth '\n",
            "gpt3.5 Accuracy:  0.6434782608695652\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.841742967825005\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.23673377695509362\n",
            "Test results: {\n",
            "    \"model\": \"gpt3.5\",\n",
            "    \"acc\": 0.6434782608695652,\n",
            "    \"mean_em\": 0.841742967825005,\n",
            "    \"std_em\": 0.23673377695509362,\n",
            "    \"few_shot_sample_indices\": [\n",
            "        50,\n",
            "        1152,\n",
            "        312,\n",
            "        1027,\n",
            "        870,\n",
            "        827,\n",
            "        773,\n",
            "        915,\n",
            "        670,\n",
            "        608,\n",
            "        82,\n",
            "        887\n",
            "    ],\n",
            "    \"few_shot_samples\": 12,\n",
            "    \"temperature\": 0.0,\n",
            "    \"eval_split\": \"test\",\n",
            "    \"dataset_name\": \"lcc_en_subset\",\n",
            "    \"fine_tuning\": false,\n",
            "    \"task_name\": \"target_domain_prediction\"\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"$WORKDIR\" python -m src.main --llm gpt3.5 --temperature 0 --dataset lcc_en_subset --task target_domain_prediction --seed 1 --evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpCL6bVWlyAa"
      },
      "source": [
        "## LCC (EN) - Source lexeme prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nr3xmss6mdSU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc6f3903-517c-4608-89b2-51faa34d8745"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-10 01:24:21.521688: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-10 01:24:21.521748: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-10 01:24:21.521781: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-10 01:24:22.640366: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "User is already logged in.\n",
            "\n",
            "llm: gpt3.5\n",
            "fine_tuned_model_path: None\n",
            "dataset: lcc_en_subset\n",
            "task: source_lexeme_prediction\n",
            "temperature: 0.0\n",
            "seed: 1\n",
            "evaluate: True\n",
            "fine_tuning: False\n",
            "\n",
            "\n",
            "Lenght of train: 1206\n",
            "Lenght of valid: 172\n",
            "Train indices: [\n",
            "    [\n",
            "        200,\n",
            "        584\n",
            "    ],\n",
            "    [\n",
            "        638,\n",
            "        307\n",
            "    ],\n",
            "    [\n",
            "        628,\n",
            "        607\n",
            "    ],\n",
            "    [\n",
            "        200,\n",
            "        584,\n",
            "        807,\n",
            "        895\n",
            "    ],\n",
            "    [\n",
            "        627,\n",
            "        606,\n",
            "        245,\n",
            "        458\n",
            "    ],\n",
            "    [\n",
            "        467,\n",
            "        607,\n",
            "        490,\n",
            "        189\n",
            "    ],\n",
            "    [\n",
            "        200,\n",
            "        584,\n",
            "        807,\n",
            "        895,\n",
            "        336,\n",
            "        314\n",
            "    ],\n",
            "    [\n",
            "        640,\n",
            "        687,\n",
            "        1039,\n",
            "        190,\n",
            "        1089,\n",
            "        284\n",
            "    ],\n",
            "    [\n",
            "        49,\n",
            "        1152,\n",
            "        309,\n",
            "        1026,\n",
            "        869,\n",
            "        826\n",
            "    ],\n",
            "    [\n",
            "        200,\n",
            "        584,\n",
            "        807,\n",
            "        895,\n",
            "        336,\n",
            "        314,\n",
            "        311,\n",
            "        198\n",
            "    ],\n",
            "    [\n",
            "        469,\n",
            "        608,\n",
            "        492,\n",
            "        189,\n",
            "        1026,\n",
            "        943,\n",
            "        204,\n",
            "        1152\n",
            "    ],\n",
            "    [\n",
            "        49,\n",
            "        389,\n",
            "        308,\n",
            "        1024,\n",
            "        810,\n",
            "        1027,\n",
            "        316,\n",
            "        397\n",
            "    ],\n",
            "    [\n",
            "        200,\n",
            "        584,\n",
            "        807,\n",
            "        895,\n",
            "        336,\n",
            "        314,\n",
            "        311,\n",
            "        198,\n",
            "        1029,\n",
            "        189,\n",
            "        190,\n",
            "        49\n",
            "    ],\n",
            "    [\n",
            "        50,\n",
            "        1152,\n",
            "        312,\n",
            "        1027,\n",
            "        870,\n",
            "        827,\n",
            "        773,\n",
            "        915,\n",
            "        670,\n",
            "        608,\n",
            "        82,\n",
            "        887\n",
            "    ],\n",
            "    [\n",
            "        941,\n",
            "        305,\n",
            "        948,\n",
            "        333,\n",
            "        246,\n",
            "        145,\n",
            "        689,\n",
            "        1160,\n",
            "        606,\n",
            "        561,\n",
            "        1058,\n",
            "        564\n",
            "    ]\n",
            "]\n",
            "\n",
            "Number of parameter combinations: 15 \n",
            "\n",
            "[{'few_shot_sample_indices': [200, 584]}, {'few_shot_sample_indices': [638, 307]}, {'few_shot_sample_indices': [628, 607]}, {'few_shot_sample_indices': [200, 584, 807, 895]}, {'few_shot_sample_indices': [627, 606, 245, 458]}, {'few_shot_sample_indices': [467, 607, 490, 189]}, {'few_shot_sample_indices': [200, 584, 807, 895, 336, 314]}, {'few_shot_sample_indices': [640, 687, 1039, 190, 1089, 284]}, {'few_shot_sample_indices': [49, 1152, 309, 1026, 869, 826]}, {'few_shot_sample_indices': [200, 584, 807, 895, 336, 314, 311, 198]}, {'few_shot_sample_indices': [469, 608, 492, 189, 1026, 943, 204, 1152]}, {'few_shot_sample_indices': [49, 389, 308, 1024, 810, 1027, 316, 397]}, {'few_shot_sample_indices': [200, 584, 807, 895, 336, 314, 311, 198, 1029, 189, 190, 49]}, {'few_shot_sample_indices': [50, 1152, 312, 1027, 870, 827, 773, 915, 670, 608, 82, 887]}, {'few_shot_sample_indices': [941, 305, 948, 333, 246, 145, 689, 1160, 606, 561, 1058, 564]}]\n",
            "\n",
            "Current few-shot sample: 1 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' remedy ', but wanted ' remedy' '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' owners ', but wanted ' flows '\n",
            "gpt3.5 Accuracy:  0.5872093023255814\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.7490179738419693\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.32678697498881487\n",
            "\n",
            "Current few-shot sample: 2 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' remedy ', but wanted ' remedy' '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' flows through ', but wanted ' flows '\n",
            "gpt3.5 Accuracy:  0.43023255813953487\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.7506340215805658\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.28224593951938326\n",
            "\n",
            "Current few-shot sample: 3 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' health care system ', but wanted ' remedy' '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' owners ', but wanted ' flows '\n",
            "gpt3.5 Accuracy:  0.5058139534883721\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.7166708108297614\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.3192615476509324\n",
            "\n",
            "Current few-shot sample: 4 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' increase ', but wanted ' remedy' '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' flows ', but wanted ' flows '\n",
            "gpt3.5 Accuracy:  0.6104651162790697\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.7718196148702572\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.31385582536198686\n",
            "\n",
            "Current few-shot sample: 5 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' remedy ', but wanted ' remedy' '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' flows through ', but wanted ' flows '\n",
            "gpt3.5 Accuracy:  0.6744186046511628\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.8223041506094295\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.28831505944653174\n",
            "\n",
            "Current few-shot sample: 6 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' remedy ', but wanted ' remedy' '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' flows ', but wanted ' flows '\n",
            "gpt3.5 Accuracy:  0.6569767441860465\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.8171882876303307\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.29027028339874444\n",
            "\n",
            "Current few-shot sample: 7 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' increase ', but wanted ' remedy' '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' flows ', but wanted ' flows '\n",
            "gpt3.5 Accuracy:  0.5872093023255814\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.7520405422722878\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.3230319483976951\n",
            "\n",
            "Current few-shot sample: 8 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' remedy ', but wanted ' remedy' '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' flows ', but wanted ' flows '\n",
            "gpt3.5 Accuracy:  0.5813953488372093\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.7511942030125579\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.3152335751317556\n",
            "\n",
            "Current few-shot sample: 9 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' remedy ', but wanted ' remedy' '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' flows through ', but wanted ' flows '\n",
            "gpt3.5 Accuracy:  0.6046511627906976\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.7935276350742856\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.2935697652620148\n",
            "\n",
            "Current few-shot sample: 10 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' costs ', but wanted ' remedy' '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' owners ', but wanted ' flows '\n",
            "gpt3.5 Accuracy:  0.6337209302325582\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.7871168572455645\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.30728542722284663\n",
            "\n",
            "Current few-shot sample: 11 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' remedy ', but wanted ' remedy' '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' flows ', but wanted ' flows '\n",
            "gpt3.5 Accuracy:  0.6627906976744186\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.8158050553310056\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.29137176630682493\n",
            "\n",
            "Current few-shot sample: 12 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' remedy ', but wanted ' remedy' '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' flows ', but wanted ' flows '\n",
            "gpt3.5 Accuracy:  0.686046511627907\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.8355053661521091\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.2764277208330771\n",
            "\n",
            "Current few-shot sample: 13 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' remedy ', but wanted ' remedy' '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' flows ', but wanted ' flows '\n",
            "gpt3.5 Accuracy:  0.6802325581395349\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.8152793854215118\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.295419044022009\n",
            "\n",
            "Current few-shot sample: 14 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' remedy ', but wanted ' remedy' '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' flows ', but wanted ' flows '\n",
            "gpt3.5 Accuracy:  0.6686046511627907\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.8161729219867739\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.29186752808622224\n",
            "\n",
            "Current few-shot sample: 15 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' remedy ', but wanted ' remedy' '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' flows through ', but wanted ' flows '\n",
            "gpt3.5 Accuracy:  0.622093023255814\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.7883848217857439\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.30183376337877044\n",
            "Validation results: [\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5872093023255814,\n",
            "        \"mean_em\": 0.7490179738419693,\n",
            "        \"std_em\": 0.32678697498881487,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            200,\n",
            "            584\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"source_lexeme_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.43023255813953487,\n",
            "        \"mean_em\": 0.7506340215805658,\n",
            "        \"std_em\": 0.28224593951938326,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            638,\n",
            "            307\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"source_lexeme_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5058139534883721,\n",
            "        \"mean_em\": 0.7166708108297614,\n",
            "        \"std_em\": 0.3192615476509324,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            628,\n",
            "            607\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"source_lexeme_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.6104651162790697,\n",
            "        \"mean_em\": 0.7718196148702572,\n",
            "        \"std_em\": 0.31385582536198686,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            200,\n",
            "            584,\n",
            "            807,\n",
            "            895\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"source_lexeme_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.6744186046511628,\n",
            "        \"mean_em\": 0.8223041506094295,\n",
            "        \"std_em\": 0.28831505944653174,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            627,\n",
            "            606,\n",
            "            245,\n",
            "            458\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"source_lexeme_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.6569767441860465,\n",
            "        \"mean_em\": 0.8171882876303307,\n",
            "        \"std_em\": 0.29027028339874444,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            467,\n",
            "            607,\n",
            "            490,\n",
            "            189\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"source_lexeme_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5872093023255814,\n",
            "        \"mean_em\": 0.7520405422722878,\n",
            "        \"std_em\": 0.3230319483976951,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            200,\n",
            "            584,\n",
            "            807,\n",
            "            895,\n",
            "            336,\n",
            "            314\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"source_lexeme_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5813953488372093,\n",
            "        \"mean_em\": 0.7511942030125579,\n",
            "        \"std_em\": 0.3152335751317556,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            640,\n",
            "            687,\n",
            "            1039,\n",
            "            190,\n",
            "            1089,\n",
            "            284\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"source_lexeme_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.6046511627906976,\n",
            "        \"mean_em\": 0.7935276350742856,\n",
            "        \"std_em\": 0.2935697652620148,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            49,\n",
            "            1152,\n",
            "            309,\n",
            "            1026,\n",
            "            869,\n",
            "            826\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"source_lexeme_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.6337209302325582,\n",
            "        \"mean_em\": 0.7871168572455645,\n",
            "        \"std_em\": 0.30728542722284663,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            200,\n",
            "            584,\n",
            "            807,\n",
            "            895,\n",
            "            336,\n",
            "            314,\n",
            "            311,\n",
            "            198\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"source_lexeme_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.6627906976744186,\n",
            "        \"mean_em\": 0.8158050553310056,\n",
            "        \"std_em\": 0.29137176630682493,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            469,\n",
            "            608,\n",
            "            492,\n",
            "            189,\n",
            "            1026,\n",
            "            943,\n",
            "            204,\n",
            "            1152\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"source_lexeme_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.686046511627907,\n",
            "        \"mean_em\": 0.8355053661521091,\n",
            "        \"std_em\": 0.2764277208330771,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            49,\n",
            "            389,\n",
            "            308,\n",
            "            1024,\n",
            "            810,\n",
            "            1027,\n",
            "            316,\n",
            "            397\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"source_lexeme_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.6802325581395349,\n",
            "        \"mean_em\": 0.8152793854215118,\n",
            "        \"std_em\": 0.295419044022009,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            200,\n",
            "            584,\n",
            "            807,\n",
            "            895,\n",
            "            336,\n",
            "            314,\n",
            "            311,\n",
            "            198,\n",
            "            1029,\n",
            "            189,\n",
            "            190,\n",
            "            49\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"source_lexeme_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.6686046511627907,\n",
            "        \"mean_em\": 0.8161729219867739,\n",
            "        \"std_em\": 0.29186752808622224,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            50,\n",
            "            1152,\n",
            "            312,\n",
            "            1027,\n",
            "            870,\n",
            "            827,\n",
            "            773,\n",
            "            915,\n",
            "            670,\n",
            "            608,\n",
            "            82,\n",
            "            887\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"source_lexeme_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.622093023255814,\n",
            "        \"mean_em\": 0.7883848217857439,\n",
            "        \"std_em\": 0.30183376337877044,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            941,\n",
            "            305,\n",
            "            948,\n",
            "            333,\n",
            "            246,\n",
            "            145,\n",
            "            689,\n",
            "            1160,\n",
            "            606,\n",
            "            561,\n",
            "            1058,\n",
            "            564\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"source_lexeme_prediction\"\n",
            "    }\n",
            "]\n",
            "\n",
            "Lenght of test: 345\n",
            "Getting completions...\n",
            "Evaluating test set performance...\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' registration ', but wanted ' passionist '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' anti gun brayers ', but wanted ' brayers '\n",
            "gpt3.5 Accuracy:  0.6956521739130435\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.841149627212165\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.27126438960658444\n",
            "Test results: {\n",
            "    \"model\": \"gpt3.5\",\n",
            "    \"acc\": 0.6956521739130435,\n",
            "    \"mean_em\": 0.841149627212165,\n",
            "    \"std_em\": 0.27126438960658444,\n",
            "    \"few_shot_sample_indices\": [\n",
            "        49,\n",
            "        389,\n",
            "        308,\n",
            "        1024,\n",
            "        810,\n",
            "        1027,\n",
            "        316,\n",
            "        397\n",
            "    ],\n",
            "    \"few_shot_samples\": 8,\n",
            "    \"temperature\": 0.0,\n",
            "    \"eval_split\": \"test\",\n",
            "    \"dataset_name\": \"lcc_en_subset\",\n",
            "    \"fine_tuning\": false,\n",
            "    \"task_name\": \"source_lexeme_prediction\"\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"$WORKDIR\" python -m src.main --llm gpt3.5 --temperature 0 --dataset lcc_en_subset --task source_lexeme_prediction --seed 1 --evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXb4HkbflyCv"
      },
      "source": [
        "## LCC (EN) - Target lexeme prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "4XGBLHnhmeSh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "586780c1-def1-4dc2-c789-c8cda3d1f500"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-10 01:47:31.055320: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-10 01:47:31.055375: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-10 01:47:31.055416: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-10 01:47:32.176528: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "User is already logged in.\n",
            "\n",
            "llm: gpt3.5\n",
            "fine_tuned_model_path: None\n",
            "dataset: lcc_en_subset\n",
            "task: target_lexeme_prediction\n",
            "temperature: 0.0\n",
            "seed: 1\n",
            "evaluate: True\n",
            "fine_tuning: False\n",
            "\n",
            "\n",
            "Lenght of train: 1206\n",
            "Lenght of valid: 172\n",
            "Train indices: [\n",
            "    [\n",
            "        200,\n",
            "        584\n",
            "    ],\n",
            "    [\n",
            "        638,\n",
            "        307\n",
            "    ],\n",
            "    [\n",
            "        628,\n",
            "        607\n",
            "    ],\n",
            "    [\n",
            "        200,\n",
            "        584,\n",
            "        807,\n",
            "        895\n",
            "    ],\n",
            "    [\n",
            "        627,\n",
            "        606,\n",
            "        245,\n",
            "        458\n",
            "    ],\n",
            "    [\n",
            "        467,\n",
            "        607,\n",
            "        490,\n",
            "        189\n",
            "    ],\n",
            "    [\n",
            "        200,\n",
            "        584,\n",
            "        807,\n",
            "        895,\n",
            "        336,\n",
            "        314\n",
            "    ],\n",
            "    [\n",
            "        640,\n",
            "        687,\n",
            "        1039,\n",
            "        190,\n",
            "        1089,\n",
            "        284\n",
            "    ],\n",
            "    [\n",
            "        49,\n",
            "        1152,\n",
            "        309,\n",
            "        1026,\n",
            "        869,\n",
            "        826\n",
            "    ],\n",
            "    [\n",
            "        200,\n",
            "        584,\n",
            "        807,\n",
            "        895,\n",
            "        336,\n",
            "        314,\n",
            "        311,\n",
            "        198\n",
            "    ],\n",
            "    [\n",
            "        469,\n",
            "        608,\n",
            "        492,\n",
            "        189,\n",
            "        1026,\n",
            "        943,\n",
            "        204,\n",
            "        1152\n",
            "    ],\n",
            "    [\n",
            "        49,\n",
            "        389,\n",
            "        308,\n",
            "        1024,\n",
            "        810,\n",
            "        1027,\n",
            "        316,\n",
            "        397\n",
            "    ],\n",
            "    [\n",
            "        200,\n",
            "        584,\n",
            "        807,\n",
            "        895,\n",
            "        336,\n",
            "        314,\n",
            "        311,\n",
            "        198,\n",
            "        1029,\n",
            "        189,\n",
            "        190,\n",
            "        49\n",
            "    ],\n",
            "    [\n",
            "        50,\n",
            "        1152,\n",
            "        312,\n",
            "        1027,\n",
            "        870,\n",
            "        827,\n",
            "        773,\n",
            "        915,\n",
            "        670,\n",
            "        608,\n",
            "        82,\n",
            "        887\n",
            "    ],\n",
            "    [\n",
            "        941,\n",
            "        305,\n",
            "        948,\n",
            "        333,\n",
            "        246,\n",
            "        145,\n",
            "        689,\n",
            "        1160,\n",
            "        606,\n",
            "        561,\n",
            "        1058,\n",
            "        564\n",
            "    ]\n",
            "]\n",
            "\n",
            "Number of parameter combinations: 15 \n",
            "\n",
            "[{'few_shot_sample_indices': [200, 584]}, {'few_shot_sample_indices': [638, 307]}, {'few_shot_sample_indices': [628, 607]}, {'few_shot_sample_indices': [200, 584, 807, 895]}, {'few_shot_sample_indices': [627, 606, 245, 458]}, {'few_shot_sample_indices': [467, 607, 490, 189]}, {'few_shot_sample_indices': [200, 584, 807, 895, 336, 314]}, {'few_shot_sample_indices': [640, 687, 1039, 190, 1089, 284]}, {'few_shot_sample_indices': [49, 1152, 309, 1026, 869, 826]}, {'few_shot_sample_indices': [200, 584, 807, 895, 336, 314, 311, 198]}, {'few_shot_sample_indices': [469, 608, 492, 189, 1026, 943, 204, 1152]}, {'few_shot_sample_indices': [49, 389, 308, 1024, 810, 1027, 316, 397]}, {'few_shot_sample_indices': [200, 584, 807, 895, 336, 314, 311, 198, 1029, 189, 190, 49]}, {'few_shot_sample_indices': [50, 1152, 312, 1027, 870, 827, 773, 915, 670, 608, 82, 887]}, {'few_shot_sample_indices': [941, 305, 948, 333, 246, 145, 689, 1160, 606, 561, 1058, 564]}]\n",
            "\n",
            "Current few-shot sample: 1 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Democracy ', but wanted ' Democracys '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Woman ', but wanted ' \"taxes\" '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' militia ', but wanted ' 2A. '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Bachmannia ', but wanted ' candidate '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' NRA/ISRA ', but wanted ' NRA '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government ', but wanted ' government's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' democracy ', but wanted ' \"democracy\" '\n",
            "gpt3.5 Accuracy:  0.7093023255813954\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.8299980770341705\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.3039312995426243\n",
            "\n",
            "Current few-shot sample: 2 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Democracy ', but wanted ' Democracys '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' emperor's ', but wanted ' government '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' taxes ', but wanted ' \"taxes\" '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' 2A ', but wanted ' 2A. '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Bachmannia ', but wanted ' candidate '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' NRA/ISRA ', but wanted ' NRA '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government ', but wanted ' government's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' freedom ', but wanted ' \"democracy\" '\n",
            "gpt3.5 Accuracy:  0.686046511627907\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.8092779859378975\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.3231213791341049\n",
            "\n",
            "Current few-shot sample: 3 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Democracy's ', but wanted ' Democracys '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' taxes ', but wanted ' \"taxes\" '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' 2A ', but wanted ' 2A. '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Bachmannia ', but wanted ' candidate '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' NRA/ISRA ', but wanted ' NRA '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government ', but wanted ' government's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' freedom ', but wanted ' \"democracy\" '\n",
            "gpt3.5 Accuracy:  0.7325581395348837\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.8666660243340397\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.2692919423948747\n",
            "\n",
            "Current few-shot sample: 4 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Democracy ', but wanted ' Democracys '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Woman ', but wanted ' \"taxes\" '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' militia ', but wanted ' 2A. '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' NRA/ISRA ', but wanted ' NRA '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government ', but wanted ' government's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' democracy ', but wanted ' \"democracy\" '\n",
            "gpt3.5 Accuracy:  0.7558139534883721\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.8706253220673738\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.27227299603520455\n",
            "\n",
            "Current few-shot sample: 5 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' democracy ', but wanted ' Democracys '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' taxes ', but wanted ' \"taxes\" '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' 2A ', but wanted ' 2A. '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government ', but wanted ' government's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' freedom ', but wanted ' \"democracy\" '\n",
            "gpt3.5 Accuracy:  0.7790697674418605\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.8841623814211722\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.25566034129376175\n",
            "\n",
            "Current few-shot sample: 6 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Democracy ', but wanted ' Democracys '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' taxes ', but wanted ' \"taxes\" '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' 2A ', but wanted ' 2A. '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Bachmannia ', but wanted ' candidate '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' NRA/ISRA ', but wanted ' NRA '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government ', but wanted ' government's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' democracy ', but wanted ' \"democracy\" '\n",
            "gpt3.5 Accuracy:  0.7383720930232558\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.8627066307287964\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.2742142194712972\n",
            "\n",
            "Current few-shot sample: 7 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Democracy ', but wanted ' Democracys '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Woman ', but wanted ' \"taxes\" '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' militia ', but wanted ' 2A. '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' NRA/ISRA ', but wanted ' NRA '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government ', but wanted ' government's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' democracy ', but wanted ' \"democracy\" '\n",
            "gpt3.5 Accuracy:  0.7965116279069767\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.8929407873277574\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.25567308782465975\n",
            "\n",
            "Current few-shot sample: 8 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' democracy ', but wanted ' Democracys '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' emperor's ', but wanted ' government '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' taxes ', but wanted ' \"taxes\" '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' militia ', but wanted ' 2A. '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Bachmannia ', but wanted ' candidate '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' NRA/ISRA ', but wanted ' NRA '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government ', but wanted ' government's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' democracy ', but wanted ' \"democracy\" '\n",
            "gpt3.5 Accuracy:  0.7558139534883721\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.8547311702005086\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.2837540542018059\n",
            "\n",
            "Current few-shot sample: 9 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Democracy ', but wanted ' Democracys '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' emperor's ', but wanted ' government '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' taxes ', but wanted ' \"taxes\" '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' 2A ', but wanted ' 2A. '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Bachmannia ', but wanted ' candidate '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' NRA/ISRA ', but wanted ' NRA '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government ', but wanted ' government's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' democracy ', but wanted ' \"democracy\" '\n",
            "gpt3.5 Accuracy:  0.7558139534883721\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.8802368006299095\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.2672509081359665\n",
            "\n",
            "Current few-shot sample: 10 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Democracy ', but wanted ' Democracys '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Woman ', but wanted ' \"taxes\" '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' militia ', but wanted ' 2A. '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' NRA/ISRA ', but wanted ' NRA '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government ', but wanted ' government's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' democracy ', but wanted ' \"democracy\" '\n",
            "gpt3.5 Accuracy:  0.8023255813953488\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.8953237505304779\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.2511790103339973\n",
            "\n",
            "Current few-shot sample: 11 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Democracy ', but wanted ' Democracys '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' emperor's ', but wanted ' government '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' taxes ', but wanted ' \"taxes\" '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' militia ', but wanted ' 2A. '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Bachmannia ', but wanted ' candidate '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' NRA/ISRA ', but wanted ' NRA '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government ', but wanted ' government's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' democracy ', but wanted ' \"democracy\" '\n",
            "gpt3.5 Accuracy:  0.7790697674418605\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.8755504896559382\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.2709320073110674\n",
            "\n",
            "Current few-shot sample: 12 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Democracy ', but wanted ' Democracys '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' taxes ', but wanted ' \"taxes\" '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' 2A ', but wanted ' 2A. '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Bachmannia ', but wanted ' candidate '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' NRA/ISRA ', but wanted ' NRA '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government ', but wanted ' government's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' freedom ', but wanted ' \"democracy\" '\n",
            "gpt3.5 Accuracy:  0.7034883720930233\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.8658970093222939\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.2707750656216196\n",
            "\n",
            "Current few-shot sample: 13 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Democracy ', but wanted ' Democracys '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Woman ', but wanted ' \"taxes\" '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' militia ', but wanted ' 2A. '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Bachmannia ', but wanted ' candidate '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' NRA/ISRA ', but wanted ' NRA '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government ', but wanted ' government's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' democracy ', but wanted ' \"democracy\" '\n",
            "gpt3.5 Accuracy:  0.8081395348837209\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.8919689467631627\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.2617790808150438\n",
            "\n",
            "Current few-shot sample: 14 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Democracy ', but wanted ' Democracys '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' taxes ', but wanted ' \"taxes\" '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' 2A ', but wanted ' 2A. '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Bachmannia ', but wanted ' candidate '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' NRA/ISRA ', but wanted ' NRA '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government ', but wanted ' government's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' democracy ', but wanted ' \"democracy\" '\n",
            "gpt3.5 Accuracy:  0.7441860465116279\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.8622663918621012\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.27841006523602757\n",
            "\n",
            "Current few-shot sample: 15 / 15\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Democracy ', but wanted ' Democracys '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Taxes ', but wanted ' \"taxes\" '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' 2A ', but wanted ' 2A. '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Bachmannia ', but wanted ' candidate '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' NRA/ISRA ', but wanted ' NRA '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government ', but wanted ' government's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' democracy ', but wanted ' \"democracy\" '\n",
            "gpt3.5 Accuracy:  0.7383720930232558\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.8822025586957543\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.2601988030195219\n",
            "Validation results: [\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.7093023255813954,\n",
            "        \"mean_em\": 0.8299980770341705,\n",
            "        \"std_em\": 0.3039312995426243,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            200,\n",
            "            584\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"target_lexeme_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.686046511627907,\n",
            "        \"mean_em\": 0.8092779859378975,\n",
            "        \"std_em\": 0.3231213791341049,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            638,\n",
            "            307\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"target_lexeme_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.7325581395348837,\n",
            "        \"mean_em\": 0.8666660243340397,\n",
            "        \"std_em\": 0.2692919423948747,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            628,\n",
            "            607\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"target_lexeme_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.7558139534883721,\n",
            "        \"mean_em\": 0.8706253220673738,\n",
            "        \"std_em\": 0.27227299603520455,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            200,\n",
            "            584,\n",
            "            807,\n",
            "            895\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"target_lexeme_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.7790697674418605,\n",
            "        \"mean_em\": 0.8841623814211722,\n",
            "        \"std_em\": 0.25566034129376175,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            627,\n",
            "            606,\n",
            "            245,\n",
            "            458\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"target_lexeme_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.7383720930232558,\n",
            "        \"mean_em\": 0.8627066307287964,\n",
            "        \"std_em\": 0.2742142194712972,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            467,\n",
            "            607,\n",
            "            490,\n",
            "            189\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"target_lexeme_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.7965116279069767,\n",
            "        \"mean_em\": 0.8929407873277574,\n",
            "        \"std_em\": 0.25567308782465975,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            200,\n",
            "            584,\n",
            "            807,\n",
            "            895,\n",
            "            336,\n",
            "            314\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"target_lexeme_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.7558139534883721,\n",
            "        \"mean_em\": 0.8547311702005086,\n",
            "        \"std_em\": 0.2837540542018059,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            640,\n",
            "            687,\n",
            "            1039,\n",
            "            190,\n",
            "            1089,\n",
            "            284\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"target_lexeme_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.7558139534883721,\n",
            "        \"mean_em\": 0.8802368006299095,\n",
            "        \"std_em\": 0.2672509081359665,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            49,\n",
            "            1152,\n",
            "            309,\n",
            "            1026,\n",
            "            869,\n",
            "            826\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"target_lexeme_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.8023255813953488,\n",
            "        \"mean_em\": 0.8953237505304779,\n",
            "        \"std_em\": 0.2511790103339973,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            200,\n",
            "            584,\n",
            "            807,\n",
            "            895,\n",
            "            336,\n",
            "            314,\n",
            "            311,\n",
            "            198\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"target_lexeme_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.7790697674418605,\n",
            "        \"mean_em\": 0.8755504896559382,\n",
            "        \"std_em\": 0.2709320073110674,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            469,\n",
            "            608,\n",
            "            492,\n",
            "            189,\n",
            "            1026,\n",
            "            943,\n",
            "            204,\n",
            "            1152\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"target_lexeme_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.7034883720930233,\n",
            "        \"mean_em\": 0.8658970093222939,\n",
            "        \"std_em\": 0.2707750656216196,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            49,\n",
            "            389,\n",
            "            308,\n",
            "            1024,\n",
            "            810,\n",
            "            1027,\n",
            "            316,\n",
            "            397\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"target_lexeme_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.8081395348837209,\n",
            "        \"mean_em\": 0.8919689467631627,\n",
            "        \"std_em\": 0.2617790808150438,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            200,\n",
            "            584,\n",
            "            807,\n",
            "            895,\n",
            "            336,\n",
            "            314,\n",
            "            311,\n",
            "            198,\n",
            "            1029,\n",
            "            189,\n",
            "            190,\n",
            "            49\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"target_lexeme_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.7441860465116279,\n",
            "        \"mean_em\": 0.8622663918621012,\n",
            "        \"std_em\": 0.27841006523602757,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            50,\n",
            "            1152,\n",
            "            312,\n",
            "            1027,\n",
            "            870,\n",
            "            827,\n",
            "            773,\n",
            "            915,\n",
            "            670,\n",
            "            608,\n",
            "            82,\n",
            "            887\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"target_lexeme_prediction\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.7383720930232558,\n",
            "        \"mean_em\": 0.8822025586957543,\n",
            "        \"std_em\": 0.2601988030195219,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            941,\n",
            "            305,\n",
            "            948,\n",
            "            333,\n",
            "            246,\n",
            "            145,\n",
            "            689,\n",
            "            1160,\n",
            "            606,\n",
            "            561,\n",
            "            1058,\n",
            "            564\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"lcc_en_subset\",\n",
            "        \"task_name\": \"target_lexeme_prediction\"\n",
            "    }\n",
            "]\n",
            "\n",
            "Lenght of test: 345\n",
            "Getting completions...\n",
            "Evaluating test set performance...\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' hunting ', but wanted ' 2A. '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Democracy ', but wanted ' Democracys '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Senate ', but wanted ' Senate's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Government ', but wanted ' Government's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' NRA ', but wanted ' NRAs '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' power ', but wanted ' government's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' candidate ', but wanted ' candidates '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' reform ', but wanted ' government's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' NRA ', but wanted ' NRA's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' HIV/AIDS ', but wanted ' HIV '\n",
            "gpt3.5 Accuracy:  0.8\n",
            "gpt3.5 - (fasttext) Mean similarity:  0.878571656184352\n",
            "gpt3.5 - (fasttext) Standard deviation:  0.2557942612083324\n",
            "Test results: {\n",
            "    \"model\": \"gpt3.5\",\n",
            "    \"acc\": 0.8,\n",
            "    \"mean_em\": 0.878571656184352,\n",
            "    \"std_em\": 0.2557942612083324,\n",
            "    \"few_shot_sample_indices\": [\n",
            "        200,\n",
            "        584,\n",
            "        807,\n",
            "        895,\n",
            "        336,\n",
            "        314,\n",
            "        311,\n",
            "        198\n",
            "    ],\n",
            "    \"few_shot_samples\": 8,\n",
            "    \"temperature\": 0.0,\n",
            "    \"eval_split\": \"test\",\n",
            "    \"dataset_name\": \"lcc_en_subset\",\n",
            "    \"fine_tuning\": false,\n",
            "    \"task_name\": \"target_lexeme_prediction\"\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"$WORKDIR\" python -m src.main --llm gpt3.5 --temperature 0 --dataset lcc_en_subset --task target_lexeme_prediction --seed 1 --evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xT5f20zglyFY"
      },
      "source": [
        "## TroFi - Metaphor classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0Q5KfVdmfMf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90b826b7-a52e-47ae-96c0-d8936e30b955"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-29 12:35:16.620839: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-29 12:35:16.620899: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-29 12:35:16.620939: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-29 12:35:18.172724: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "User is already logged in.\n",
            "\n",
            "llm: gpt3.5\n",
            "fine_tuned_model_path: None\n",
            "dataset: trofi\n",
            "task: classification\n",
            "temperature: 0.0\n",
            "seed: 1\n",
            "evaluate: True\n",
            "fine_tuning: False\n",
            "\n",
            "\n",
            "Lenght of train: 3838\n",
            "Lenght of valid: 548\n",
            "Train indices: [\n",
            "    [\n",
            "        100,\n",
            "        85\n",
            "    ],\n",
            "    [\n",
            "        102,\n",
            "        86\n",
            "    ],\n",
            "    [\n",
            "        89,\n",
            "        106\n",
            "    ],\n",
            "    [\n",
            "        85,\n",
            "        100,\n",
            "        2262,\n",
            "        2189\n",
            "    ],\n",
            "    [\n",
            "        102,\n",
            "        2267,\n",
            "        2192,\n",
            "        86\n",
            "    ],\n",
            "    [\n",
            "        89,\n",
            "        3811,\n",
            "        3817,\n",
            "        106\n",
            "    ],\n",
            "    [\n",
            "        2262,\n",
            "        2401,\n",
            "        100,\n",
            "        2436,\n",
            "        85,\n",
            "        2189\n",
            "    ],\n",
            "    [\n",
            "        86,\n",
            "        102,\n",
            "        3811,\n",
            "        3817,\n",
            "        423,\n",
            "        480\n",
            "    ],\n",
            "    [\n",
            "        288,\n",
            "        580,\n",
            "        3620,\n",
            "        658,\n",
            "        3595,\n",
            "        271\n",
            "    ],\n",
            "    [\n",
            "        354,\n",
            "        2436,\n",
            "        2262,\n",
            "        418,\n",
            "        2401,\n",
            "        85,\n",
            "        2189,\n",
            "        100\n",
            "    ],\n",
            "    [\n",
            "        102,\n",
            "        420,\n",
            "        3811,\n",
            "        482,\n",
            "        424,\n",
            "        86,\n",
            "        359,\n",
            "        3817\n",
            "    ],\n",
            "    [\n",
            "        288,\n",
            "        572,\n",
            "        3662,\n",
            "        583,\n",
            "        663,\n",
            "        507,\n",
            "        3677,\n",
            "        271\n",
            "    ],\n",
            "    [\n",
            "        2189,\n",
            "        2457,\n",
            "        2401,\n",
            "        793,\n",
            "        100,\n",
            "        85,\n",
            "        2262,\n",
            "        2436,\n",
            "        418,\n",
            "        2426,\n",
            "        354,\n",
            "        685\n",
            "    ],\n",
            "    [\n",
            "        407,\n",
            "        657,\n",
            "        3191,\n",
            "        3625,\n",
            "        3596,\n",
            "        502,\n",
            "        3262,\n",
            "        346,\n",
            "        270,\n",
            "        561,\n",
            "        578,\n",
            "        287\n",
            "    ],\n",
            "    [\n",
            "        2534,\n",
            "        572,\n",
            "        3727,\n",
            "        2568,\n",
            "        3265,\n",
            "        409,\n",
            "        288,\n",
            "        3721,\n",
            "        271,\n",
            "        507,\n",
            "        3197,\n",
            "        348\n",
            "    ]\n",
            "]\n",
            "\n",
            "Number of parameter combinations: 15 \n",
            "\n",
            "[{'few_shot_sample_indices': [100, 85]}, {'few_shot_sample_indices': [102, 86]}, {'few_shot_sample_indices': [89, 106]}, {'few_shot_sample_indices': [85, 100, 2262, 2189]}, {'few_shot_sample_indices': [102, 2267, 2192, 86]}, {'few_shot_sample_indices': [89, 3811, 3817, 106]}, {'few_shot_sample_indices': [2262, 2401, 100, 2436, 85, 2189]}, {'few_shot_sample_indices': [86, 102, 3811, 3817, 423, 480]}, {'few_shot_sample_indices': [288, 580, 3620, 658, 3595, 271]}, {'few_shot_sample_indices': [354, 2436, 2262, 418, 2401, 85, 2189, 100]}, {'few_shot_sample_indices': [102, 420, 3811, 482, 424, 86, 359, 3817]}, {'few_shot_sample_indices': [288, 572, 3662, 583, 663, 507, 3677, 271]}, {'few_shot_sample_indices': [2189, 2457, 2401, 793, 100, 85, 2262, 2436, 418, 2426, 354, 685]}, {'few_shot_sample_indices': [407, 657, 3191, 3625, 3596, 502, 3262, 346, 270, 561, 578, 287]}, {'few_shot_sample_indices': [2534, 572, 3727, 2568, 3265, 409, 288, 3721, 271, 507, 3197, 348]}]\n",
            "\n",
            "Current few-shot sample: 1 / 15\n",
            "Accuracy: 0.5456204379562044\n",
            "F1 score: 0.4\n",
            "Precision: 0.5886524822695035\n",
            "Recall: 0.3029197080291971\n",
            "\n",
            "\n",
            "Current few-shot sample: 2 / 15\n",
            "Accuracy: 0.5164233576642335\n",
            "F1 score: 0.22740524781341107\n",
            "Precision: 0.5652173913043478\n",
            "Recall: 0.14233576642335766\n",
            "\n",
            "\n",
            "Current few-shot sample: 3 / 15\n",
            "Accuracy: 0.5474452554744526\n",
            "F1 score: 0.36082474226804123\n",
            "Precision: 0.6140350877192983\n",
            "Recall: 0.25547445255474455\n",
            "\n",
            "\n",
            "Current few-shot sample: 4 / 15\n",
            "Accuracy: 0.5565693430656934\n",
            "F1 score: 0.39702233250620345\n",
            "Precision: 0.6201550387596899\n",
            "Recall: 0.291970802919708\n",
            "\n",
            "\n",
            "Current few-shot sample: 5 / 15\n",
            "Accuracy: 0.5401459854014599\n",
            "F1 score: 0.34375\n",
            "Precision: 0.6\n",
            "Recall: 0.24087591240875914\n",
            "\n",
            "\n",
            "Current few-shot sample: 6 / 15\n",
            "Accuracy: 0.5656934306569343\n",
            "F1 score: 0.44392523364485986\n",
            "Precision: 0.6168831168831169\n",
            "Recall: 0.3467153284671533\n",
            "\n",
            "\n",
            "Current few-shot sample: 7 / 15\n",
            "Accuracy: 0.5766423357664233\n",
            "F1 score: 0.47747747747747743\n",
            "Precision: 0.6235294117647059\n",
            "Recall: 0.38686131386861317\n",
            "\n",
            "\n",
            "Current few-shot sample: 8 / 15\n",
            "Accuracy: 0.5912408759124088\n",
            "F1 score: 0.6042402826855123\n",
            "Precision: 0.5856164383561644\n",
            "Recall: 0.6240875912408759\n",
            "\n",
            "\n",
            "Current few-shot sample: 9 / 15\n",
            "Accuracy: 0.5547445255474452\n",
            "F1 score: 0.48305084745762716\n",
            "Precision: 0.5757575757575758\n",
            "Recall: 0.41605839416058393\n",
            "\n",
            "\n",
            "Current few-shot sample: 10 / 15\n",
            "Accuracy: 0.5656934306569343\n",
            "F1 score: 0.4892703862660944\n",
            "Precision: 0.59375\n",
            "Recall: 0.41605839416058393\n",
            "\n",
            "\n",
            "Current few-shot sample: 11 / 15\n",
            "Accuracy: 0.531021897810219\n",
            "F1 score: 0.38369304556354916\n",
            "Precision: 0.5594405594405595\n",
            "Recall: 0.291970802919708\n",
            "\n",
            "\n",
            "Current few-shot sample: 12 / 15\n",
            "Accuracy: 0.5675182481751825\n",
            "F1 score: 0.49681528662420377\n",
            "Precision: 0.5939086294416244\n",
            "Recall: 0.42700729927007297\n",
            "\n",
            "\n",
            "Current few-shot sample: 13 / 15\n",
            "Accuracy: 0.5620437956204379\n",
            "F1 score: 0.5588235294117646\n",
            "Precision: 0.562962962962963\n",
            "Recall: 0.5547445255474452\n",
            "\n",
            "\n",
            "Current few-shot sample: 14 / 15\n",
            "Accuracy: 0.5638686131386861\n",
            "F1 score: 0.5693693693693693\n",
            "Precision: 0.5622775800711743\n",
            "Recall: 0.5766423357664233\n",
            "\n",
            "\n",
            "Current few-shot sample: 15 / 15\n",
            "Accuracy: 0.5437956204379562\n",
            "F1 score: 0.4703389830508474\n",
            "Precision: 0.5606060606060606\n",
            "Recall: 0.4051094890510949\n",
            "\n",
            "Validation results: [\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5456204379562044,\n",
            "        \"f1\": 0.4,\n",
            "        \"precision\": 0.5886524822695035,\n",
            "        \"recall\": 0.3029197080291971,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            100,\n",
            "            85\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"trofi\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5164233576642335,\n",
            "        \"f1\": 0.22740524781341107,\n",
            "        \"precision\": 0.5652173913043478,\n",
            "        \"recall\": 0.14233576642335766,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            102,\n",
            "            86\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"trofi\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5474452554744526,\n",
            "        \"f1\": 0.36082474226804123,\n",
            "        \"precision\": 0.6140350877192983,\n",
            "        \"recall\": 0.25547445255474455,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            89,\n",
            "            106\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"trofi\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5565693430656934,\n",
            "        \"f1\": 0.39702233250620345,\n",
            "        \"precision\": 0.6201550387596899,\n",
            "        \"recall\": 0.291970802919708,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            85,\n",
            "            100,\n",
            "            2262,\n",
            "            2189\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"trofi\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5401459854014599,\n",
            "        \"f1\": 0.34375,\n",
            "        \"precision\": 0.6,\n",
            "        \"recall\": 0.24087591240875914,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            102,\n",
            "            2267,\n",
            "            2192,\n",
            "            86\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"trofi\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5656934306569343,\n",
            "        \"f1\": 0.44392523364485986,\n",
            "        \"precision\": 0.6168831168831169,\n",
            "        \"recall\": 0.3467153284671533,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            89,\n",
            "            3811,\n",
            "            3817,\n",
            "            106\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"trofi\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5766423357664233,\n",
            "        \"f1\": 0.47747747747747743,\n",
            "        \"precision\": 0.6235294117647059,\n",
            "        \"recall\": 0.38686131386861317,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            2262,\n",
            "            2401,\n",
            "            100,\n",
            "            2436,\n",
            "            85,\n",
            "            2189\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"trofi\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5912408759124088,\n",
            "        \"f1\": 0.6042402826855123,\n",
            "        \"precision\": 0.5856164383561644,\n",
            "        \"recall\": 0.6240875912408759,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            86,\n",
            "            102,\n",
            "            3811,\n",
            "            3817,\n",
            "            423,\n",
            "            480\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"trofi\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5547445255474452,\n",
            "        \"f1\": 0.48305084745762716,\n",
            "        \"precision\": 0.5757575757575758,\n",
            "        \"recall\": 0.41605839416058393,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            288,\n",
            "            580,\n",
            "            3620,\n",
            "            658,\n",
            "            3595,\n",
            "            271\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"trofi\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5656934306569343,\n",
            "        \"f1\": 0.4892703862660944,\n",
            "        \"precision\": 0.59375,\n",
            "        \"recall\": 0.41605839416058393,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            354,\n",
            "            2436,\n",
            "            2262,\n",
            "            418,\n",
            "            2401,\n",
            "            85,\n",
            "            2189,\n",
            "            100\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"trofi\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.531021897810219,\n",
            "        \"f1\": 0.38369304556354916,\n",
            "        \"precision\": 0.5594405594405595,\n",
            "        \"recall\": 0.291970802919708,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            102,\n",
            "            420,\n",
            "            3811,\n",
            "            482,\n",
            "            424,\n",
            "            86,\n",
            "            359,\n",
            "            3817\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"trofi\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5675182481751825,\n",
            "        \"f1\": 0.49681528662420377,\n",
            "        \"precision\": 0.5939086294416244,\n",
            "        \"recall\": 0.42700729927007297,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            288,\n",
            "            572,\n",
            "            3662,\n",
            "            583,\n",
            "            663,\n",
            "            507,\n",
            "            3677,\n",
            "            271\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"trofi\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5620437956204379,\n",
            "        \"f1\": 0.5588235294117646,\n",
            "        \"precision\": 0.562962962962963,\n",
            "        \"recall\": 0.5547445255474452,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            2189,\n",
            "            2457,\n",
            "            2401,\n",
            "            793,\n",
            "            100,\n",
            "            85,\n",
            "            2262,\n",
            "            2436,\n",
            "            418,\n",
            "            2426,\n",
            "            354,\n",
            "            685\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"trofi\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5638686131386861,\n",
            "        \"f1\": 0.5693693693693693,\n",
            "        \"precision\": 0.5622775800711743,\n",
            "        \"recall\": 0.5766423357664233,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            407,\n",
            "            657,\n",
            "            3191,\n",
            "            3625,\n",
            "            3596,\n",
            "            502,\n",
            "            3262,\n",
            "            346,\n",
            "            270,\n",
            "            561,\n",
            "            578,\n",
            "            287\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"trofi\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5437956204379562,\n",
            "        \"f1\": 0.4703389830508474,\n",
            "        \"precision\": 0.5606060606060606,\n",
            "        \"recall\": 0.4051094890510949,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            2534,\n",
            "            572,\n",
            "            3727,\n",
            "            2568,\n",
            "            3265,\n",
            "            409,\n",
            "            288,\n",
            "            3721,\n",
            "            271,\n",
            "            507,\n",
            "            3197,\n",
            "            348\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"trofi\"\n",
            "    }\n",
            "]\n",
            "\n",
            "Lenght of test: 1096\n",
            "Getting completions...\n",
            "Evaluating test set performance...\n",
            "Accuracy: 0.5784671532846716\n",
            "F1 score: 0.5896980461811723\n",
            "Precision: 0.5743944636678201\n",
            "Recall: 0.6058394160583942\n",
            "\n",
            "Test results: {\n",
            "    \"model\": \"gpt3.5\",\n",
            "    \"acc\": 0.5784671532846716,\n",
            "    \"f1\": 0.5896980461811723,\n",
            "    \"precision\": 0.5743944636678201,\n",
            "    \"recall\": 0.6058394160583942,\n",
            "    \"few_shot_sample_indices\": [\n",
            "        86,\n",
            "        102,\n",
            "        3811,\n",
            "        3817,\n",
            "        423,\n",
            "        480\n",
            "    ],\n",
            "    \"few_shot_samples\": 6,\n",
            "    \"temperature\": 0.0,\n",
            "    \"eval_split\": \"test\",\n",
            "    \"dataset_name\": \"trofi\",\n",
            "    \"fine_tuning\": false\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"$WORKDIR\" python -m src.main --llm gpt3.5 --temperature 0 --dataset trofi --task classification --seed 1 --evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTD5eEGylyH8"
      },
      "source": [
        "## VUA POS - Metaphor classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZD9x62NmgDJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee728302-0a1d-430c-b67f-534e72dbb014"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-29 13:30:40.623026: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-29 13:30:40.623091: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-29 13:30:40.623126: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-29 13:30:41.680768: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "User is already logged in.\n",
            "\n",
            "llm: gpt3.5\n",
            "fine_tuned_model_path: None\n",
            "dataset: vua_pos\n",
            "task: classification\n",
            "temperature: 0.0\n",
            "seed: 1\n",
            "evaluate: True\n",
            "fine_tuning: False\n",
            "\n",
            "\n",
            "Lenght of train: 3506\n",
            "Lenght of valid: 502\n",
            "Train indices: [\n",
            "    [\n",
            "        2179,\n",
            "        2162\n",
            "    ],\n",
            "    [\n",
            "        2178,\n",
            "        2161\n",
            "    ],\n",
            "    [\n",
            "        3414,\n",
            "        3416\n",
            "    ],\n",
            "    [\n",
            "        2162,\n",
            "        2179,\n",
            "        1941,\n",
            "        1932\n",
            "    ],\n",
            "    [\n",
            "        3416,\n",
            "        3181,\n",
            "        3162,\n",
            "        3414\n",
            "    ],\n",
            "    [\n",
            "        3412,\n",
            "        3179,\n",
            "        3159,\n",
            "        3413\n",
            "    ],\n",
            "    [\n",
            "        1941,\n",
            "        89,\n",
            "        2179,\n",
            "        98,\n",
            "        2162,\n",
            "        1932\n",
            "    ],\n",
            "    [\n",
            "        3414,\n",
            "        3416,\n",
            "        3401,\n",
            "        3386,\n",
            "        92,\n",
            "        99\n",
            "    ],\n",
            "    [\n",
            "        3179,\n",
            "        2030,\n",
            "        94,\n",
            "        2026,\n",
            "        100,\n",
            "        3159\n",
            "    ],\n",
            "    [\n",
            "        3021,\n",
            "        98,\n",
            "        1941,\n",
            "        3057,\n",
            "        89,\n",
            "        2162,\n",
            "        1932,\n",
            "        2179\n",
            "    ],\n",
            "    [\n",
            "        3416,\n",
            "        624,\n",
            "        3181,\n",
            "        99,\n",
            "        92,\n",
            "        3414,\n",
            "        584,\n",
            "        3162\n",
            "    ],\n",
            "    [\n",
            "        3180,\n",
            "        627,\n",
            "        100,\n",
            "        2032,\n",
            "        2027,\n",
            "        587,\n",
            "        94,\n",
            "        3160\n",
            "    ],\n",
            "    [\n",
            "        1932,\n",
            "        550,\n",
            "        89,\n",
            "        1094,\n",
            "        2179,\n",
            "        2162,\n",
            "        1941,\n",
            "        98,\n",
            "        3057,\n",
            "        488,\n",
            "        3021,\n",
            "        1045\n",
            "    ],\n",
            "    [\n",
            "        1099,\n",
            "        2027,\n",
            "        2246,\n",
            "        92,\n",
            "        99,\n",
            "        585,\n",
            "        2285,\n",
            "        1053,\n",
            "        3162,\n",
            "        626,\n",
            "        2032,\n",
            "        3181\n",
            "    ],\n",
            "    [\n",
            "        3472,\n",
            "        3238,\n",
            "        2066,\n",
            "        3476,\n",
            "        3150,\n",
            "        828,\n",
            "        566,\n",
            "        2073,\n",
            "        508,\n",
            "        3211,\n",
            "        3116,\n",
            "        795\n",
            "    ]\n",
            "]\n",
            "\n",
            "Number of parameter combinations: 15 \n",
            "\n",
            "[{'few_shot_sample_indices': [2179, 2162]}, {'few_shot_sample_indices': [2178, 2161]}, {'few_shot_sample_indices': [3414, 3416]}, {'few_shot_sample_indices': [2162, 2179, 1941, 1932]}, {'few_shot_sample_indices': [3416, 3181, 3162, 3414]}, {'few_shot_sample_indices': [3412, 3179, 3159, 3413]}, {'few_shot_sample_indices': [1941, 89, 2179, 98, 2162, 1932]}, {'few_shot_sample_indices': [3414, 3416, 3401, 3386, 92, 99]}, {'few_shot_sample_indices': [3179, 2030, 94, 2026, 100, 3159]}, {'few_shot_sample_indices': [3021, 98, 1941, 3057, 89, 2162, 1932, 2179]}, {'few_shot_sample_indices': [3416, 624, 3181, 99, 92, 3414, 584, 3162]}, {'few_shot_sample_indices': [3180, 627, 100, 2032, 2027, 587, 94, 3160]}, {'few_shot_sample_indices': [1932, 550, 89, 1094, 2179, 2162, 1941, 98, 3057, 488, 3021, 1045]}, {'few_shot_sample_indices': [1099, 2027, 2246, 92, 99, 585, 2285, 1053, 3162, 626, 2032, 3181]}, {'few_shot_sample_indices': [3472, 3238, 2066, 3476, 3150, 828, 566, 2073, 508, 3211, 3116, 795]}]\n",
            "\n",
            "Current few-shot sample: 1 / 15\n",
            "Accuracy: 0.5258964143426295\n",
            "F1 score: 0.24203821656050956\n",
            "Precision: 0.6031746031746031\n",
            "Recall: 0.15139442231075698\n",
            "\n",
            "\n",
            "Current few-shot sample: 2 / 15\n",
            "Accuracy: 0.5278884462151394\n",
            "F1 score: 0.3209169054441261\n",
            "Precision: 0.5714285714285714\n",
            "Recall: 0.22310756972111553\n",
            "\n",
            "\n",
            "Current few-shot sample: 3 / 15\n",
            "Accuracy: 0.5199203187250996\n",
            "F1 score: 0.23974763406940064\n",
            "Precision: 0.5757575757575758\n",
            "Recall: 0.15139442231075698\n",
            "\n",
            "\n",
            "Current few-shot sample: 4 / 15\n",
            "Accuracy: 0.5577689243027888\n",
            "F1 score: 0.46634615384615385\n",
            "Precision: 0.5878787878787879\n",
            "Recall: 0.38645418326693226\n",
            "\n",
            "\n",
            "Current few-shot sample: 5 / 15\n",
            "Accuracy: 0.5298804780876494\n",
            "F1 score: 0.48017621145374456\n",
            "Precision: 0.5369458128078818\n",
            "Recall: 0.4342629482071713\n",
            "\n",
            "\n",
            "Current few-shot sample: 6 / 15\n",
            "Accuracy: 0.5378486055776892\n",
            "F1 score: 0.3333333333333333\n",
            "Precision: 0.5979381443298969\n",
            "Recall: 0.23107569721115537\n",
            "\n",
            "\n",
            "Current few-shot sample: 7 / 15\n",
            "Accuracy: 0.5637450199203188\n",
            "F1 score: 0.5290322580645161\n",
            "Precision: 0.5747663551401869\n",
            "Recall: 0.4900398406374502\n",
            "\n",
            "\n",
            "Current few-shot sample: 8 / 15\n",
            "Accuracy: 0.5338645418326693\n",
            "F1 score: 0.44549763033175355\n",
            "Precision: 0.5497076023391813\n",
            "Recall: 0.3745019920318725\n",
            "\n",
            "\n",
            "Current few-shot sample: 9 / 15\n",
            "Accuracy: 0.5577689243027888\n",
            "F1 score: 0.46116504854368934\n",
            "Precision: 0.5900621118012422\n",
            "Recall: 0.3784860557768924\n",
            "\n",
            "\n",
            "Current few-shot sample: 10 / 15\n",
            "Accuracy: 0.5557768924302788\n",
            "F1 score: 0.5703275529865126\n",
            "Precision: 0.5522388059701493\n",
            "Recall: 0.5896414342629482\n",
            "\n",
            "\n",
            "Current few-shot sample: 11 / 15\n",
            "Accuracy: 0.5099601593625498\n",
            "F1 score: 0.2678571428571429\n",
            "Precision: 0.5294117647058824\n",
            "Recall: 0.17928286852589642\n",
            "\n",
            "\n",
            "Current few-shot sample: 12 / 15\n",
            "Accuracy: 0.5438247011952191\n",
            "F1 score: 0.44282238442822386\n",
            "Precision: 0.56875\n",
            "Recall: 0.36254980079681276\n",
            "\n",
            "\n",
            "Current few-shot sample: 13 / 15\n",
            "Accuracy: 0.5756972111553785\n",
            "F1 score: 0.5553235908141961\n",
            "Precision: 0.5833333333333334\n",
            "Recall: 0.5298804780876494\n",
            "\n",
            "\n",
            "Current few-shot sample: 14 / 15\n",
            "Accuracy: 0.5756972111553785\n",
            "F1 score: 0.5973534971644613\n",
            "Precision: 0.5683453237410072\n",
            "Recall: 0.6294820717131474\n",
            "\n",
            "\n",
            "Current few-shot sample: 15 / 15\n",
            "Accuracy: 0.5418326693227091\n",
            "F1 score: 0.5490196078431372\n",
            "Precision: 0.5405405405405406\n",
            "Recall: 0.5577689243027888\n",
            "\n",
            "Validation results: [\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5258964143426295,\n",
            "        \"f1\": 0.24203821656050956,\n",
            "        \"precision\": 0.6031746031746031,\n",
            "        \"recall\": 0.15139442231075698,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            2179,\n",
            "            2162\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_pos\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5278884462151394,\n",
            "        \"f1\": 0.3209169054441261,\n",
            "        \"precision\": 0.5714285714285714,\n",
            "        \"recall\": 0.22310756972111553,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            2178,\n",
            "            2161\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_pos\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5199203187250996,\n",
            "        \"f1\": 0.23974763406940064,\n",
            "        \"precision\": 0.5757575757575758,\n",
            "        \"recall\": 0.15139442231075698,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            3414,\n",
            "            3416\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_pos\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5577689243027888,\n",
            "        \"f1\": 0.46634615384615385,\n",
            "        \"precision\": 0.5878787878787879,\n",
            "        \"recall\": 0.38645418326693226,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            2162,\n",
            "            2179,\n",
            "            1941,\n",
            "            1932\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_pos\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5298804780876494,\n",
            "        \"f1\": 0.48017621145374456,\n",
            "        \"precision\": 0.5369458128078818,\n",
            "        \"recall\": 0.4342629482071713,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            3416,\n",
            "            3181,\n",
            "            3162,\n",
            "            3414\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_pos\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5378486055776892,\n",
            "        \"f1\": 0.3333333333333333,\n",
            "        \"precision\": 0.5979381443298969,\n",
            "        \"recall\": 0.23107569721115537,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            3412,\n",
            "            3179,\n",
            "            3159,\n",
            "            3413\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_pos\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5637450199203188,\n",
            "        \"f1\": 0.5290322580645161,\n",
            "        \"precision\": 0.5747663551401869,\n",
            "        \"recall\": 0.4900398406374502,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            1941,\n",
            "            89,\n",
            "            2179,\n",
            "            98,\n",
            "            2162,\n",
            "            1932\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_pos\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5338645418326693,\n",
            "        \"f1\": 0.44549763033175355,\n",
            "        \"precision\": 0.5497076023391813,\n",
            "        \"recall\": 0.3745019920318725,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            3414,\n",
            "            3416,\n",
            "            3401,\n",
            "            3386,\n",
            "            92,\n",
            "            99\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_pos\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5577689243027888,\n",
            "        \"f1\": 0.46116504854368934,\n",
            "        \"precision\": 0.5900621118012422,\n",
            "        \"recall\": 0.3784860557768924,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            3179,\n",
            "            2030,\n",
            "            94,\n",
            "            2026,\n",
            "            100,\n",
            "            3159\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_pos\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5557768924302788,\n",
            "        \"f1\": 0.5703275529865126,\n",
            "        \"precision\": 0.5522388059701493,\n",
            "        \"recall\": 0.5896414342629482,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            3021,\n",
            "            98,\n",
            "            1941,\n",
            "            3057,\n",
            "            89,\n",
            "            2162,\n",
            "            1932,\n",
            "            2179\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_pos\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5099601593625498,\n",
            "        \"f1\": 0.2678571428571429,\n",
            "        \"precision\": 0.5294117647058824,\n",
            "        \"recall\": 0.17928286852589642,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            3416,\n",
            "            624,\n",
            "            3181,\n",
            "            99,\n",
            "            92,\n",
            "            3414,\n",
            "            584,\n",
            "            3162\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_pos\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5438247011952191,\n",
            "        \"f1\": 0.44282238442822386,\n",
            "        \"precision\": 0.56875,\n",
            "        \"recall\": 0.36254980079681276,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            3180,\n",
            "            627,\n",
            "            100,\n",
            "            2032,\n",
            "            2027,\n",
            "            587,\n",
            "            94,\n",
            "            3160\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_pos\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5756972111553785,\n",
            "        \"f1\": 0.5553235908141961,\n",
            "        \"precision\": 0.5833333333333334,\n",
            "        \"recall\": 0.5298804780876494,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            1932,\n",
            "            550,\n",
            "            89,\n",
            "            1094,\n",
            "            2179,\n",
            "            2162,\n",
            "            1941,\n",
            "            98,\n",
            "            3057,\n",
            "            488,\n",
            "            3021,\n",
            "            1045\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_pos\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5756972111553785,\n",
            "        \"f1\": 0.5973534971644613,\n",
            "        \"precision\": 0.5683453237410072,\n",
            "        \"recall\": 0.6294820717131474,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            1099,\n",
            "            2027,\n",
            "            2246,\n",
            "            92,\n",
            "            99,\n",
            "            585,\n",
            "            2285,\n",
            "            1053,\n",
            "            3162,\n",
            "            626,\n",
            "            2032,\n",
            "            3181\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_pos\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5418326693227091,\n",
            "        \"f1\": 0.5490196078431372,\n",
            "        \"precision\": 0.5405405405405406,\n",
            "        \"recall\": 0.5577689243027888,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            3472,\n",
            "            3238,\n",
            "            2066,\n",
            "            3476,\n",
            "            3150,\n",
            "            828,\n",
            "            566,\n",
            "            2073,\n",
            "            508,\n",
            "            3211,\n",
            "            3116,\n",
            "            795\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_pos\"\n",
            "    }\n",
            "]\n",
            "\n",
            "Lenght of test: 1002\n",
            "Getting completions...\n",
            "Evaluating test set performance...\n",
            "Accuracy: 0.5369261477045908\n",
            "F1 score: 0.5639097744360902\n",
            "Precision: 0.5328596802841918\n",
            "Recall: 0.5988023952095808\n",
            "\n",
            "Test results: {\n",
            "    \"model\": \"gpt3.5\",\n",
            "    \"acc\": 0.5369261477045908,\n",
            "    \"f1\": 0.5639097744360902,\n",
            "    \"precision\": 0.5328596802841918,\n",
            "    \"recall\": 0.5988023952095808,\n",
            "    \"few_shot_sample_indices\": [\n",
            "        1099,\n",
            "        2027,\n",
            "        2246,\n",
            "        92,\n",
            "        99,\n",
            "        585,\n",
            "        2285,\n",
            "        1053,\n",
            "        3162,\n",
            "        626,\n",
            "        2032,\n",
            "        3181\n",
            "    ],\n",
            "    \"few_shot_samples\": 12,\n",
            "    \"temperature\": 0.0,\n",
            "    \"eval_split\": \"test\",\n",
            "    \"dataset_name\": \"vua_pos\",\n",
            "    \"fine_tuning\": false\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"$WORKDIR\" python -m src.main --llm gpt3.5 --temperature 0 --dataset vua_pos --task classification --seed 1 --evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-EydejslyKP"
      },
      "source": [
        "## VUA Verb - Metaphor classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EVPI3ROmg-C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67f55a47-d68c-4d66-9682-15a600cbf07e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-29 14:21:58.365576: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-29 14:21:58.365648: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-29 14:21:58.365687: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-29 14:21:59.967261: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "User is already logged in.\n",
            "\n",
            "llm: gpt3.5\n",
            "fine_tuned_model_path: None\n",
            "dataset: vua_verb\n",
            "task: classification\n",
            "temperature: 0.0\n",
            "seed: 1\n",
            "evaluate: True\n",
            "fine_tuning: False\n",
            "\n",
            "\n",
            "Lenght of train: 2294\n",
            "Lenght of valid: 328\n",
            "Train indices: [\n",
            "    [\n",
            "        1877,\n",
            "        1858\n",
            "    ],\n",
            "    [\n",
            "        1468,\n",
            "        1474\n",
            "    ],\n",
            "    [\n",
            "        750,\n",
            "        782\n",
            "    ],\n",
            "    [\n",
            "        1858,\n",
            "        1877,\n",
            "        233,\n",
            "        254\n",
            "    ],\n",
            "    [\n",
            "        784,\n",
            "        1358,\n",
            "        1355,\n",
            "        751\n",
            "    ],\n",
            "    [\n",
            "        613,\n",
            "        1400,\n",
            "        1403,\n",
            "        640\n",
            "    ],\n",
            "    [\n",
            "        233,\n",
            "        1388,\n",
            "        1877,\n",
            "        1389,\n",
            "        1858,\n",
            "        254\n",
            "    ],\n",
            "    [\n",
            "        751,\n",
            "        784,\n",
            "        1358,\n",
            "        1355,\n",
            "        1034,\n",
            "        1036\n",
            "    ],\n",
            "    [\n",
            "        1182,\n",
            "        613,\n",
            "        1280,\n",
            "        640,\n",
            "        1268,\n",
            "        1183\n",
            "    ],\n",
            "    [\n",
            "        1928,\n",
            "        1389,\n",
            "        233,\n",
            "        1938,\n",
            "        1388,\n",
            "        1858,\n",
            "        254,\n",
            "        1877\n",
            "    ],\n",
            "    [\n",
            "        640,\n",
            "        2283,\n",
            "        1399,\n",
            "        1708,\n",
            "        1683,\n",
            "        613,\n",
            "        2276,\n",
            "        1402\n",
            "    ],\n",
            "    [\n",
            "        2266,\n",
            "        797,\n",
            "        1173,\n",
            "        1661,\n",
            "        1690,\n",
            "        763,\n",
            "        1170,\n",
            "        2252\n",
            "    ],\n",
            "    [\n",
            "        254,\n",
            "        2223,\n",
            "        1388,\n",
            "        2199,\n",
            "        1877,\n",
            "        1858,\n",
            "        233,\n",
            "        1389,\n",
            "        1938,\n",
            "        2230,\n",
            "        1928,\n",
            "        2206\n",
            "    ],\n",
            "    [\n",
            "        2214,\n",
            "        640,\n",
            "        672,\n",
            "        1277,\n",
            "        1260,\n",
            "        1922,\n",
            "        699,\n",
            "        2222,\n",
            "        1179,\n",
            "        1918,\n",
            "        613,\n",
            "        1176\n",
            "    ],\n",
            "    [\n",
            "        2225,\n",
            "        175,\n",
            "        795,\n",
            "        2220,\n",
            "        1887,\n",
            "        830,\n",
            "        1572,\n",
            "        758,\n",
            "        1549,\n",
            "        201,\n",
            "        1876,\n",
            "        793\n",
            "    ]\n",
            "]\n",
            "\n",
            "Number of parameter combinations: 15 \n",
            "\n",
            "[{'few_shot_sample_indices': [1877, 1858]}, {'few_shot_sample_indices': [1468, 1474]}, {'few_shot_sample_indices': [750, 782]}, {'few_shot_sample_indices': [1858, 1877, 233, 254]}, {'few_shot_sample_indices': [784, 1358, 1355, 751]}, {'few_shot_sample_indices': [613, 1400, 1403, 640]}, {'few_shot_sample_indices': [233, 1388, 1877, 1389, 1858, 254]}, {'few_shot_sample_indices': [751, 784, 1358, 1355, 1034, 1036]}, {'few_shot_sample_indices': [1182, 613, 1280, 640, 1268, 1183]}, {'few_shot_sample_indices': [1928, 1389, 233, 1938, 1388, 1858, 254, 1877]}, {'few_shot_sample_indices': [640, 2283, 1399, 1708, 1683, 613, 2276, 1402]}, {'few_shot_sample_indices': [2266, 797, 1173, 1661, 1690, 763, 1170, 2252]}, {'few_shot_sample_indices': [254, 2223, 1388, 2199, 1877, 1858, 233, 1389, 1938, 2230, 1928, 2206]}, {'few_shot_sample_indices': [2214, 640, 672, 1277, 1260, 1922, 699, 2222, 1179, 1918, 613, 1176]}, {'few_shot_sample_indices': [2225, 175, 795, 2220, 1887, 830, 1572, 758, 1549, 201, 1876, 793]}]\n",
            "\n",
            "Current few-shot sample: 1 / 15\n",
            "Accuracy: 0.5365853658536586\n",
            "F1 score: 0.23232323232323235\n",
            "Precision: 0.6764705882352942\n",
            "Recall: 0.1402439024390244\n",
            "\n",
            "\n",
            "Current few-shot sample: 2 / 15\n",
            "Accuracy: 0.5365853658536586\n",
            "F1 score: 0.1739130434782609\n",
            "Precision: 0.8\n",
            "Recall: 0.0975609756097561\n",
            "\n",
            "\n",
            "Current few-shot sample: 3 / 15\n",
            "Accuracy: 0.524390243902439\n",
            "F1 score: 0.19587628865979384\n",
            "Precision: 0.6333333333333333\n",
            "Recall: 0.11585365853658537\n",
            "\n",
            "\n",
            "Current few-shot sample: 4 / 15\n",
            "Accuracy: 0.5823170731707317\n",
            "F1 score: 0.43621399176954734\n",
            "Precision: 0.6708860759493671\n",
            "Recall: 0.3231707317073171\n",
            "\n",
            "\n",
            "Current few-shot sample: 5 / 15\n",
            "Accuracy: 0.6036585365853658\n",
            "F1 score: 0.48000000000000004\n",
            "Precision: 0.6976744186046512\n",
            "Recall: 0.36585365853658536\n",
            "\n",
            "\n",
            "Current few-shot sample: 6 / 15\n",
            "Accuracy: 0.5914634146341463\n",
            "F1 score: 0.5037037037037037\n",
            "Precision: 0.6415094339622641\n",
            "Recall: 0.4146341463414634\n",
            "\n",
            "\n",
            "Current few-shot sample: 7 / 15\n",
            "Accuracy: 0.5914634146341463\n",
            "F1 score: 0.45528455284552855\n",
            "Precision: 0.6829268292682927\n",
            "Recall: 0.34146341463414637\n",
            "\n",
            "\n",
            "Current few-shot sample: 8 / 15\n",
            "Accuracy: 0.5640243902439024\n",
            "F1 score: 0.5626911314984709\n",
            "Precision: 0.5644171779141104\n",
            "Recall: 0.5609756097560976\n",
            "\n",
            "\n",
            "Current few-shot sample: 9 / 15\n",
            "Accuracy: 0.5945121951219512\n",
            "F1 score: 0.48648648648648646\n",
            "Precision: 0.6631578947368421\n",
            "Recall: 0.38414634146341464\n",
            "\n",
            "\n",
            "Current few-shot sample: 10 / 15\n",
            "Accuracy: 0.5823170731707317\n",
            "F1 score: 0.4120171673819742\n",
            "Precision: 0.6956521739130435\n",
            "Recall: 0.2926829268292683\n",
            "\n",
            "\n",
            "Current few-shot sample: 11 / 15\n",
            "Accuracy: 0.573170731707317\n",
            "F1 score: 0.4444444444444445\n",
            "Precision: 0.6363636363636364\n",
            "Recall: 0.34146341463414637\n",
            "\n",
            "\n",
            "Current few-shot sample: 12 / 15\n",
            "Accuracy: 0.4847560975609756\n",
            "F1 score: 0.45307443365695793\n",
            "Precision: 0.4827586206896552\n",
            "Recall: 0.4268292682926829\n",
            "\n",
            "\n",
            "Current few-shot sample: 13 / 15\n",
            "Accuracy: 0.5945121951219512\n",
            "F1 score: 0.5333333333333333\n",
            "Precision: 0.628099173553719\n",
            "Recall: 0.4634146341463415\n",
            "\n",
            "\n",
            "Current few-shot sample: 14 / 15\n",
            "Accuracy: 0.6158536585365854\n",
            "F1 score: 0.5594405594405595\n",
            "Precision: 0.6557377049180327\n",
            "Recall: 0.4878048780487805\n",
            "\n",
            "\n",
            "Current few-shot sample: 15 / 15\n",
            "Accuracy: 0.5640243902439024\n",
            "F1 score: 0.4115226337448559\n",
            "Precision: 0.6329113924050633\n",
            "Recall: 0.3048780487804878\n",
            "\n",
            "Validation results: [\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5365853658536586,\n",
            "        \"f1\": 0.23232323232323235,\n",
            "        \"precision\": 0.6764705882352942,\n",
            "        \"recall\": 0.1402439024390244,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            1877,\n",
            "            1858\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_verb\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5365853658536586,\n",
            "        \"f1\": 0.1739130434782609,\n",
            "        \"precision\": 0.8,\n",
            "        \"recall\": 0.0975609756097561,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            1468,\n",
            "            1474\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_verb\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.524390243902439,\n",
            "        \"f1\": 0.19587628865979384,\n",
            "        \"precision\": 0.6333333333333333,\n",
            "        \"recall\": 0.11585365853658537,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            750,\n",
            "            782\n",
            "        ],\n",
            "        \"few_shot_samples\": 2,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_verb\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5823170731707317,\n",
            "        \"f1\": 0.43621399176954734,\n",
            "        \"precision\": 0.6708860759493671,\n",
            "        \"recall\": 0.3231707317073171,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            1858,\n",
            "            1877,\n",
            "            233,\n",
            "            254\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_verb\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.6036585365853658,\n",
            "        \"f1\": 0.48000000000000004,\n",
            "        \"precision\": 0.6976744186046512,\n",
            "        \"recall\": 0.36585365853658536,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            784,\n",
            "            1358,\n",
            "            1355,\n",
            "            751\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_verb\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5914634146341463,\n",
            "        \"f1\": 0.5037037037037037,\n",
            "        \"precision\": 0.6415094339622641,\n",
            "        \"recall\": 0.4146341463414634,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            613,\n",
            "            1400,\n",
            "            1403,\n",
            "            640\n",
            "        ],\n",
            "        \"few_shot_samples\": 4,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_verb\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5914634146341463,\n",
            "        \"f1\": 0.45528455284552855,\n",
            "        \"precision\": 0.6829268292682927,\n",
            "        \"recall\": 0.34146341463414637,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            233,\n",
            "            1388,\n",
            "            1877,\n",
            "            1389,\n",
            "            1858,\n",
            "            254\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_verb\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5640243902439024,\n",
            "        \"f1\": 0.5626911314984709,\n",
            "        \"precision\": 0.5644171779141104,\n",
            "        \"recall\": 0.5609756097560976,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            751,\n",
            "            784,\n",
            "            1358,\n",
            "            1355,\n",
            "            1034,\n",
            "            1036\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_verb\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5945121951219512,\n",
            "        \"f1\": 0.48648648648648646,\n",
            "        \"precision\": 0.6631578947368421,\n",
            "        \"recall\": 0.38414634146341464,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            1182,\n",
            "            613,\n",
            "            1280,\n",
            "            640,\n",
            "            1268,\n",
            "            1183\n",
            "        ],\n",
            "        \"few_shot_samples\": 6,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_verb\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5823170731707317,\n",
            "        \"f1\": 0.4120171673819742,\n",
            "        \"precision\": 0.6956521739130435,\n",
            "        \"recall\": 0.2926829268292683,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            1928,\n",
            "            1389,\n",
            "            233,\n",
            "            1938,\n",
            "            1388,\n",
            "            1858,\n",
            "            254,\n",
            "            1877\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_verb\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.573170731707317,\n",
            "        \"f1\": 0.4444444444444445,\n",
            "        \"precision\": 0.6363636363636364,\n",
            "        \"recall\": 0.34146341463414637,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            640,\n",
            "            2283,\n",
            "            1399,\n",
            "            1708,\n",
            "            1683,\n",
            "            613,\n",
            "            2276,\n",
            "            1402\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_verb\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.4847560975609756,\n",
            "        \"f1\": 0.45307443365695793,\n",
            "        \"precision\": 0.4827586206896552,\n",
            "        \"recall\": 0.4268292682926829,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            2266,\n",
            "            797,\n",
            "            1173,\n",
            "            1661,\n",
            "            1690,\n",
            "            763,\n",
            "            1170,\n",
            "            2252\n",
            "        ],\n",
            "        \"few_shot_samples\": 8,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_verb\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5945121951219512,\n",
            "        \"f1\": 0.5333333333333333,\n",
            "        \"precision\": 0.628099173553719,\n",
            "        \"recall\": 0.4634146341463415,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            254,\n",
            "            2223,\n",
            "            1388,\n",
            "            2199,\n",
            "            1877,\n",
            "            1858,\n",
            "            233,\n",
            "            1389,\n",
            "            1938,\n",
            "            2230,\n",
            "            1928,\n",
            "            2206\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_verb\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.6158536585365854,\n",
            "        \"f1\": 0.5594405594405595,\n",
            "        \"precision\": 0.6557377049180327,\n",
            "        \"recall\": 0.4878048780487805,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            2214,\n",
            "            640,\n",
            "            672,\n",
            "            1277,\n",
            "            1260,\n",
            "            1922,\n",
            "            699,\n",
            "            2222,\n",
            "            1179,\n",
            "            1918,\n",
            "            613,\n",
            "            1176\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_verb\"\n",
            "    },\n",
            "    {\n",
            "        \"model\": \"gpt3.5\",\n",
            "        \"acc\": 0.5640243902439024,\n",
            "        \"f1\": 0.4115226337448559,\n",
            "        \"precision\": 0.6329113924050633,\n",
            "        \"recall\": 0.3048780487804878,\n",
            "        \"few_shot_sample_indices\": [\n",
            "            2225,\n",
            "            175,\n",
            "            795,\n",
            "            2220,\n",
            "            1887,\n",
            "            830,\n",
            "            1572,\n",
            "            758,\n",
            "            1549,\n",
            "            201,\n",
            "            1876,\n",
            "            793\n",
            "        ],\n",
            "        \"few_shot_samples\": 12,\n",
            "        \"temperature\": 0.0,\n",
            "        \"eval_split\": \"val\",\n",
            "        \"dataset_name\": \"vua_verb\"\n",
            "    }\n",
            "]\n",
            "\n",
            "Lenght of test: 656\n",
            "Getting completions...\n",
            "Evaluating test set performance...\n",
            "Accuracy: 0.5716463414634146\n",
            "F1 score: 0.5873715124816447\n",
            "Precision: 0.56657223796034\n",
            "Recall: 0.6097560975609756\n",
            "\n",
            "Test results: {\n",
            "    \"model\": \"gpt3.5\",\n",
            "    \"acc\": 0.5716463414634146,\n",
            "    \"f1\": 0.5873715124816447,\n",
            "    \"precision\": 0.56657223796034,\n",
            "    \"recall\": 0.6097560975609756,\n",
            "    \"few_shot_sample_indices\": [\n",
            "        751,\n",
            "        784,\n",
            "        1358,\n",
            "        1355,\n",
            "        1034,\n",
            "        1036\n",
            "    ],\n",
            "    \"few_shot_samples\": 6,\n",
            "    \"temperature\": 0.0,\n",
            "    \"eval_split\": \"test\",\n",
            "    \"dataset_name\": \"vua_verb\",\n",
            "    \"fine_tuning\": false\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"$WORKDIR\" python -m src.main --llm gpt3.5 --temperature 0 --dataset vua_verb --task classification --seed 1 --evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tktzs_ZQlyMb"
      },
      "source": [
        "# (Llama2-7b) Fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbsGEf1mlyPg"
      },
      "source": [
        "## Metaphor List - Source domain prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byIfoXhkoCy4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0516d42d-cdc5-4994-ba2e-1ddab83743b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-29 16:23:21.528973: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-29 16:23:21.529042: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-29 16:23:21.529084: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-29 16:23:22.999728: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n",
            "\n",
            "llm: llama2-7b\n",
            "fine_tuned_model_path: None\n",
            "dataset: metaphor_list\n",
            "task: source_domain_prediction\n",
            "temperature: 0.0\n",
            "seed: 1\n",
            "evaluate: False\n",
            "fine_tuning: True\n",
            "\n",
            "\n",
            "config.json: 100% 609/609 [00:00<00:00, 3.35MB/s]\n",
            "model.safetensors.index.json: 100% 26.8k/26.8k [00:00<00:00, 91.4MB/s]\n",
            "Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00001-of-00002.safetensors:   0% 0.00/9.98G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 21.0M/9.98G [00:00<00:51, 195MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 62.9M/9.98G [00:00<00:35, 283MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 94.4M/9.98G [00:00<00:34, 288MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 136M/9.98G [00:00<00:32, 301MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 168M/9.98G [00:00<00:40, 240MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 199M/9.98G [00:00<00:38, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 231M/9.98G [00:00<00:37, 258MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 262M/9.98G [00:01<00:38, 256MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 294M/9.98G [00:03<03:52, 41.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 315M/9.98G [00:03<03:11, 50.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 336M/9.98G [00:03<02:42, 59.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 357M/9.98G [00:03<02:26, 65.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 377M/9.98G [00:03<01:59, 80.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 409M/9.98G [00:03<01:28, 108MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 440M/9.98G [00:04<01:10, 135MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 472M/9.98G [00:04<01:08, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 503M/9.98G [00:04<00:59, 159MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 535M/9.98G [00:04<00:52, 179MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 566M/9.98G [00:04<00:48, 193MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 598M/9.98G [00:04<00:46, 203MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 629M/9.98G [00:04<00:42, 218MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 661M/9.98G [00:05<00:38, 240MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 692M/9.98G [00:05<00:36, 254MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 724M/9.98G [00:05<00:35, 263MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 755M/9.98G [00:05<00:33, 271MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 786M/9.98G [00:05<00:36, 254MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 818M/9.98G [00:05<00:38, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 849M/9.98G [00:05<00:38, 240MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 881M/9.98G [00:05<00:35, 253MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 912M/9.98G [00:05<00:35, 257MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 944M/9.98G [00:06<00:34, 260MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 975M/9.98G [00:06<00:33, 265MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 1.01G/9.98G [00:06<00:33, 268MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 1.04G/9.98G [00:06<00:33, 266MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.07G/9.98G [00:06<00:33, 262MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.10G/9.98G [00:06<00:33, 265MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.13G/9.98G [00:06<00:33, 267MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 1.16G/9.98G [00:06<00:32, 270MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 1.20G/9.98G [00:07<00:32, 269MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 1.23G/9.98G [00:07<00:32, 272MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.26G/9.98G [00:07<00:32, 271MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.29G/9.98G [00:07<00:31, 274MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.32G/9.98G [00:07<00:31, 274MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 1.35G/9.98G [00:07<00:31, 276MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 1.38G/9.98G [00:07<00:31, 275MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 1.42G/9.98G [00:07<00:30, 277MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.45G/9.98G [00:07<00:30, 277MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.48G/9.98G [00:08<00:30, 279MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.51G/9.98G [00:08<00:30, 281MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.54G/9.98G [00:08<00:29, 288MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 1.58G/9.98G [00:08<00:27, 301MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 1.63G/9.98G [00:08<00:27, 305MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.66G/9.98G [00:08<00:42, 196MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.69G/9.98G [00:09<00:44, 185MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.72G/9.98G [00:09<00:41, 199MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.75G/9.98G [00:09<00:37, 217MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.78G/9.98G [00:09<00:35, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.81G/9.98G [00:09<00:33, 242MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.85G/9.98G [00:09<00:32, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 1.88G/9.98G [00:09<00:31, 257MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 1.91G/9.98G [00:09<00:29, 269MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 1.94G/9.98G [00:09<00:29, 273MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.97G/9.98G [00:10<00:45, 176MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 2.00G/9.98G [00:10<00:39, 200MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 2.03G/9.98G [00:10<00:35, 221MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 2.07G/9.98G [00:10<00:33, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 2.10G/9.98G [00:10<00:31, 253MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 2.13G/9.98G [00:10<00:30, 260MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.16G/9.98G [00:10<00:29, 265MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.19G/9.98G [00:11<00:28, 275MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.22G/9.98G [00:11<00:27, 279MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.25G/9.98G [00:11<00:27, 281MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.29G/9.98G [00:11<00:27, 276MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.32G/9.98G [00:11<00:29, 263MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.35G/9.98G [00:11<00:29, 256MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.38G/9.98G [00:11<00:29, 261MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.41G/9.98G [00:11<00:27, 270MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.45G/9.98G [00:11<00:26, 289MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.49G/9.98G [00:12<00:26, 284MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.52G/9.98G [00:12<00:25, 291MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.55G/9.98G [00:12<00:25, 291MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.58G/9.98G [00:12<00:25, 285MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.61G/9.98G [00:12<00:25, 287MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.64G/9.98G [00:12<00:26, 278MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.67G/9.98G [00:12<00:26, 278MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.71G/9.98G [00:12<00:25, 281MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.74G/9.98G [00:13<00:25, 282MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.77G/9.98G [00:13<00:25, 283MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.80G/9.98G [00:13<00:24, 288MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.83G/9.98G [00:13<00:31, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.86G/9.98G [00:13<00:37, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.89G/9.98G [00:13<00:36, 195MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.93G/9.98G [00:13<00:34, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 2.96G/9.98G [00:14<00:31, 222MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 2.99G/9.98G [00:14<00:32, 216MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 3.02G/9.98G [00:14<00:29, 232MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.05G/9.98G [00:18<04:40, 24.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.08G/9.98G [00:18<03:24, 33.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.11G/9.98G [00:18<02:31, 45.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.15G/9.98G [00:18<01:54, 59.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.18G/9.98G [00:18<01:27, 77.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.21G/9.98G [00:18<01:07, 99.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.24G/9.98G [00:18<00:54, 124MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.27G/9.98G [00:19<00:44, 151MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.30G/9.98G [00:19<00:45, 147MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.33G/9.98G [00:19<00:44, 148MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.36G/9.98G [00:19<00:43, 152MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.38G/9.98G [00:20<00:59, 111MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.40G/9.98G [00:23<05:18, 20.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.44G/9.98G [00:23<03:11, 34.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.47G/9.98G [00:23<02:18, 47.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.50G/9.98G [00:23<01:42, 62.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.53G/9.98G [00:23<01:19, 81.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.57G/9.98G [00:24<01:04, 99.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.60G/9.98G [00:24<00:52, 123MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.64G/9.98G [00:24<00:40, 155MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.67G/9.98G [00:24<00:35, 176MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.70G/9.98G [00:24<00:32, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.73G/9.98G [00:24<00:30, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.76G/9.98G [00:24<00:30, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.80G/9.98G [00:25<00:29, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.83G/9.98G [00:25<00:27, 223MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.86G/9.98G [00:25<00:25, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.89G/9.98G [00:25<00:24, 252MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.92G/9.98G [00:25<00:24, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 3.95G/9.98G [00:25<00:24, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 3.98G/9.98G [00:25<00:22, 261MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 4.02G/9.98G [00:25<00:24, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.05G/9.98G [00:26<00:26, 222MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.08G/9.98G [00:26<00:25, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.11G/9.98G [00:30<04:12, 23.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.13G/9.98G [00:30<03:22, 28.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.16G/9.98G [00:30<02:22, 40.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.19G/9.98G [00:30<01:43, 55.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.23G/9.98G [00:30<01:25, 67.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.25G/9.98G [00:31<01:12, 78.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.28G/9.98G [00:31<00:57, 99.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.30G/9.98G [00:31<00:51, 110MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.32G/9.98G [00:31<00:47, 120MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.34G/9.98G [00:31<00:42, 134MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.37G/9.98G [00:31<00:36, 155MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.40G/9.98G [00:31<00:31, 178MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.44G/9.98G [00:31<00:28, 193MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 4.47G/9.98G [00:32<00:25, 215MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 4.50G/9.98G [00:32<00:24, 224MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 4.53G/9.98G [00:32<00:23, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.56G/9.98G [00:32<00:22, 240MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.59G/9.98G [00:32<00:21, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.62G/9.98G [00:32<00:22, 242MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.66G/9.98G [00:32<00:22, 241MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.69G/9.98G [00:32<00:22, 240MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.72G/9.98G [00:33<00:21, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.75G/9.98G [00:33<00:21, 242MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.78G/9.98G [00:33<00:22, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.81G/9.98G [00:33<00:21, 235MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.84G/9.98G [00:33<00:21, 235MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.88G/9.98G [00:33<00:21, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.91G/9.98G [00:33<00:21, 240MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 4.94G/9.98G [00:35<01:23, 60.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 4.96G/9.98G [00:35<01:23, 59.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 4.99G/9.98G [00:35<01:01, 81.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 5.03G/9.98G [00:35<00:43, 113MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.06G/9.98G [00:36<00:36, 134MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.10G/9.98G [00:36<00:32, 149MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.13G/9.98G [00:36<00:28, 169MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.16G/9.98G [00:36<00:25, 188MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.19G/9.98G [00:36<00:23, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.22G/9.98G [00:36<00:20, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.26G/9.98G [00:36<00:18, 254MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.30G/9.98G [00:36<00:17, 261MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.33G/9.98G [00:37<00:17, 267MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 5.36G/9.98G [00:37<00:16, 273MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 5.39G/9.98G [00:37<00:16, 273MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 5.42G/9.98G [00:37<00:16, 274MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.45G/9.98G [00:37<00:16, 276MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.48G/9.98G [00:37<00:16, 276MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.52G/9.98G [00:37<00:15, 280MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 5.55G/9.98G [00:37<00:15, 283MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 5.58G/9.98G [00:37<00:15, 288MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 5.61G/9.98G [00:38<00:15, 285MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.64G/9.98G [00:38<00:15, 287MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.67G/9.98G [00:38<00:15, 286MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.70G/9.98G [00:38<00:15, 277MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.74G/9.98G [00:38<00:15, 272MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.77G/9.98G [00:38<00:16, 262MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.80G/9.98G [00:38<00:15, 263MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.83G/9.98G [00:38<00:16, 259MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.86G/9.98G [00:38<00:16, 254MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.89G/9.98G [00:39<00:15, 260MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.92G/9.98G [00:39<00:16, 253MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 5.96G/9.98G [00:39<00:16, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 5.99G/9.98G [00:39<00:16, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 6.02G/9.98G [00:39<00:15, 252MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.05G/9.98G [00:39<00:15, 253MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.08G/9.98G [00:39<00:16, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.11G/9.98G [00:39<00:15, 253MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.14G/9.98G [00:40<00:15, 255MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.18G/9.98G [00:40<00:14, 257MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.21G/9.98G [00:40<00:15, 239MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.24G/9.98G [00:40<00:18, 204MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.27G/9.98G [00:40<00:19, 186MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.29G/9.98G [00:40<00:19, 187MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.32G/9.98G [00:41<00:17, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 6.35G/9.98G [00:41<00:16, 213MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 6.39G/9.98G [00:41<00:16, 215MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 6.42G/9.98G [00:41<00:15, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.45G/9.98G [00:41<00:14, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.48G/9.98G [00:41<00:13, 258MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.51G/9.98G [00:41<00:13, 259MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.54G/9.98G [00:41<00:12, 268MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.57G/9.98G [00:41<00:12, 277MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.61G/9.98G [00:42<00:11, 284MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.64G/9.98G [00:42<00:11, 290MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.68G/9.98G [00:42<00:10, 301MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.71G/9.98G [00:42<00:10, 305MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 6.74G/9.98G [00:42<00:11, 287MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 6.77G/9.98G [00:42<00:11, 286MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 6.82G/9.98G [00:42<00:10, 297MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.85G/9.98G [00:42<00:11, 281MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.88G/9.98G [00:43<00:12, 253MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.91G/9.98G [00:43<00:11, 260MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 6.94G/9.98G [00:43<00:11, 261MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 6.97G/9.98G [00:43<00:11, 267MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 7.00G/9.98G [00:43<00:11, 261MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.04G/9.98G [00:43<00:11, 253MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.07G/9.98G [00:43<00:11, 258MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.10G/9.98G [00:43<00:11, 244MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.13G/9.98G [00:44<00:11, 254MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.16G/9.98G [00:44<00:11, 245MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.19G/9.98G [00:44<00:11, 241MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.22G/9.98G [00:44<00:10, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.26G/9.98G [00:44<00:11, 245MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.29G/9.98G [00:44<00:11, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.32G/9.98G [00:44<00:11, 239MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.35G/9.98G [00:44<00:11, 232MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.38G/9.98G [00:45<00:10, 239MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.41G/9.98G [00:45<00:10, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.44G/9.98G [00:45<00:10, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.49G/9.98G [00:45<00:09, 269MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.52G/9.98G [00:45<00:10, 226MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.55G/9.98G [00:45<00:11, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.58G/9.98G [00:45<00:11, 208MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.61G/9.98G [00:46<00:11, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.64G/9.98G [00:46<00:11, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.67G/9.98G [00:46<00:12, 181MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.69G/9.98G [00:50<01:54, 19.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.73G/9.98G [00:50<01:09, 32.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.76G/9.98G [00:50<00:50, 43.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.79G/9.98G [00:50<00:38, 57.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.82G/9.98G [00:51<00:28, 75.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.85G/9.98G [00:51<00:23, 90.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.89G/9.98G [00:51<00:18, 111MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.92G/9.98G [00:51<00:15, 136MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 7.95G/9.98G [00:51<00:12, 161MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 7.98G/9.98G [00:51<00:10, 184MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 8.01G/9.98G [00:51<00:09, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.04G/9.98G [00:51<00:09, 208MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.07G/9.98G [00:52<00:08, 223MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.11G/9.98G [00:52<00:08, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.14G/9.98G [00:52<00:07, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.17G/9.98G [00:52<00:07, 258MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.20G/9.98G [00:52<00:06, 266MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.23G/9.98G [00:52<00:06, 273MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.26G/9.98G [00:52<00:06, 282MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.29G/9.98G [00:52<00:06, 279MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.33G/9.98G [00:52<00:06, 272MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 8.36G/9.98G [00:53<00:05, 272MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 8.39G/9.98G [00:53<00:05, 275MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 8.42G/9.98G [00:53<00:05, 278MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.45G/9.98G [00:53<00:05, 278MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.48G/9.98G [00:53<00:05, 268MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.51G/9.98G [00:53<00:05, 277MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 8.55G/9.98G [00:53<00:05, 281MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 8.58G/9.98G [00:53<00:05, 277MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 8.61G/9.98G [00:53<00:05, 269MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.64G/9.98G [00:54<00:04, 268MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.67G/9.98G [00:54<00:04, 280MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.71G/9.98G [00:54<00:05, 240MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.75G/9.98G [00:54<00:05, 220MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.78G/9.98G [00:54<00:05, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.81G/9.98G [00:54<00:05, 200MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.83G/9.98G [00:55<00:05, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 8.86G/9.98G [00:55<00:05, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 8.88G/9.98G [00:55<00:13, 81.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 8.92G/9.98G [00:56<00:08, 117MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 8.97G/9.98G [00:56<00:06, 156MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 9.01G/9.98G [00:56<00:05, 187MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 9.04G/9.98G [00:56<00:04, 202MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 9.07G/9.98G [00:56<00:04, 217MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 9.10G/9.98G [00:56<00:03, 234MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.13G/9.98G [00:56<00:03, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.16G/9.98G [00:56<00:03, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.20G/9.98G [00:57<00:03, 256MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.23G/9.98G [00:57<00:02, 263MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.26G/9.98G [00:57<00:02, 269MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.29G/9.98G [00:57<00:02, 277MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.32G/9.98G [00:57<00:02, 272MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.35G/9.98G [00:57<00:02, 278MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.38G/9.98G [00:57<00:02, 277MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.42G/9.98G [00:57<00:02, 274MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.45G/9.98G [00:57<00:01, 277MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.48G/9.98G [00:58<00:01, 279MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.51G/9.98G [00:58<00:01, 273MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.54G/9.98G [00:58<00:01, 279MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.57G/9.98G [00:58<00:01, 280MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.60G/9.98G [00:58<00:01, 275MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.64G/9.98G [00:58<00:01, 279MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.67G/9.98G [00:58<00:01, 277MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.70G/9.98G [00:58<00:00, 280MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.73G/9.98G [00:58<00:00, 276MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.76G/9.98G [00:59<00:00, 276MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.79G/9.98G [00:59<00:00, 267MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.83G/9.98G [00:59<00:00, 252MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.86G/9.98G [00:59<00:00, 245MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.89G/9.98G [00:59<00:00, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.92G/9.98G [00:59<00:00, 229MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 9.95G/9.98G [00:59<00:00, 228MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 9.98G/9.98G [01:00<00:00, 166MB/s]\n",
            "Downloading shards:  50% 1/2 [01:00<01:00, 60.35s/it]\n",
            "model-00002-of-00002.safetensors:   0% 0.00/3.50G [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   1% 31.5M/3.50G [00:00<00:15, 220MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   2% 62.9M/3.50G [00:00<00:16, 213MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   3% 94.4M/3.50G [00:00<00:14, 241MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   4% 136M/3.50G [00:00<00:12, 271MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:   5% 168M/3.50G [00:00<00:11, 279MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   6% 199M/3.50G [00:01<00:21, 153MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   7% 231M/3.50G [00:01<00:20, 161MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   7% 262M/3.50G [00:01<00:17, 181MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   8% 294M/3.50G [00:01<00:16, 200MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   9% 325M/3.50G [00:01<00:14, 213MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  10% 357M/3.50G [00:01<00:15, 201MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  11% 388M/3.50G [00:01<00:15, 196MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  12% 419M/3.50G [00:02<00:15, 203MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  13% 451M/3.50G [00:02<00:14, 213MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  14% 482M/3.50G [00:02<00:13, 220MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  15% 514M/3.50G [00:02<00:13, 223MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  16% 545M/3.50G [00:02<00:13, 224MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  16% 577M/3.50G [00:02<00:13, 217MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  17% 608M/3.50G [00:02<00:12, 225MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  18% 640M/3.50G [00:03<00:12, 228MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  19% 671M/3.50G [00:03<00:12, 233MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  20% 703M/3.50G [00:03<00:12, 228MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  21% 734M/3.50G [00:03<00:11, 235MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  22% 765M/3.50G [00:03<00:11, 239MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  23% 797M/3.50G [00:03<00:11, 234MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  24% 828M/3.50G [00:03<00:11, 236MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  25% 860M/3.50G [00:03<00:11, 233MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  25% 891M/3.50G [00:04<00:10, 250MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  26% 923M/3.50G [00:04<00:10, 239MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  27% 954M/3.50G [00:04<00:10, 244MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  28% 986M/3.50G [00:04<00:10, 238MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  29% 1.02G/3.50G [00:04<00:09, 250MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  30% 1.05G/3.50G [00:04<00:10, 237MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  31% 1.08G/3.50G [00:04<00:10, 224MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  32% 1.11G/3.50G [00:05<00:10, 238MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  33% 1.14G/3.50G [00:05<00:09, 242MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  34% 1.17G/3.50G [00:05<00:09, 239MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  34% 1.21G/3.50G [00:05<00:09, 250MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  35% 1.24G/3.50G [00:05<00:09, 249MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  36% 1.27G/3.50G [00:05<00:08, 264MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  37% 1.30G/3.50G [00:05<00:08, 270MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  38% 1.33G/3.50G [00:05<00:07, 273MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  39% 1.36G/3.50G [00:05<00:07, 284MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  40% 1.39G/3.50G [00:06<00:09, 224MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  41% 1.43G/3.50G [00:10<01:26, 23.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  42% 1.46G/3.50G [00:10<01:01, 33.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  43% 1.49G/3.50G [00:10<00:46, 43.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  43% 1.51G/3.50G [00:10<00:37, 52.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  44% 1.53G/3.50G [00:10<00:31, 63.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  45% 1.56G/3.50G [00:10<00:23, 82.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  46% 1.59G/3.50G [00:11<00:22, 85.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  47% 1.64G/3.50G [00:11<00:15, 118MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  48% 1.67G/3.50G [00:12<00:28, 65.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  48% 1.69G/3.50G [00:15<01:14, 24.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  49% 1.71G/3.50G [00:15<00:59, 30.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  50% 1.74G/3.50G [00:15<00:41, 42.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  50% 1.76G/3.50G [00:15<00:34, 51.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  51% 1.78G/3.50G [00:15<00:27, 63.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  52% 1.81G/3.50G [00:15<00:19, 85.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  52% 1.84G/3.50G [00:15<00:16, 98.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  53% 1.87G/3.50G [00:16<00:13, 121MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  54% 1.90G/3.50G [00:16<00:10, 149MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  55% 1.93G/3.50G [00:16<00:08, 175MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  56% 1.96G/3.50G [00:16<00:08, 190MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  57% 1.99G/3.50G [00:16<00:07, 202MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  58% 2.02G/3.50G [00:16<00:06, 215MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  59% 2.06G/3.50G [00:16<00:06, 216MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  60% 2.09G/3.50G [00:17<00:06, 218MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  61% 2.12G/3.50G [00:17<00:06, 226MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  61% 2.15G/3.50G [00:17<00:06, 220MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  62% 2.18G/3.50G [00:17<00:05, 224MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  63% 2.21G/3.50G [00:17<00:05, 223MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  64% 2.24G/3.50G [00:17<00:05, 233MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  65% 2.28G/3.50G [00:17<00:05, 238MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  66% 2.31G/3.50G [00:17<00:05, 236MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  67% 2.34G/3.50G [00:18<00:04, 248MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  68% 2.37G/3.50G [00:18<00:04, 253MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  69% 2.40G/3.50G [00:18<00:04, 242MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  69% 2.43G/3.50G [00:18<00:04, 242MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  70% 2.46G/3.50G [00:18<00:04, 242MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  71% 2.50G/3.50G [00:18<00:04, 242MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  72% 2.53G/3.50G [00:18<00:04, 238MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  73% 2.56G/3.50G [00:19<00:04, 224MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  74% 2.59G/3.50G [00:19<00:04, 228MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  75% 2.62G/3.50G [00:19<00:03, 226MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  76% 2.65G/3.50G [00:20<00:09, 84.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  77% 2.68G/3.50G [00:20<00:07, 107MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  78% 2.72G/3.50G [00:20<00:06, 131MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  78% 2.75G/3.50G [00:20<00:05, 132MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  79% 2.77G/3.50G [00:20<00:05, 140MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  80% 2.79G/3.50G [00:20<00:04, 149MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  81% 2.82G/3.50G [00:21<00:04, 169MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  81% 2.84G/3.50G [00:21<00:03, 169MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  82% 2.86G/3.50G [00:21<00:03, 169MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  83% 2.89G/3.50G [00:21<00:03, 184MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  84% 2.93G/3.50G [00:21<00:02, 205MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  84% 2.96G/3.50G [00:21<00:02, 209MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  85% 2.99G/3.50G [00:21<00:02, 220MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  86% 3.02G/3.50G [00:21<00:02, 236MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  87% 3.05G/3.50G [00:22<00:01, 228MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  88% 3.08G/3.50G [00:22<00:01, 241MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  89% 3.11G/3.50G [00:22<00:01, 243MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  90% 3.15G/3.50G [00:22<00:01, 242MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  91% 3.18G/3.50G [00:22<00:01, 251MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  92% 3.21G/3.50G [00:22<00:01, 242MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  93% 3.24G/3.50G [00:22<00:01, 241MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  93% 3.27G/3.50G [00:22<00:00, 246MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  94% 3.30G/3.50G [00:23<00:00, 245MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  95% 3.33G/3.50G [00:23<00:00, 254MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  96% 3.37G/3.50G [00:23<00:00, 259MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  97% 3.40G/3.50G [00:23<00:00, 264MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  98% 3.43G/3.50G [00:23<00:00, 272MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  99% 3.46G/3.50G [00:23<00:00, 265MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 3.50G/3.50G [00:23<00:00, 147MB/s]\n",
            "Downloading shards: 100% 2/2 [01:24<00:00, 42.16s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [01:16<00:00, 38.21s/it]\n",
            "generation_config.json: 100% 188/188 [00:00<00:00, 1.09MB/s]\n",
            "tokenizer_config.json: 100% 776/776 [00:00<00:00, 4.32MB/s]\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 383MB/s]\n",
            "tokenizer.json: 100% 1.84M/1.84M [00:00<00:00, 7.19MB/s]\n",
            "special_tokens_map.json: 100% 414/414 [00:00<00:00, 2.54MB/s]\n",
            "Lenght of train: 132\n",
            "Lenght of valid: 120\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:159: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
            "  warnings.warn(\n",
            "100% 1/1 [00:00<00:00,  5.23ba/s]\n",
            "100% 1/1 [00:00<00:00, 55.71ba/s]\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:127: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n",
            "For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "Cloning https://huggingface.co/lfmatosmelo/llama2-7b-metaphor-list-source-domain-prediction into local empty directory.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 1.8013, 'learning_rate': 2.9289321881345254e-05, 'epoch': 0.76}\n",
            "{'train_runtime': 39.2112, 'train_samples_per_second': 3.366, 'train_steps_per_second': 0.842, 'train_loss': 1.5898933410644531, 'epoch': 1.0}\n",
            "Saving fine-tuned model to llama2-7b-metaphor-list-source-domain-prediction\n",
            "Uploading fine-tuned model (llama2-7b-metaphor-list-source-domain-prediction) to HuggingFace Hub\n",
            "Upload file adapter_model.bin:   0% 1.00/128M [00:00<?, ?B/s]\n",
            "Upload file training_args.bin:   0% 1.00/4.37k [00:00<?, ?B/s]\u001b[A\n",
            "Upload file adapter_model.bin:  95% 122M/128M [00:06<00:00, 24.1MB/s] To https://huggingface.co/lfmatosmelo/llama2-7b-metaphor-list-source-domain-prediction\n",
            "   ac4aa17..ae1f6ae  main -> main\n",
            "\n",
            "Upload file adapter_model.bin: 100% 128M/128M [00:09<00:00, 14.9MB/s]\n",
            "\n",
            "Upload file training_args.bin: 100% 4.37k/4.37k [00:09<00:00, 496B/s]  \n",
            "To https://huggingface.co/lfmatosmelo/llama2-7b-metaphor-list-source-domain-prediction\n",
            "   ae1f6ae..36ae894  main -> main\n",
            "\n",
            "Fine-tuned model saved to 'llama2-7b-metaphor-list-source-domain-prediction'\n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"$WORKDIR\" python -m src.main --llm llama2-7b --temperature 0 --dataset metaphor_list --task source_domain_prediction --seed 1 --fine_tuning --push-model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7hPGqS-55O3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "483e5fcd-dc5e-4a62-fd92-e8b6be7f8877"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-29 17:12:04.133192: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-29 17:12:04.133244: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-29 17:12:04.133280: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-29 17:12:06.320844: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "User is already logged in.\n",
            "\n",
            "llm: llama2-7b\n",
            "fine_tuned_model_path: llama2-7b-metaphor-list-source-domain-prediction\n",
            "dataset: metaphor_list\n",
            "task: source_domain_prediction\n",
            "temperature: 0.0\n",
            "seed: 1\n",
            "evaluate: True\n",
            "fine_tuning: True\n",
            "\n",
            "\n",
            "Fine-tuned model path received, model will be loaded for evaluation\n",
            "No. of unreachable objects: 0\n",
            "Loading checkpoint shards: 100% 2/2 [01:14<00:00, 37.26s/it]\n",
            "Reuploading llama2-7b-metaphor-list-source-domain-prediction after merging weights\n",
            "pytorch_model-00001-of-00002.bin:   0% 0.00/9.98G [00:00<?, ?B/s]\n",
            "Upload 2 LFS files:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   0% 16.4k/9.98G [00:00<30:21:44, 91.3kB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   0% 6.52M/9.98G [00:00<07:46, 21.4MB/s]   \n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   0% 8.67M/9.98G [00:00<08:26, 19.7MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   0% 13.6M/9.98G [00:00<06:37, 25.1MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   0% 16.0M/3.50G [00:00<03:25, 16.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   0% 28.4M/9.98G [00:01<07:35, 21.9MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   1% 36.3M/3.50G [00:01<02:36, 22.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   0% 37.3M/9.98G [00:02<08:55, 18.6MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   0% 45.0M/9.98G [00:02<07:12, 23.0MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   2% 59.2M/3.50G [00:02<02:22, 24.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   2% 64.0M/3.50G [00:03<03:12, 17.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   1% 68.4M/9.98G [00:03<07:39, 21.6MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   1% 72.9M/9.98G [00:03<06:57, 23.7MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   1% 77.2M/9.98G [00:03<07:18, 22.6MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   3% 97.2M/3.50G [00:04<02:25, 23.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   1% 95.1M/9.98G [00:04<05:07, 32.1MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   1% 101M/9.98G [00:04<06:00, 27.4MB/s] \n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   4% 128M/3.50G [00:04<01:52, 29.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   1% 111M/9.98G [00:05<05:54, 27.8MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   1% 115M/9.98G [00:05<09:11, 17.9MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   1% 119M/9.98G [00:05<07:53, 20.8MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   1% 125M/9.98G [00:05<06:18, 26.0MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   5% 178M/3.50G [00:06<01:36, 34.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   1% 143M/9.98G [00:06<05:07, 32.0MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   6% 198M/3.50G [00:06<01:29, 36.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   6% 208M/3.50G [00:06<01:34, 34.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   6% 216M/3.50G [00:07<01:21, 40.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   2% 174M/9.98G [00:07<05:00, 32.6MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   6% 226M/3.50G [00:07<02:35, 21.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   2% 181M/9.98G [00:08<05:56, 27.5MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   2% 206M/9.98G [00:08<03:48, 42.7MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   7% 256M/3.50G [00:08<02:05, 25.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   2% 227M/9.98G [00:09<04:43, 34.3MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   2% 237M/9.98G [00:09<03:50, 42.3MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   2% 243M/9.98G [00:09<05:03, 32.1MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   8% 288M/3.50G [00:09<02:16, 23.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   3% 269M/9.98G [00:10<03:24, 47.4MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   9% 304M/3.50G [00:10<02:09, 24.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   3% 293M/9.98G [00:11<05:06, 31.6MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   3% 302M/9.98G [00:11<04:17, 37.6MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   3% 315M/9.98G [00:11<05:24, 29.8MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   3% 319M/9.98G [00:11<05:22, 29.9MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  10% 348M/3.50G [00:11<01:45, 29.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  10% 354M/3.50G [00:12<01:54, 27.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   3% 334M/9.98G [00:12<04:57, 32.4MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   3% 345M/9.98G [00:12<04:49, 33.2MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   4% 352M/9.98G [00:13<06:10, 26.0MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   4% 360M/9.98G [00:13<04:54, 32.6MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   4% 368M/9.98G [00:13<05:23, 29.7MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   4% 375M/9.98G [00:13<04:28, 35.8MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   4% 399M/9.98G [00:14<03:15, 49.1MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  12% 432M/3.50G [00:14<01:40, 30.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   4% 416M/9.98G [00:15<05:18, 30.0MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  13% 454M/3.50G [00:15<01:38, 30.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   4% 424M/9.98G [00:15<04:33, 35.0MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   4% 446M/9.98G [00:15<03:35, 44.3MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  14% 480M/3.50G [00:15<01:40, 30.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   5% 463M/9.98G [00:16<03:40, 43.1MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   5% 480M/9.98G [00:16<04:29, 35.2MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   5% 492M/9.98G [00:16<03:30, 45.1MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  15% 522M/3.50G [00:16<01:21, 36.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   5% 498M/9.98G [00:17<04:36, 34.3MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   5% 511M/9.98G [00:17<03:53, 40.6MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  16% 544M/3.50G [00:17<01:27, 33.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   5% 526M/9.98G [00:17<03:37, 43.4MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   5% 532M/9.98G [00:18<04:34, 34.4MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  16% 576M/3.50G [00:18<01:14, 39.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   6% 564M/9.98G [00:18<03:56, 39.8MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   6% 591M/9.98G [00:19<03:10, 49.3MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  17% 608M/3.50G [00:19<01:42, 28.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  18% 621M/3.50G [00:19<01:13, 39.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  18% 628M/3.50G [00:19<01:28, 32.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   6% 598M/9.98G [00:20<06:51, 22.8MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   6% 604M/9.98G [00:20<06:11, 25.2MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   6% 610M/9.98G [00:20<06:28, 24.1MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   6% 617M/9.98G [00:20<05:25, 28.8MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   6% 638M/9.98G [00:21<04:26, 35.0MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  20% 688M/3.50G [00:21<01:27, 32.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   6% 645M/9.98G [00:21<04:58, 31.3MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   7% 670M/9.98G [00:22<03:20, 46.5MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  21% 720M/3.50G [00:22<01:26, 32.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   7% 678M/9.98G [00:22<04:03, 38.2MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  21% 741M/3.50G [00:22<01:11, 38.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  21% 752M/3.50G [00:22<01:12, 37.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   7% 709M/9.98G [00:23<05:06, 30.2MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  22% 773M/3.50G [00:23<01:44, 26.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   7% 734M/9.98G [00:24<03:39, 42.0MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   7% 742M/9.98G [00:24<04:35, 33.5MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   8% 750M/9.98G [00:24<03:52, 39.6MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  23% 809M/3.50G [00:24<01:11, 37.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  23% 816M/3.50G [00:25<01:33, 28.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   8% 757M/9.98G [00:25<06:50, 22.4MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   8% 790M/9.98G [00:26<04:33, 33.6MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  24% 848M/3.50G [00:26<01:46, 24.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   8% 814M/9.98G [00:26<03:28, 43.9MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  25% 864M/3.50G [00:26<01:40, 26.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   8% 832M/9.98G [00:27<04:29, 33.9MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   8% 841M/9.98G [00:27<03:42, 41.0MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   8% 847M/9.98G [00:27<03:30, 43.5MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   9% 854M/9.98G [00:27<04:44, 32.0MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   9% 859M/9.98G [00:27<04:22, 34.7MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  26% 915M/3.50G [00:28<01:20, 32.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   9% 879M/9.98G [00:28<03:26, 44.2MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  27% 934M/3.50G [00:28<01:08, 37.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   9% 886M/9.98G [00:28<05:30, 27.5MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   9% 892M/9.98G [00:29<04:54, 30.9MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   9% 897M/9.98G [00:29<06:05, 24.9MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   9% 908M/9.98G [00:29<04:11, 36.1MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   9% 920M/9.98G [00:29<04:24, 34.2MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  28% 991M/3.50G [00:29<01:01, 41.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   9% 942M/9.98G [00:30<03:31, 42.8MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  29% 1.01G/3.50G [00:30<01:12, 34.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  10% 949M/9.98G [00:30<04:27, 33.8MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  10% 981M/9.98G [00:31<04:07, 36.3MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  30% 1.04G/3.50G [00:31<01:42, 23.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  30% 1.05G/3.50G [00:31<01:10, 34.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  10% 992M/9.98G [00:32<05:19, 28.1MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  10% 1.01G/9.98G [00:32<03:52, 38.6MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  10% 1.04G/9.98G [00:33<03:36, 41.3MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  31% 1.09G/3.50G [00:33<02:04, 19.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.05G/9.98G [00:33<03:32, 42.0MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.06G/9.98G [00:34<03:59, 37.2MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.07G/9.98G [00:34<03:44, 39.8MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  32% 1.12G/3.50G [00:34<01:25, 27.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.07G/9.98G [00:34<07:12, 20.6MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.08G/9.98G [00:34<05:58, 24.9MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.09G/9.98G [00:35<05:40, 26.1MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.10G/9.98G [00:35<04:38, 31.9MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  33% 1.17G/3.50G [00:35<01:03, 36.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.12G/9.98G [00:35<03:31, 41.8MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.12G/9.98G [00:36<04:07, 35.8MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.14G/9.98G [00:36<04:04, 36.1MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.14G/9.98G [00:36<03:37, 40.6MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  35% 1.22G/3.50G [00:36<00:56, 40.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  35% 1.23G/3.50G [00:37<01:04, 34.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.17G/9.98G [00:37<04:03, 36.2MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.20G/9.98G [00:38<03:17, 44.5MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.21G/9.98G [00:38<03:38, 40.1MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.22G/9.98G [00:38<04:04, 35.8MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.23G/9.98G [00:38<03:04, 47.5MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  36% 1.27G/3.50G [00:38<01:25, 26.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.24G/9.98G [00:39<03:47, 38.4MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.26G/9.98G [00:39<02:45, 52.6MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  37% 1.30G/3.50G [00:39<01:12, 30.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  37% 1.31G/3.50G [00:39<00:48, 44.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.27G/9.98G [00:40<05:24, 26.8MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  38% 1.33G/3.50G [00:40<01:07, 32.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.29G/9.98G [00:40<03:38, 39.8MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.30G/9.98G [00:41<04:22, 33.0MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  39% 1.36G/3.50G [00:41<01:02, 34.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.33G/9.98G [00:41<03:15, 44.3MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  39% 1.38G/3.50G [00:41<00:54, 39.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  40% 1.39G/3.50G [00:42<01:06, 31.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.33G/9.98G [00:42<05:26, 26.5MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.36G/9.98G [00:43<04:13, 33.9MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  41% 1.42G/3.50G [00:43<01:11, 28.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.38G/9.98G [00:43<04:23, 32.6MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.38G/9.98G [00:43<03:50, 37.2MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.40G/9.98G [00:43<04:23, 32.6MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.40G/9.98G [00:44<03:42, 38.6MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  42% 1.46G/3.50G [00:44<00:57, 35.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.44G/9.98G [00:44<02:54, 48.8MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  42% 1.48G/3.50G [00:44<01:36, 21.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  42% 1.48G/3.50G [00:44<01:14, 27.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  43% 1.49G/3.50G [00:45<01:19, 25.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.45G/9.98G [00:45<03:54, 36.4MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  43% 1.51G/3.50G [00:45<01:00, 32.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.46G/9.98G [00:45<04:36, 30.7MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.48G/9.98G [00:46<03:35, 39.5MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  44% 1.54G/3.50G [00:46<00:59, 32.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  44% 1.55G/3.50G [00:46<00:40, 47.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.50G/9.98G [00:47<04:11, 33.7MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  45% 1.57G/3.50G [00:47<00:53, 35.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.51G/9.98G [00:47<04:40, 30.2MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.53G/9.98G [00:47<03:09, 44.6MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  46% 1.60G/3.50G [00:47<00:55, 34.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.54G/9.98G [00:48<03:54, 36.0MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.57G/9.98G [00:48<02:54, 48.2MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  47% 1.63G/3.50G [00:48<00:50, 37.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.57G/9.98G [00:48<03:40, 38.2MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.60G/9.98G [00:49<02:43, 51.4MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  48% 1.66G/3.50G [00:49<00:52, 34.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.62G/9.98G [00:50<03:59, 34.8MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.63G/9.98G [00:50<03:20, 41.5MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.63G/9.98G [00:50<03:08, 44.3MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  49% 1.70G/3.50G [00:50<00:57, 31.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.64G/9.98G [00:50<04:37, 30.0MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.66G/9.98G [00:51<03:09, 44.0MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  49% 1.73G/3.50G [00:51<00:54, 32.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.67G/9.98G [00:51<04:04, 33.9MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.69G/9.98G [00:51<02:59, 46.1MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  50% 1.76G/3.50G [00:51<00:47, 36.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.70G/9.98G [00:52<03:36, 38.3MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.73G/9.98G [00:52<02:44, 50.2MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  51% 1.79G/3.50G [00:52<00:49, 34.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.73G/9.98G [00:52<03:21, 40.9MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.76G/9.98G [00:53<02:41, 50.9MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  52% 1.82G/3.50G [00:53<00:42, 39.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.77G/9.98G [00:53<03:21, 40.8MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.79G/9.98G [00:54<02:55, 46.7MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  53% 1.86G/3.50G [00:54<00:50, 32.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.80G/9.98G [00:54<03:25, 39.8MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.83G/9.98G [00:55<03:24, 39.9MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.84G/9.98G [00:55<03:50, 35.3MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.85G/9.98G [00:55<03:22, 40.2MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.87G/9.98G [00:56<02:53, 46.8MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  55% 1.92G/3.50G [00:56<00:47, 33.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.88G/9.98G [00:56<04:05, 33.0MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.88G/9.98G [00:56<03:33, 37.8MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  56% 1.95G/3.50G [00:56<00:39, 39.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  56% 1.95G/3.50G [00:57<00:48, 31.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.92G/9.98G [00:57<03:04, 43.8MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  56% 1.97G/3.50G [00:57<00:56, 27.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.93G/9.98G [00:58<04:31, 29.6MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.93G/9.98G [00:58<03:49, 35.1MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.94G/9.98G [00:58<04:38, 28.8MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  20% 1.95G/9.98G [00:58<03:54, 34.3MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  20% 1.95G/9.98G [00:59<04:30, 29.7MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  20% 1.97G/9.98G [00:59<02:49, 47.1MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  20% 1.97G/9.98G [00:59<03:35, 37.2MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  58% 2.03G/3.50G [00:59<00:46, 31.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  20% 2.00G/9.98G [01:00<02:50, 46.8MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  59% 2.05G/3.50G [01:00<00:44, 32.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  20% 2.01G/9.98G [01:00<03:25, 38.8MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  59% 2.07G/3.50G [01:00<00:41, 34.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  20% 2.03G/9.98G [01:00<02:35, 51.2MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  20% 2.04G/9.98G [01:01<03:14, 40.9MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  60% 2.10G/3.50G [01:01<00:37, 37.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  60% 2.10G/3.50G [01:01<00:30, 45.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  60% 2.11G/3.50G [01:01<00:36, 38.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.06G/9.98G [01:01<03:08, 41.9MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.09G/9.98G [01:02<02:54, 45.3MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  61% 2.14G/3.50G [01:02<00:53, 25.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.13G/9.98G [01:03<02:43, 48.2MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.13G/9.98G [01:03<03:14, 40.4MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  62% 2.18G/3.50G [01:03<00:53, 24.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.16G/9.98G [01:04<02:42, 48.1MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.19G/9.98G [01:04<02:27, 52.8MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  63% 2.21G/3.50G [01:05<01:21, 15.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.20G/9.98G [01:06<07:00, 18.5MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.22G/9.98G [01:06<04:27, 29.0MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  64% 2.24G/3.50G [01:06<00:53, 23.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.24G/9.98G [01:06<03:19, 38.8MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.25G/9.98G [01:07<05:35, 23.0MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  65% 2.27G/3.50G [01:07<00:52, 23.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.28G/9.98G [01:08<03:57, 32.4MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.29G/9.98G [01:08<03:31, 36.4MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.29G/9.98G [01:08<03:46, 34.0MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.30G/9.98G [01:08<02:50, 44.9MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  66% 2.31G/3.50G [01:08<00:35, 33.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  66% 2.32G/3.50G [01:09<00:39, 29.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  67% 2.33G/3.50G [01:09<00:25, 44.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  67% 2.34G/3.50G [01:09<00:29, 39.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  67% 2.35G/3.50G [01:09<00:33, 34.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.33G/9.98G [01:10<04:29, 28.3MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  68% 2.37G/3.50G [01:10<00:37, 30.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.34G/9.98G [01:10<04:17, 29.6MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.37G/9.98G [01:11<03:01, 41.9MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  69% 2.40G/3.50G [01:11<00:36, 29.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.41G/9.98G [01:12<02:46, 45.3MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.43G/9.98G [01:13<04:20, 28.9MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.45G/9.98G [01:13<03:06, 40.3MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.45G/9.98G [01:13<03:28, 36.2MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  70% 2.45G/3.50G [01:13<00:48, 21.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.48G/9.98G [01:14<02:39, 47.1MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.49G/9.98G [01:14<03:19, 37.5MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.50G/9.98G [01:15<03:56, 31.6MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.51G/9.98G [01:15<03:11, 39.0MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.53G/9.98G [01:15<02:37, 47.2MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  72% 2.51G/3.50G [01:15<00:32, 30.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.54G/9.98G [01:16<03:29, 35.6MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.55G/9.98G [01:16<02:57, 41.8MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.56G/9.98G [01:16<02:47, 44.2MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.56G/9.98G [01:16<03:25, 36.1MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.57G/9.98G [01:16<03:09, 39.1MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.58G/9.98G [01:17<03:43, 33.1MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.59G/9.98G [01:17<02:47, 44.1MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.59G/9.98G [01:17<03:23, 36.2MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.61G/9.98G [01:17<03:32, 34.6MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.62G/9.98G [01:17<02:55, 42.1MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.63G/9.98G [01:18<03:17, 37.1MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.64G/9.98G [01:18<03:33, 34.4MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.66G/9.98G [01:19<03:00, 40.5MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.67G/9.98G [01:19<02:35, 46.9MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  75% 2.63G/3.50G [01:19<00:29, 29.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  75% 2.64G/3.50G [01:19<00:23, 36.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.69G/9.98G [01:19<03:09, 38.5MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  76% 2.66G/3.50G [01:19<00:27, 31.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  76% 2.67G/3.50G [01:20<00:17, 47.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.69G/9.98G [01:20<05:01, 24.1MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  77% 2.69G/3.50G [01:20<00:21, 37.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.72G/9.98G [01:20<03:04, 39.3MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.73G/9.98G [01:21<03:30, 34.5MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  78% 2.72G/3.50G [01:21<00:21, 37.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.75G/9.98G [01:21<02:28, 48.6MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  78% 2.74G/3.50G [01:21<00:19, 39.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.77G/9.98G [01:21<02:40, 44.9MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.77G/9.98G [01:22<03:30, 34.3MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  79% 2.77G/3.50G [01:22<00:20, 35.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.78G/9.98G [01:22<04:38, 25.9MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.79G/9.98G [01:23<03:38, 32.9MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.80G/9.98G [01:23<03:17, 36.3MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.80G/9.98G [01:23<03:44, 32.0MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.82G/9.98G [01:23<04:00, 29.7MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.83G/9.98G [01:23<02:51, 41.7MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  81% 2.82G/3.50G [01:23<00:17, 38.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.85G/9.98G [01:24<02:22, 49.9MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  81% 2.84G/3.50G [01:24<00:23, 28.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  81% 2.85G/3.50G [01:24<00:21, 30.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  82% 2.86G/3.50G [01:24<00:14, 44.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.85G/9.98G [01:25<06:17, 18.9MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  82% 2.88G/3.50G [01:25<00:18, 34.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.87G/9.98G [01:25<04:26, 26.7MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.88G/9.98G [01:26<04:53, 24.2MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  83% 2.91G/3.50G [01:26<00:13, 44.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.89G/9.98G [01:26<03:38, 32.4MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  84% 2.93G/3.50G [01:26<00:19, 29.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.91G/9.98G [01:27<04:11, 28.1MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  84% 2.95G/3.50G [01:27<00:15, 34.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  84% 2.96G/3.50G [01:27<00:13, 39.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  85% 2.96G/3.50G [01:27<00:15, 33.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.94G/9.98G [01:28<03:11, 36.8MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  30% 2.95G/9.98G [01:28<03:50, 30.5MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  85% 2.99G/3.50G [01:28<00:20, 24.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  30% 2.97G/9.98G [01:29<02:51, 40.9MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  30% 2.98G/9.98G [01:29<03:18, 35.3MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  86% 3.02G/3.50G [01:29<00:15, 29.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  30% 3.01G/9.98G [01:30<02:43, 42.7MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  87% 3.05G/3.50G [01:30<00:12, 35.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  87% 3.06G/3.50G [01:30<00:13, 32.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  30% 3.01G/9.98G [01:30<04:32, 25.6MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  88% 3.08G/3.50G [01:31<00:13, 32.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  30% 3.04G/9.98G [01:31<03:16, 35.4MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  88% 3.10G/3.50G [01:31<00:10, 37.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  89% 3.10G/3.50G [01:31<00:11, 34.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.05G/9.98G [01:32<04:02, 28.5MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  89% 3.13G/3.50G [01:32<00:09, 37.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  90% 3.13G/3.50G [01:32<00:08, 43.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  90% 3.14G/3.50G [01:32<00:09, 37.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.06G/9.98G [01:32<05:32, 20.8MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.12G/9.98G [01:34<02:39, 43.0MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  91% 3.17G/3.50G [01:34<00:19, 16.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.13G/9.98G [01:34<03:03, 37.4MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.14G/9.98G [01:34<03:12, 35.5MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.14G/9.98G [01:34<02:47, 40.8MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.15G/9.98G [01:35<03:22, 33.7MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.17G/9.98G [01:35<03:24, 33.4MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.18G/9.98G [01:35<02:46, 40.8MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.18G/9.98G [01:35<02:33, 44.1MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.19G/9.98G [01:36<03:01, 37.5MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.20G/9.98G [01:36<02:34, 43.8MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.20G/9.98G [01:36<03:31, 32.0MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.21G/9.98G [01:36<02:27, 45.8MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.22G/9.98G [01:36<03:06, 36.2MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  93% 3.26G/3.50G [01:37<00:08, 27.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.23G/9.98G [01:37<03:39, 30.8MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.24G/9.98G [01:37<02:44, 40.9MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.25G/9.98G [01:37<03:32, 31.6MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.26G/9.98G [01:37<02:47, 40.2MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  94% 3.30G/3.50G [01:37<00:05, 37.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.27G/9.98G [01:38<03:35, 31.1MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.28G/9.98G [01:38<02:43, 41.0MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.30G/9.98G [01:38<02:17, 48.7MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  95% 3.33G/3.50G [01:38<00:06, 26.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.32G/9.98G [01:39<03:14, 34.2MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  96% 3.34G/3.50G [01:39<00:07, 20.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.33G/9.98G [01:40<03:51, 28.7MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.34G/9.98G [01:40<02:41, 41.1MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.35G/9.98G [01:40<03:15, 33.9MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  96% 3.38G/3.50G [01:40<00:04, 26.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.37G/9.98G [01:40<02:13, 49.4MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  97% 3.40G/3.50G [01:41<00:03, 32.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  97% 3.41G/3.50G [01:41<00:02, 46.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.39G/9.98G [01:41<03:17, 33.3MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  98% 3.42G/3.50G [01:41<00:02, 32.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.39G/9.98G [01:42<04:13, 25.9MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.42G/9.98G [01:42<02:30, 43.5MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.43G/9.98G [01:42<03:05, 35.4MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.43G/9.98G [01:42<02:52, 37.9MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.45G/9.98G [01:43<02:20, 46.4MB/s]\n",
            "\n",
            "pytorch_model-00002-of-00002.bin: 100% 3.50G/3.50G [01:43<00:00, 33.7MB/s]\n",
            "pytorch_model-00001-of-00002.bin: 100% 9.98G/9.98G [05:01<00:00, 33.1MB/s]\n",
            "\n",
            "Upload 2 LFS files: 100% 2/2 [05:02<00:00, 151.20s/it]\n",
            "Lenght of test: 120\n",
            "Getting completions...\n",
            "Evaluating test set performance...\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5299603822330634\n",
            "llama2-7b - (fasttext) Standard deviation:  0.09946704967191551\n",
            "Validation results: {\n",
            "    \"model\": \"llama2-7b\",\n",
            "    \"acc\": 0.0,\n",
            "    \"mean_em\": 0.5299603822330634,\n",
            "    \"std_em\": 0.09946704967191551,\n",
            "    \"temperature\": 0.0,\n",
            "    \"eval_split\": \"test\",\n",
            "    \"dataset_name\": \"metaphor_list\",\n",
            "    \"fine_tuning\": true\n",
            "}\n",
            "\n",
            "Lenght of test: 244\n",
            "Getting completions...\n",
            "Evaluating test set performance...\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5209082035866918\n",
            "llama2-7b - (fasttext) Standard deviation:  0.10671024184614016\n",
            "Test results: {\n",
            "    \"model\": \"llama2-7b\",\n",
            "    \"acc\": 0.0,\n",
            "    \"mean_em\": 0.5209082035866918,\n",
            "    \"std_em\": 0.10671024184614016,\n",
            "    \"temperature\": 0.0,\n",
            "    \"eval_split\": \"test\",\n",
            "    \"dataset_name\": \"metaphor_list\",\n",
            "    \"fine_tuning\": true\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"$WORKDIR\" python -m src.main --llm llama2-7b --temperature 0 --dataset metaphor_list --task source_domain_prediction --fine_tuned_model_path \"llama2-7b-metaphor-list-source-domain-prediction\" --seed 1 --fine_tuning --evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QycyJPMm2UG"
      },
      "source": [
        "## Metaphor List - Target domain prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pde8kPC2oDik",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2034f866-9218-469b-efbe-433181ae5561"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-29 17:36:51.667053: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-29 17:36:51.667105: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-29 17:36:51.667143: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-29 17:36:53.689320: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "User is already logged in.\n",
            "\n",
            "llm: llama2-7b\n",
            "fine_tuned_model_path: None\n",
            "dataset: metaphor_list\n",
            "task: target_domain_prediction\n",
            "temperature: 0.0\n",
            "seed: 1\n",
            "evaluate: False\n",
            "fine_tuning: True\n",
            "\n",
            "\n",
            "Loading checkpoint shards: 100% 2/2 [01:17<00:00, 38.68s/it]\n",
            "Lenght of train: 132\n",
            "Lenght of valid: 120\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:159: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
            "  warnings.warn(\n",
            "100% 1/1 [00:00<00:00,  4.49ba/s]\n",
            "100% 1/1 [00:00<00:00, 57.86ba/s]\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:127: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n",
            "For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "Cloning https://huggingface.co/lfmatosmelo/llama2-7b-metaphor-list-target-domain-prediction into local empty directory.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 1.884, 'learning_rate': 2.9289321881345254e-05, 'epoch': 0.76}\n",
            "{'train_runtime': 39.0347, 'train_samples_per_second': 3.382, 'train_steps_per_second': 0.845, 'train_loss': 1.6570263053431655, 'epoch': 1.0}\n",
            "Saving fine-tuned model to llama2-7b-metaphor-list-target-domain-prediction\n",
            "Uploading fine-tuned model (llama2-7b-metaphor-list-target-domain-prediction) to HuggingFace Hub\n",
            "Upload file adapter_model.bin:   0% 1.00/128M [00:00<?, ?B/s]\n",
            "Upload file adapter_model.bin: 137MB [00:06, 25.9MB/s]               To https://huggingface.co/lfmatosmelo/llama2-7b-metaphor-list-target-domain-prediction\n",
            "   0f666c5..2ff0101  main -> main\n",
            "\n",
            "Upload file adapter_model.bin: 100% 128M/128M [00:07<00:00, 19.1MB/s]\n",
            "\n",
            "Upload file training_args.bin: 100% 4.37k/4.37k [00:07<00:00, 2.28MB/s]\u001b[A\n",
            "Upload file training_args.bin: 100% 4.37k/4.37k [00:07<00:00, 637B/s]  \n",
            "To https://huggingface.co/lfmatosmelo/llama2-7b-metaphor-list-target-domain-prediction\n",
            "   2ff0101..2e32a2f  main -> main\n",
            "\n",
            "Fine-tuned model saved to 'llama2-7b-metaphor-list-target-domain-prediction'\n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"$WORKDIR\" python -m src.main --llm llama2-7b --temperature 0 --dataset metaphor_list --task target_domain_prediction --seed 1 --fine_tuning --push-model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSdQrnl255O3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff1ebb2e-67cc-43fb-b82c-38619794e294"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-29 17:39:45.346212: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-29 17:39:45.346262: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-29 17:39:45.346302: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-29 17:39:47.298247: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "User is already logged in.\n",
            "\n",
            "llm: llama2-7b\n",
            "fine_tuned_model_path: llama2-7b-metaphor-list-target-domain-prediction\n",
            "dataset: metaphor_list\n",
            "task: target_domain_prediction\n",
            "temperature: 0.0\n",
            "seed: 1\n",
            "evaluate: True\n",
            "fine_tuning: True\n",
            "\n",
            "\n",
            "Fine-tuned model path received, model will be loaded for evaluation\n",
            "No. of unreachable objects: 0\n",
            "Loading checkpoint shards: 100% 2/2 [01:17<00:00, 38.62s/it]\n",
            "Lenght of test: 120\n",
            "Getting completions...\n",
            "Evaluating test set performance...\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' search\n",
            "Source domain: space\n",
            "Answer: find ', but wanted ' missing  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' sound\n",
            "Source domain: physical\n",
            "Answer: ring ', but wanted ' bells  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' time\n",
            "Source domain: space\n",
            "Answer: distance ', but wanted ' time  '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5682542259494464\n",
            "llama2-7b - (fasttext) Standard deviation:  0.15712485405366008\n",
            "Validation results: {\n",
            "    \"model\": \"llama2-7b\",\n",
            "    \"acc\": 0.0,\n",
            "    \"mean_em\": 0.5682542259494464,\n",
            "    \"std_em\": 0.15712485405366008,\n",
            "    \"temperature\": 0.0,\n",
            "    \"eval_split\": \"test\",\n",
            "    \"dataset_name\": \"metaphor_list\",\n",
            "    \"fine_tuning\": true\n",
            "}\n",
            "\n",
            "Lenght of test: 244\n",
            "Getting completions...\n",
            "Evaluating test set performance...\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' upwards\n",
            "Source domain: height\n",
            "Answer: ', but wanted ' scanning  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' action\n",
            "Source domain: space\n",
            "Answer: location ', but wanted ' arriving  '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' distance\n",
            "Source domain: population\n",
            "Answer: route ', but wanted ' paths   '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.5788094386702678\n",
            "llama2-7b - (fasttext) Standard deviation:  0.1450769257699007\n",
            "Test results: {\n",
            "    \"model\": \"llama2-7b\",\n",
            "    \"acc\": 0.0,\n",
            "    \"mean_em\": 0.5788094386702678,\n",
            "    \"std_em\": 0.1450769257699007,\n",
            "    \"temperature\": 0.0,\n",
            "    \"eval_split\": \"test\",\n",
            "    \"dataset_name\": \"metaphor_list\",\n",
            "    \"fine_tuning\": true\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"$WORKDIR\" python -m src.main --llm llama2-7b --temperature 0 --dataset metaphor_list --task target_domain_prediction --fine_tuned_model_path \"llama2-7b-metaphor-list-target-domain-prediction\" --seed 1 --fine_tuning --evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t32mchmWm2g8"
      },
      "source": [
        "## LCC (EN) - Source domain prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_45sMFroEeB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4d96082-fbc3-494f-dc23-3ddf9b35243e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-29 17:51:23.310015: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-29 17:51:23.310062: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-29 17:51:23.310098: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-29 17:51:25.292355: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "User is already logged in.\n",
            "\n",
            "llm: llama2-7b\n",
            "fine_tuned_model_path: None\n",
            "dataset: lcc_en_subset\n",
            "task: source_domain_prediction\n",
            "temperature: 0.0\n",
            "seed: 1\n",
            "evaluate: False\n",
            "fine_tuning: True\n",
            "\n",
            "\n",
            "Loading checkpoint shards: 100% 2/2 [01:15<00:00, 37.68s/it]\n",
            "Lenght of train: 1206\n",
            "Lenght of valid: 172\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:159: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
            "  warnings.warn(\n",
            "100% 2/2 [00:00<00:00,  6.57ba/s]\n",
            "100% 1/1 [00:00<00:00, 27.69ba/s]\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:127: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n",
            "For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "Cloning https://huggingface.co/lfmatosmelo/llama2-7b-lcc-en-subset-source-domain-prediction into local empty directory.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 2.3244, 'learning_rate': 0.0001987005972629389, 'epoch': 0.08}\n",
            "{'loss': 1.1197, 'learning_rate': 0.0001908817637339503, 'epoch': 0.17}\n",
            "{'loss': 1.4783, 'learning_rate': 0.00017652754877106274, 'epoch': 0.25}\n",
            "{'loss': 0.9567, 'learning_rate': 0.00015667017562911176, 'epoch': 0.33}\n",
            "{'loss': 1.421, 'learning_rate': 0.00013273760413662594, 'epoch': 0.41}\n",
            "{'loss': 0.9391, 'learning_rate': 0.00010645084494493165, 'epoch': 0.5}\n",
            "{'loss': 1.431, 'learning_rate': 7.970020025460765e-05, 'epoch': 0.58}\n",
            "{'loss': 0.9396, 'learning_rate': 5.440933064915414e-05, 'epoch': 0.66}\n",
            "{'loss': 1.4519, 'learning_rate': 3.2396923100255515e-05, 'epoch': 0.75}\n",
            "{'loss': 0.9239, 'learning_rate': 1.5245907710716911e-05, 'epoch': 0.83}\n",
            "{'loss': 1.4233, 'learning_rate': 4.189627925296202e-06, 'epoch': 0.91}\n",
            "{'loss': 0.9067, 'learning_rate': 2.3149802010913323e-08, 'epoch': 0.99}\n",
            "{'train_runtime': 457.7898, 'train_samples_per_second': 2.634, 'train_steps_per_second': 0.66, 'train_loss': 1.2739786359648042, 'epoch': 1.0}\n",
            "Saving fine-tuned model to llama2-7b-lcc-en-subset-source-domain-prediction\n",
            "Uploading fine-tuned model (llama2-7b-lcc-en-subset-source-domain-prediction) to HuggingFace Hub\n",
            "Upload file adapter_model.bin:   0% 1.00/128M [00:00<?, ?B/s]\n",
            "Upload file adapter_model.bin: 137MB [00:06, 27.1MB/s]               To https://huggingface.co/lfmatosmelo/llama2-7b-lcc-en-subset-source-domain-prediction\n",
            "   37c0a0f..03f5606  main -> main\n",
            "\n",
            "Upload file adapter_model.bin: 100% 128M/128M [00:08<00:00, 16.8MB/s]\n",
            "\n",
            "Upload file training_args.bin: 100% 4.37k/4.37k [00:08<00:00, 2.00MB/s]\u001b[A\n",
            "Upload file training_args.bin: 100% 4.37k/4.37k [00:08<00:00, 558B/s]  \n",
            "To https://huggingface.co/lfmatosmelo/llama2-7b-lcc-en-subset-source-domain-prediction\n",
            "   03f5606..db89879  main -> main\n",
            "\n",
            "Fine-tuned model saved to 'llama2-7b-lcc-en-subset-source-domain-prediction'\n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"$WORKDIR\" python -m src.main --llm llama2-7b --temperature 0 --dataset lcc_en_subset --task source_domain_prediction --seed 1 --fine_tuning --push-model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bi6qe-4X55O4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f592d20-0da3-4ce2-f43d-f56b47d442fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-29 18:01:15.868781: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-29 18:01:15.868835: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-29 18:01:15.868883: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-29 18:01:17.920278: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "User is already logged in.\n",
            "\n",
            "llm: llama2-7b\n",
            "fine_tuned_model_path: llama2-7b-lcc-en-subset-source-domain-prediction\n",
            "dataset: lcc_en_subset\n",
            "task: source_domain_prediction\n",
            "temperature: 0.0\n",
            "seed: 1\n",
            "evaluate: True\n",
            "fine_tuning: True\n",
            "\n",
            "\n",
            "Fine-tuned model path received, model will be loaded for evaluation\n",
            "No. of unreachable objects: 0\n",
            "Loading checkpoint shards: 100% 2/2 [01:17<00:00, 38.77s/it]\n",
            "Lenght of test: 172\n",
            "Getting completions...\n",
            "Evaluating test set performance...\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.7145997961593229\n",
            "llama2-7b - (fasttext) Standard deviation:  0.15960637379871387\n",
            "Validation results: {\n",
            "    \"model\": \"llama2-7b\",\n",
            "    \"acc\": 0.0,\n",
            "    \"mean_em\": 0.7145997961593229,\n",
            "    \"std_em\": 0.15960637379871387,\n",
            "    \"temperature\": 0.0,\n",
            "    \"eval_split\": \"test\",\n",
            "    \"dataset_name\": \"lcc_en_subset\",\n",
            "    \"fine_tuning\": true\n",
            "}\n",
            "\n",
            "Lenght of test: 345\n",
            "Getting completions...\n",
            "Evaluating test set performance...\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.7046418272066808\n",
            "llama2-7b - (fasttext) Standard deviation:  0.1657103878440335\n",
            "Test results: {\n",
            "    \"model\": \"llama2-7b\",\n",
            "    \"acc\": 0.0,\n",
            "    \"mean_em\": 0.7046418272066808,\n",
            "    \"std_em\": 0.1657103878440335,\n",
            "    \"temperature\": 0.0,\n",
            "    \"eval_split\": \"test\",\n",
            "    \"dataset_name\": \"lcc_en_subset\",\n",
            "    \"fine_tuning\": true\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"$WORKDIR\" python -m src.main --llm llama2-7b --temperature 0 --dataset lcc_en_subset --task source_domain_prediction --fine_tuned_model_path \"llama2-7b-lcc-en-subset-source-domain-prediction\" --seed 1 --fine_tuning --evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeHKeUWIm2lT"
      },
      "source": [
        "## LCC (EN) - Target domain prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSudvlU2oFSH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51f37e71-4b10-4c34-e3b3-7184804e37e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-29 18:12:41.834468: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-29 18:12:41.834518: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-29 18:12:41.834559: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-29 18:12:43.819866: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "User is already logged in.\n",
            "\n",
            "llm: llama2-7b\n",
            "fine_tuned_model_path: None\n",
            "dataset: lcc_en_subset\n",
            "task: target_domain_prediction\n",
            "temperature: 0.0\n",
            "seed: 1\n",
            "evaluate: False\n",
            "fine_tuning: True\n",
            "\n",
            "\n",
            "Loading checkpoint shards: 100% 2/2 [01:16<00:00, 38.44s/it]\n",
            "Lenght of train: 1206\n",
            "Lenght of valid: 172\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:159: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
            "  warnings.warn(\n",
            "100% 2/2 [00:00<00:00,  6.57ba/s]\n",
            "100% 1/1 [00:00<00:00, 28.67ba/s]\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:127: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n",
            "For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "Cloning https://huggingface.co/lfmatosmelo/llama2-7b-lcc-en-subset-target-domain-prediction into local empty directory.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 2.3853, 'learning_rate': 0.0001987005972629389, 'epoch': 0.08}\n",
            "{'loss': 1.1298, 'learning_rate': 0.0001908817637339503, 'epoch': 0.17}\n",
            "{'loss': 1.4802, 'learning_rate': 0.00017652754877106274, 'epoch': 0.25}\n",
            "{'loss': 0.9575, 'learning_rate': 0.00015667017562911176, 'epoch': 0.33}\n",
            "{'loss': 1.428, 'learning_rate': 0.00013273760413662594, 'epoch': 0.41}\n",
            "{'loss': 0.9416, 'learning_rate': 0.00010645084494493165, 'epoch': 0.5}\n",
            "{'loss': 1.4338, 'learning_rate': 7.970020025460765e-05, 'epoch': 0.58}\n",
            "{'loss': 0.9397, 'learning_rate': 5.440933064915414e-05, 'epoch': 0.66}\n",
            "{'loss': 1.4512, 'learning_rate': 3.2396923100255515e-05, 'epoch': 0.75}\n",
            "{'loss': 0.9229, 'learning_rate': 1.5245907710716911e-05, 'epoch': 0.83}\n",
            "{'loss': 1.425, 'learning_rate': 4.189627925296202e-06, 'epoch': 0.91}\n",
            "{'loss': 0.9071, 'learning_rate': 2.3149802010913323e-08, 'epoch': 0.99}\n",
            "{'train_runtime': 459.5856, 'train_samples_per_second': 2.624, 'train_steps_per_second': 0.657, 'train_loss': 1.2811747197283814, 'epoch': 1.0}\n",
            "Saving fine-tuned model to llama2-7b-lcc-en-subset-target-domain-prediction\n",
            "Uploading fine-tuned model (llama2-7b-lcc-en-subset-target-domain-prediction) to HuggingFace Hub\n",
            "Upload file adapter_model.bin:   0% 1.00/128M [00:00<?, ?B/s]\n",
            "Upload file adapter_model.bin:  95% 122M/128M [00:07<00:00, 19.6MB/s]To https://huggingface.co/lfmatosmelo/llama2-7b-lcc-en-subset-target-domain-prediction\n",
            "   77d1dcd..346380f  main -> main\n",
            "\n",
            "Upload file adapter_model.bin: 100% 128M/128M [00:09<00:00, 14.9MB/s]\n",
            "\n",
            "Upload file training_args.bin: 100% 4.37k/4.37k [00:09<00:00, 1.78MB/s]\u001b[A\n",
            "Upload file training_args.bin: 100% 4.37k/4.37k [00:09<00:00, 496B/s]  \n",
            "To https://huggingface.co/lfmatosmelo/llama2-7b-lcc-en-subset-target-domain-prediction\n",
            "   346380f..d326e4f  main -> main\n",
            "\n",
            "Fine-tuned model saved to 'llama2-7b-lcc-en-subset-target-domain-prediction'\n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"$WORKDIR\" python -m src.main --llm llama2-7b --temperature 0 --dataset lcc_en_subset --task target_domain_prediction --seed 1 --fine_tuning --push-model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0-VVNUP55O5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb1585d6-90b0-4631-def7-5632ef3670cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-29 18:22:36.674484: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-29 18:22:36.674541: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-29 18:22:36.674582: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-29 18:22:38.741106: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "User is already logged in.\n",
            "\n",
            "llm: llama2-7b\n",
            "fine_tuned_model_path: llama2-7b-lcc-en-subset-target-domain-prediction\n",
            "dataset: lcc_en_subset\n",
            "task: target_domain_prediction\n",
            "temperature: 0.0\n",
            "seed: 1\n",
            "evaluate: True\n",
            "fine_tuning: True\n",
            "\n",
            "\n",
            "Fine-tuned model path received, model will be loaded for evaluation\n",
            "No. of unreachable objects: 0\n",
            "Loading checkpoint shards: 100% 2/2 [01:15<00:00, 37.82s/it]\n",
            "Lenght of test: 172\n",
            "Getting completions...\n",
            "Evaluating test set performance...\n",
            "llama2-7b Accuracy:  0.03488372093023256\n",
            "llama2-7b - (fasttext) Mean similarity:  0.7132543812310973\n",
            "llama2-7b - (fasttext) Standard deviation:  0.11734644444654899\n",
            "Validation results: {\n",
            "    \"model\": \"llama2-7b\",\n",
            "    \"acc\": 0.03488372093023256,\n",
            "    \"mean_em\": 0.7132543812310973,\n",
            "    \"std_em\": 0.11734644444654899,\n",
            "    \"temperature\": 0.0,\n",
            "    \"eval_split\": \"test\",\n",
            "    \"dataset_name\": \"lcc_en_subset\",\n",
            "    \"fine_tuning\": true\n",
            "}\n",
            "\n",
            "Lenght of test: 345\n",
            "Getting completions...\n",
            "Evaluating test set performance...\n",
            "llama2-7b Accuracy:  0.02608695652173913\n",
            "llama2-7b - (fasttext) Mean similarity:  0.7105934036241007\n",
            "llama2-7b - (fasttext) Standard deviation:  0.12853789456633138\n",
            "Test results: {\n",
            "    \"model\": \"llama2-7b\",\n",
            "    \"acc\": 0.02608695652173913,\n",
            "    \"mean_em\": 0.7105934036241007,\n",
            "    \"std_em\": 0.12853789456633138,\n",
            "    \"temperature\": 0.0,\n",
            "    \"eval_split\": \"test\",\n",
            "    \"dataset_name\": \"lcc_en_subset\",\n",
            "    \"fine_tuning\": true\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"$WORKDIR\" python -m src.main --llm llama2-7b --temperature 0 --dataset lcc_en_subset --task target_domain_prediction --fine_tuned_model_path \"llama2-7b-lcc-en-subset-target-domain-prediction\" --seed 1 --fine_tuning --evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rB7-BcMLm3MH"
      },
      "source": [
        "## LCC (EN) - Source lexeme prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dk8gZe3hoHE3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dac006e0-0513-4f9e-b1fb-f12498a737b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-29 18:34:08.301752: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-29 18:34:08.301805: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-29 18:34:08.301844: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-29 18:34:10.420102: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "User is already logged in.\n",
            "\n",
            "llm: llama2-7b\n",
            "fine_tuned_model_path: None\n",
            "dataset: lcc_en_subset\n",
            "task: source_lexeme_prediction\n",
            "temperature: 0.0\n",
            "seed: 1\n",
            "evaluate: False\n",
            "fine_tuning: True\n",
            "\n",
            "\n",
            "Loading checkpoint shards: 100% 2/2 [01:16<00:00, 38.19s/it]\n",
            "Lenght of train: 1206\n",
            "Lenght of valid: 172\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:159: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
            "  warnings.warn(\n",
            "100% 2/2 [00:00<00:00,  4.11ba/s]\n",
            "100% 1/1 [00:00<00:00, 14.34ba/s]\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:127: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n",
            "For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "Cloning https://huggingface.co/lfmatosmelo/llama2-7b-lcc-en-subset-source-lexeme-prediction into local empty directory.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 2.2247, 'learning_rate': 0.0001987005972629389, 'epoch': 0.08}\n",
            "{'loss': 1.0478, 'learning_rate': 0.0001908817637339503, 'epoch': 0.17}\n",
            "{'loss': 1.4019, 'learning_rate': 0.00017652754877106274, 'epoch': 0.25}\n",
            "{'loss': 0.9039, 'learning_rate': 0.00015667017562911176, 'epoch': 0.33}\n",
            "{'loss': 1.3867, 'learning_rate': 0.00013273760413662594, 'epoch': 0.41}\n",
            "{'loss': 0.8966, 'learning_rate': 0.00010645084494493165, 'epoch': 0.5}\n",
            "{'loss': 1.3819, 'learning_rate': 7.970020025460765e-05, 'epoch': 0.58}\n",
            "{'loss': 0.8969, 'learning_rate': 5.440933064915414e-05, 'epoch': 0.66}\n",
            "{'loss': 1.4081, 'learning_rate': 3.2396923100255515e-05, 'epoch': 0.75}\n",
            "{'loss': 0.8911, 'learning_rate': 1.5245907710716911e-05, 'epoch': 0.83}\n",
            "{'loss': 1.3803, 'learning_rate': 4.189627925296202e-06, 'epoch': 0.91}\n",
            "{'loss': 0.878, 'learning_rate': 2.3149802010913323e-08, 'epoch': 0.99}\n",
            "{'train_runtime': 467.6187, 'train_samples_per_second': 2.579, 'train_steps_per_second': 0.646, 'train_loss': 1.2226070370895183, 'epoch': 1.0}\n",
            "Saving fine-tuned model to llama2-7b-lcc-en-subset-source-lexeme-prediction\n",
            "Uploading fine-tuned model (llama2-7b-lcc-en-subset-source-lexeme-prediction) to HuggingFace Hub\n",
            "Upload file adapter_model.bin:   0% 1.00/128M [00:00<?, ?B/s]\n",
            "Upload file training_args.bin:   0% 1.00/4.37k [00:00<?, ?B/s]\u001b[A\n",
            "Upload file adapter_model.bin: 137MB [00:07, 21.4MB/s]               To https://huggingface.co/lfmatosmelo/llama2-7b-lcc-en-subset-source-lexeme-prediction\n",
            "   b47a892..f97716c  main -> main\n",
            "\n",
            "Upload file adapter_model.bin: 100% 128M/128M [00:08<00:00, 16.8MB/s]\n",
            "\n",
            "Upload file training_args.bin: 100% 4.37k/4.37k [00:08<00:00, 558B/s]  \n",
            "To https://huggingface.co/lfmatosmelo/llama2-7b-lcc-en-subset-source-lexeme-prediction\n",
            "   f97716c..c1e5164  main -> main\n",
            "\n",
            "Fine-tuned model saved to 'llama2-7b-lcc-en-subset-source-lexeme-prediction'\n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"$WORKDIR\" python -m src.main --llm llama2-7b --temperature 0 --dataset lcc_en_subset --task source_lexeme_prediction --seed 1 --fine_tuning --push-model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YERlsILr55O6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25c8e5b6-3760-4add-9dee-4412bfc88309"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-29 18:44:08.837241: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-29 18:44:08.837300: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-29 18:44:08.837336: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-29 18:44:11.174799: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "User is already logged in.\n",
            "\n",
            "llm: llama2-7b\n",
            "fine_tuned_model_path: llama2-7b-lcc-en-subset-source-lexeme-prediction\n",
            "dataset: lcc_en_subset\n",
            "task: source_lexeme_prediction\n",
            "temperature: 0.0\n",
            "seed: 1\n",
            "evaluate: True\n",
            "fine_tuning: True\n",
            "\n",
            "\n",
            "Fine-tuned model path received, model will be loaded for evaluation\n",
            "No. of unreachable objects: 0\n",
            "Loading checkpoint shards: 100% 2/2 [01:17<00:00, 38.92s/it]\n",
            "Lenght of test: 172\n",
            "Getting completions...\n",
            "Evaluating test set performance...\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' remedy\n",
            "Sentence: The NRA ', but wanted ' remedy' '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' flows through\n",
            "Sentence: The taxation ', but wanted ' flows '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.6751266315925953\n",
            "llama2-7b - (fasttext) Standard deviation:  0.1399728369931895\n",
            "Validation results: {\n",
            "    \"model\": \"llama2-7b\",\n",
            "    \"acc\": 0.0,\n",
            "    \"mean_em\": 0.6751266315925953,\n",
            "    \"std_em\": 0.1399728369931895,\n",
            "    \"temperature\": 0.0,\n",
            "    \"eval_split\": \"test\",\n",
            "    \"dataset_name\": \"lcc_en_subset\",\n",
            "    \"fine_tuning\": true\n",
            "}\n",
            "\n",
            "Lenght of test: 345\n",
            "Getting completions...\n",
            "Evaluating test set performance...\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' passionist\n",
            "Sentence: The NRA ', but wanted ' passionist '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' brayers\n",
            "Sentence: The gun ', but wanted ' brayers '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.6855551026005676\n",
            "llama2-7b - (fasttext) Standard deviation:  0.12627130140255996\n",
            "Test results: {\n",
            "    \"model\": \"llama2-7b\",\n",
            "    \"acc\": 0.0,\n",
            "    \"mean_em\": 0.6855551026005676,\n",
            "    \"std_em\": 0.12627130140255996,\n",
            "    \"temperature\": 0.0,\n",
            "    \"eval_split\": \"test\",\n",
            "    \"dataset_name\": \"lcc_en_subset\",\n",
            "    \"fine_tuning\": true\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"$WORKDIR\" python -m src.main --llm llama2-7b --temperature 0 --dataset lcc_en_subset --task source_lexeme_prediction --fine_tuned_model_path \"llama2-7b-lcc-en-subset-source-lexeme-prediction\" --seed 1 --fine_tuning --evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MiCu0tSlySN"
      },
      "source": [
        "## LCC (EN) - Target lexeme prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tl0nkf54oH5h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d107c5a-bf2a-440a-fd27-dc02cb188507"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-29 18:55:31.903780: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-29 18:55:31.903835: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-29 18:55:31.903886: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-29 18:55:34.108981: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "User is already logged in.\n",
            "\n",
            "llm: llama2-7b\n",
            "fine_tuned_model_path: None\n",
            "dataset: lcc_en_subset\n",
            "task: target_lexeme_prediction\n",
            "temperature: 0.0\n",
            "seed: 1\n",
            "evaluate: False\n",
            "fine_tuning: True\n",
            "\n",
            "\n",
            "Loading checkpoint shards: 100% 2/2 [01:17<00:00, 38.64s/it]\n",
            "Lenght of train: 1206\n",
            "Lenght of valid: 172\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:159: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
            "  warnings.warn(\n",
            "100% 2/2 [00:00<00:00,  6.25ba/s]\n",
            "100% 1/1 [00:00<00:00, 27.14ba/s]\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:127: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n",
            "For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "Cloning https://huggingface.co/lfmatosmelo/llama2-7b-lcc-en-subset-target-lexeme-prediction into local empty directory.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 2.2763, 'learning_rate': 0.0001987005972629389, 'epoch': 0.08}\n",
            "{'loss': 1.0519, 'learning_rate': 0.0001908817637339503, 'epoch': 0.17}\n",
            "{'loss': 1.4065, 'learning_rate': 0.00017652754877106274, 'epoch': 0.25}\n",
            "{'loss': 0.9069, 'learning_rate': 0.00015667017562911176, 'epoch': 0.33}\n",
            "{'loss': 1.3905, 'learning_rate': 0.00013273760413662594, 'epoch': 0.41}\n",
            "{'loss': 0.9049, 'learning_rate': 0.00010645084494493165, 'epoch': 0.5}\n",
            "{'loss': 1.3846, 'learning_rate': 7.970020025460765e-05, 'epoch': 0.58}\n",
            "{'loss': 0.8982, 'learning_rate': 5.440933064915414e-05, 'epoch': 0.66}\n",
            "{'loss': 1.4101, 'learning_rate': 3.2396923100255515e-05, 'epoch': 0.75}\n",
            "{'loss': 0.8904, 'learning_rate': 1.5245907710716911e-05, 'epoch': 0.83}\n",
            "{'loss': 1.3842, 'learning_rate': 4.189627925296202e-06, 'epoch': 0.91}\n",
            "{'loss': 0.8795, 'learning_rate': 2.3149802010913323e-08, 'epoch': 0.99}\n",
            "{'train_runtime': 469.1249, 'train_samples_per_second': 2.571, 'train_steps_per_second': 0.644, 'train_loss': 1.2297206931556297, 'epoch': 1.0}\n",
            "Saving fine-tuned model to llama2-7b-lcc-en-subset-target-lexeme-prediction\n",
            "Uploading fine-tuned model (llama2-7b-lcc-en-subset-target-lexeme-prediction) to HuggingFace Hub\n",
            "Upload file adapter_model.bin:   0% 1.00/128M [00:00<?, ?B/s]\n",
            "Upload file adapter_model.bin:  95% 122M/128M [00:04<00:00, 32.0MB/s] To https://huggingface.co/lfmatosmelo/llama2-7b-lcc-en-subset-target-lexeme-prediction\n",
            "   d73ecfc..9bb0cda  main -> main\n",
            "\n",
            "Upload file adapter_model.bin: 100% 128M/128M [00:06<00:00, 22.4MB/s]\n",
            "\n",
            "Upload file training_args.bin: 100% 4.37k/4.37k [00:06<00:00, 2.66MB/s]\u001b[A\n",
            "Upload file training_args.bin: 100% 4.37k/4.37k [00:06<00:00, 744B/s]  \n",
            "To https://huggingface.co/lfmatosmelo/llama2-7b-lcc-en-subset-target-lexeme-prediction\n",
            "   9bb0cda..549abfb  main -> main\n",
            "\n",
            "Fine-tuned model saved to 'llama2-7b-lcc-en-subset-target-lexeme-prediction'\n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"$WORKDIR\" python -m src.main --llm llama2-7b --temperature 0 --dataset lcc_en_subset --task target_lexeme_prediction --seed 1 --fine_tuning --push-model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNeSgCTB55O6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "025a0e14-f48f-4825-db78-56171bfb543e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-29 19:05:33.999522: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-29 19:05:33.999572: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-29 19:05:33.999615: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-29 19:05:35.988786: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "User is already logged in.\n",
            "\n",
            "llm: llama2-7b\n",
            "fine_tuned_model_path: llama2-7b-lcc-en-subset-target-lexeme-prediction\n",
            "dataset: lcc_en_subset\n",
            "task: target_lexeme_prediction\n",
            "temperature: 0.0\n",
            "seed: 1\n",
            "evaluate: True\n",
            "fine_tuning: True\n",
            "\n",
            "\n",
            "Fine-tuned model path received, model will be loaded for evaluation\n",
            "No. of unreachable objects: 0\n",
            "Loading checkpoint shards: 100% 2/2 [01:17<00:00, 38.74s/it]\n",
            "Lenght of test: 172\n",
            "Getting completions...\n",
            "Evaluating test set performance...\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Democracys ball.\n",
            "Source lexeme ', but wanted ' Democracys '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Taxes\n",
            "Noun: afflicted ', but wanted ' \"taxes\" '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' 2A.\n",
            "Source lexeme: milit ', but wanted ' 2A. '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government's\n",
            "Source lexeme: government' ', but wanted ' government's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' democracy\n",
            "Source lexeme: freedom\n",
            "Answer ', but wanted ' \"democracy\" '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Government? ', but wanted ' Government '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.6852196480992229\n",
            "llama2-7b - (fasttext) Standard deviation:  0.18757423184147134\n",
            "Validation results: {\n",
            "    \"model\": \"llama2-7b\",\n",
            "    \"acc\": 0.0,\n",
            "    \"mean_em\": 0.6852196480992229,\n",
            "    \"std_em\": 0.18757423184147134,\n",
            "    \"temperature\": 0.0,\n",
            "    \"eval_split\": \"test\",\n",
            "    \"dataset_name\": \"lcc_en_subset\",\n",
            "    \"fine_tuning\": true\n",
            "}\n",
            "\n",
            "Lenght of test: 345\n",
            "Getting completions...\n",
            "Evaluating test set performance...\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' 2A.\n",
            "Source lexeme: g ', but wanted ' 2A. '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Democracys author is therefore the first re ', but wanted ' Democracys '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' health care bill\n",
            "Source lexeme: narrowly ', but wanted ' Senate's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' bureaucracy. ', but wanted ' bureaucracy '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' Government's\n",
            "Source lexeme: Government' ', but wanted ' Government's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' NRAs\n",
            "Source lexeme: N ', but wanted ' NRAs '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government's overall power structure.\n",
            "Source lex ', but wanted ' government's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' campaigns\n",
            "Source lexeme: hemmed in ', but wanted ' candidates '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' government's blueprint for economic reform. ', but wanted ' government's '\n",
            "(fasttext) - Error in computing cosine similarity for example: predicted ' NRA's ace in the hole. ', but wanted ' NRA's '\n",
            "llama2-7b Accuracy:  0.0\n",
            "llama2-7b - (fasttext) Mean similarity:  0.6640386850073717\n",
            "llama2-7b - (fasttext) Standard deviation:  0.18073546407871044\n",
            "Test results: {\n",
            "    \"model\": \"llama2-7b\",\n",
            "    \"acc\": 0.0,\n",
            "    \"mean_em\": 0.6640386850073717,\n",
            "    \"std_em\": 0.18073546407871044,\n",
            "    \"temperature\": 0.0,\n",
            "    \"eval_split\": \"test\",\n",
            "    \"dataset_name\": \"lcc_en_subset\",\n",
            "    \"fine_tuning\": true\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"$WORKDIR\" python -m src.main --llm llama2-7b --temperature 0 --dataset lcc_en_subset --task target_lexeme_prediction --fine_tuned_model_path \"llama2-7b-lcc-en-subset-target-lexeme-prediction\" --seed 1 --fine_tuning --evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJbQnbqclyUo"
      },
      "source": [
        "## TroFi - Metaphor classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mzHyQqovoIom",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46bf64c9-649e-4768-ba2a-ab57c465d66a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-09 22:22:34.719309: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-09 22:22:34.719377: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-09 22:22:34.719424: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-09 22:22:36.108187: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n",
            "\n",
            "llm: llama2-7b\n",
            "fine_tuned_model_path: None\n",
            "dataset: trofi\n",
            "task: classification\n",
            "temperature: 0.0\n",
            "seed: 1\n",
            "evaluate: False\n",
            "fine_tuning: True\n",
            "\n",
            "\n",
            "config.json: 100% 609/609 [00:00<00:00, 3.34MB/s]\n",
            "model.safetensors.index.json: 100% 26.8k/26.8k [00:00<00:00, 22.1MB/s]\n",
            "Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00001-of-00002.safetensors:   0% 0.00/9.98G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 10.5M/9.98G [00:00<01:49, 91.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 31.5M/9.98G [00:00<01:06, 149MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 52.4M/9.98G [00:00<00:56, 174MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 73.4M/9.98G [00:00<00:53, 186MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 94.4M/9.98G [00:00<00:51, 193MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 115M/9.98G [00:00<00:49, 198MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 136M/9.98G [00:00<00:50, 195MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 157M/9.98G [00:00<00:53, 183MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 178M/9.98G [00:00<00:53, 182MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 199M/9.98G [00:01<00:53, 182MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 220M/9.98G [00:01<00:54, 178MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 241M/9.98G [00:01<00:54, 178MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 262M/9.98G [00:01<00:55, 176MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 283M/9.98G [00:03<04:14, 38.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 315M/9.98G [00:03<02:51, 56.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 336M/9.98G [00:03<02:28, 65.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 357M/9.98G [00:03<02:06, 76.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 377M/9.98G [00:03<01:43, 93.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 398M/9.98G [00:03<01:26, 111MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 419M/9.98G [00:03<01:26, 110MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 440M/9.98G [00:04<01:16, 124MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 461M/9.98G [00:04<01:12, 131MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 482M/9.98G [00:04<01:04, 146MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 503M/9.98G [00:04<00:59, 158MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 524M/9.98G [00:04<00:55, 171MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 545M/9.98G [00:04<00:52, 179MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 566M/9.98G [00:04<00:50, 185MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 587M/9.98G [00:04<00:49, 188MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 608M/9.98G [00:04<00:49, 189MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 629M/9.98G [00:04<00:48, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 650M/9.98G [00:05<00:48, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 671M/9.98G [00:05<00:48, 193MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 692M/9.98G [00:05<00:48, 193MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 713M/9.98G [00:05<00:47, 195MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 734M/9.98G [00:05<00:47, 196MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 755M/9.98G [00:05<00:46, 197MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 786M/9.98G [00:05<00:44, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 818M/9.98G [00:05<00:44, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 849M/9.98G [00:06<00:43, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 881M/9.98G [00:06<00:43, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 912M/9.98G [00:06<00:44, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 933M/9.98G [00:06<00:44, 203MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 954M/9.98G [00:06<00:44, 202MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 975M/9.98G [00:06<00:44, 203MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 996M/9.98G [00:06<00:43, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 1.02G/9.98G [00:08<04:07, 36.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.05G/9.98G [00:08<02:54, 51.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.07G/9.98G [00:09<02:31, 58.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.10G/9.98G [00:09<01:52, 79.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.12G/9.98G [00:09<01:34, 94.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.14G/9.98G [00:09<01:20, 110MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 1.16G/9.98G [00:09<01:12, 122MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 1.18G/9.98G [00:09<01:03, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 1.21G/9.98G [00:09<00:58, 150MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 1.23G/9.98G [00:09<00:54, 161MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.25G/9.98G [00:09<00:51, 169MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.27G/9.98G [00:10<00:49, 174MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.29G/9.98G [00:10<00:47, 183MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.32G/9.98G [00:10<00:44, 194MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.34G/9.98G [00:10<00:44, 196MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 1.37G/9.98G [00:10<00:42, 203MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 1.39G/9.98G [00:10<00:42, 202MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 1.42G/9.98G [00:10<00:43, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 1.44G/9.98G [00:10<00:43, 196MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.46G/9.98G [00:10<00:43, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.48G/9.98G [00:11<00:42, 199MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.50G/9.98G [00:11<00:42, 199MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.52G/9.98G [00:13<05:27, 25.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.54G/9.98G [00:13<04:19, 32.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 1.56G/9.98G [00:14<03:15, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 1.58G/9.98G [00:14<02:29, 56.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 1.61G/9.98G [00:14<01:45, 79.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 1.64G/9.98G [00:14<01:27, 95.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.66G/9.98G [00:14<01:14, 112MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.68G/9.98G [00:14<01:06, 125MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.70G/9.98G [00:14<00:59, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.72G/9.98G [00:14<00:55, 150MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.74G/9.98G [00:14<00:52, 157MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.77G/9.98G [00:15<00:47, 174MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.79G/9.98G [00:15<00:46, 178MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.82G/9.98G [00:15<00:43, 188MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.85G/9.98G [00:15<00:46, 174MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 1.87G/9.98G [00:15<00:49, 165MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 1.89G/9.98G [00:15<00:48, 166MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 1.91G/9.98G [00:15<00:48, 166MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 1.93G/9.98G [00:16<00:47, 169MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.95G/9.98G [00:16<00:46, 171MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.97G/9.98G [00:18<05:15, 25.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.99G/9.98G [00:18<03:53, 34.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 2.01G/9.98G [00:18<03:02, 43.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 2.03G/9.98G [00:19<02:29, 53.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 2.06G/9.98G [00:19<01:56, 68.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 2.09G/9.98G [00:19<01:24, 92.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 2.12G/9.98G [00:19<01:08, 115MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 2.14G/9.98G [00:19<01:01, 128MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.16G/9.98G [00:19<00:55, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.18G/9.98G [00:19<00:50, 154MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.20G/9.98G [00:19<00:46, 166MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.23G/9.98G [00:20<00:42, 181MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.25G/9.98G [00:20<00:41, 187MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.28G/9.98G [00:20<00:40, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.30G/9.98G [00:20<01:01, 125MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.32G/9.98G [00:20<00:55, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.35G/9.98G [00:20<00:48, 157MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.37G/9.98G [00:20<00:46, 165MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.39G/9.98G [00:21<00:44, 172MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.41G/9.98G [00:21<00:42, 179MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.43G/9.98G [00:23<04:40, 26.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.45G/9.98G [00:23<03:31, 35.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.47G/9.98G [00:23<02:53, 43.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.50G/9.98G [00:24<02:12, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.52G/9.98G [00:24<01:43, 72.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.54G/9.98G [00:24<01:23, 89.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.57G/9.98G [00:24<01:05, 114MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.59G/9.98G [00:24<00:58, 127MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.61G/9.98G [00:24<00:52, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.63G/9.98G [00:24<00:48, 152MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.65G/9.98G [00:24<00:44, 164MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.68G/9.98G [00:25<00:40, 178MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.72G/9.98G [00:25<00:37, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.75G/9.98G [00:25<00:36, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.78G/9.98G [00:25<00:35, 203MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.81G/9.98G [00:25<00:34, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.84G/9.98G [00:25<00:33, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.87G/9.98G [00:25<00:33, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.90G/9.98G [00:26<00:34, 204MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.93G/9.98G [00:26<00:34, 203MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 2.95G/9.98G [00:26<00:35, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 2.97G/9.98G [00:26<00:35, 199MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 2.99G/9.98G [00:28<03:16, 35.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 3.01G/9.98G [00:28<02:55, 39.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 3.03G/9.98G [00:28<02:22, 48.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.05G/9.98G [00:28<01:55, 60.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.07G/9.98G [00:29<01:32, 74.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.09G/9.98G [00:29<01:15, 91.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.11G/9.98G [00:29<01:02, 110MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.14G/9.98G [00:29<00:55, 124MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.16G/9.98G [00:29<00:49, 137MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.18G/9.98G [00:29<00:46, 146MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.20G/9.98G [00:29<00:44, 154MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.22G/9.98G [00:29<00:41, 161MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.24G/9.98G [00:30<00:39, 172MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.26G/9.98G [00:30<00:40, 165MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.28G/9.98G [00:30<00:38, 176MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.30G/9.98G [00:30<00:36, 183MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.32G/9.98G [00:30<00:35, 189MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.34G/9.98G [00:30<00:35, 189MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.37G/9.98G [00:30<00:35, 187MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.39G/9.98G [00:30<00:36, 180MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.41G/9.98G [00:30<00:36, 180MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.43G/9.98G [00:31<00:37, 174MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.45G/9.98G [00:31<01:23, 77.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.47G/9.98G [00:33<03:05, 35.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.49G/9.98G [00:33<02:20, 46.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.51G/9.98G [00:33<01:50, 58.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.53G/9.98G [00:33<01:29, 72.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.55G/9.98G [00:33<01:12, 88.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.58G/9.98G [00:34<01:55, 55.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.60G/9.98G [00:34<01:29, 71.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.63G/9.98G [00:34<01:06, 96.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.65G/9.98G [00:34<01:14, 85.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.67G/9.98G [00:34<01:04, 98.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.69G/9.98G [00:35<00:56, 111MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.71G/9.98G [00:35<00:49, 127MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.73G/9.98G [00:35<00:44, 142MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.75G/9.98G [00:35<00:40, 152MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.77G/9.98G [00:35<00:38, 162MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.80G/9.98G [00:35<00:35, 173MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.82G/9.98G [00:35<00:34, 179MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.85G/9.98G [00:35<00:32, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.87G/9.98G [00:35<00:31, 196MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.89G/9.98G [00:36<00:30, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.91G/9.98G [00:36<00:30, 197MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.93G/9.98G [00:36<00:31, 193MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 3.95G/9.98G [00:36<00:31, 194MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 3.97G/9.98G [00:36<00:31, 193MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 4.00G/9.98G [00:36<00:30, 194MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 4.02G/9.98G [00:37<01:07, 88.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 4.04G/9.98G [00:38<02:53, 34.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.07G/9.98G [00:38<01:57, 50.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.09G/9.98G [00:38<01:40, 58.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.11G/9.98G [00:39<01:20, 72.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.14G/9.98G [00:39<01:00, 96.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.16G/9.98G [00:39<00:52, 110MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.18G/9.98G [00:39<00:46, 125MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.20G/9.98G [00:39<00:43, 132MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.23G/9.98G [00:41<02:33, 37.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.25G/9.98G [00:41<01:58, 48.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.28G/9.98G [00:41<01:22, 69.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.31G/9.98G [00:41<01:02, 90.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.33G/9.98G [00:41<00:54, 104MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.35G/9.98G [00:41<00:48, 117MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.37G/9.98G [00:41<00:42, 131MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.39G/9.98G [00:42<00:38, 145MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.41G/9.98G [00:42<00:35, 158MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.44G/9.98G [00:43<02:16, 40.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 4.46G/9.98G [00:43<01:44, 52.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 4.48G/9.98G [00:43<01:23, 66.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 4.50G/9.98G [00:44<01:12, 75.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 4.52G/9.98G [00:44<00:59, 91.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.54G/9.98G [00:44<00:49, 109MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.56G/9.98G [00:44<00:42, 127MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.58G/9.98G [00:44<00:39, 136MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.60G/9.98G [00:44<00:39, 135MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.62G/9.98G [00:44<00:37, 143MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.65G/9.98G [00:44<00:35, 152MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.67G/9.98G [00:44<00:33, 157MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.69G/9.98G [00:45<00:31, 167MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.71G/9.98G [00:45<00:29, 177MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.73G/9.98G [00:45<00:28, 184MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.75G/9.98G [00:45<00:27, 189MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.77G/9.98G [00:45<00:28, 181MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.79G/9.98G [00:45<00:29, 175MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.81G/9.98G [00:46<00:46, 110MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.83G/9.98G [00:46<00:41, 125MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.85G/9.98G [00:46<00:37, 136MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.88G/9.98G [00:48<03:17, 25.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.91G/9.98G [00:48<02:08, 39.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.93G/9.98G [00:48<01:42, 49.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 4.95G/9.98G [00:49<01:24, 59.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 4.97G/9.98G [00:49<01:06, 74.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 4.99G/9.98G [00:49<00:54, 91.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 5.02G/9.98G [00:49<00:43, 114MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.04G/9.98G [00:49<00:39, 124MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.06G/9.98G [00:49<00:35, 138MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.09G/9.98G [00:49<00:32, 151MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.11G/9.98G [00:49<00:30, 161MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.13G/9.98G [00:49<00:28, 171MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.15G/9.98G [00:50<00:26, 180MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.17G/9.98G [00:50<00:25, 186MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.20G/9.98G [00:50<00:24, 195MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.22G/9.98G [00:50<00:24, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.24G/9.98G [00:50<00:25, 189MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.26G/9.98G [00:50<00:24, 189MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.28G/9.98G [00:50<00:24, 189MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.31G/9.98G [00:52<02:06, 36.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.33G/9.98G [00:53<02:46, 28.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 5.36G/9.98G [00:53<01:50, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 5.38G/9.98G [00:54<01:32, 49.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 5.40G/9.98G [00:54<01:13, 62.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 5.42G/9.98G [00:54<00:59, 76.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.45G/9.98G [00:54<00:45, 100MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.47G/9.98G [00:54<00:40, 111MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.49G/9.98G [00:54<00:35, 127MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.52G/9.98G [00:54<00:31, 142MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.54G/9.98G [00:54<00:28, 154MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 5.56G/9.98G [00:54<00:26, 164MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 5.58G/9.98G [00:55<00:25, 175MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 5.60G/9.98G [00:55<00:24, 178MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 5.63G/9.98G [00:55<00:22, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.65G/9.98G [00:55<00:22, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.67G/9.98G [00:55<00:22, 189MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.69G/9.98G [00:55<00:22, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.71G/9.98G [00:55<00:21, 195MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.75G/9.98G [00:55<00:21, 199MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.77G/9.98G [00:58<02:55, 23.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.79G/9.98G [00:58<02:12, 31.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.81G/9.98G [00:59<01:40, 41.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.83G/9.98G [00:59<01:17, 53.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.85G/9.98G [00:59<01:00, 68.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.87G/9.98G [00:59<00:48, 84.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.89G/9.98G [00:59<00:41, 98.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.91G/9.98G [00:59<00:35, 113MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.93G/9.98G [00:59<00:32, 124MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 5.96G/9.98G [00:59<00:29, 135MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 5.98G/9.98G [01:00<00:28, 142MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 6.00G/9.98G [01:00<00:26, 152MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 6.02G/9.98G [01:00<00:24, 163MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.04G/9.98G [01:00<00:22, 173MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.06G/9.98G [01:00<00:21, 180MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.08G/9.98G [01:00<00:20, 186MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.10G/9.98G [01:00<00:21, 181MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.12G/9.98G [01:00<00:22, 174MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.14G/9.98G [01:00<00:23, 165MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.17G/9.98G [01:01<00:23, 164MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.19G/9.98G [01:01<00:23, 164MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.21G/9.98G [01:01<00:22, 165MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.23G/9.98G [01:03<01:44, 35.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.25G/9.98G [01:03<01:18, 47.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.27G/9.98G [01:03<01:00, 61.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.29G/9.98G [01:03<00:51, 71.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.31G/9.98G [01:03<00:41, 87.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.33G/9.98G [01:03<00:34, 106MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 6.35G/9.98G [01:03<00:29, 123MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 6.38G/9.98G [01:03<00:26, 135MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 6.40G/9.98G [01:03<00:24, 147MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 6.42G/9.98G [01:04<00:22, 161MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.44G/9.98G [01:04<00:20, 170MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.47G/9.98G [01:04<00:18, 185MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.50G/9.98G [01:04<00:17, 196MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.53G/9.98G [01:04<00:17, 202MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.55G/9.98G [01:04<00:16, 203MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.57G/9.98G [01:04<00:17, 189MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.60G/9.98G [01:04<00:17, 188MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.63G/9.98G [01:05<00:17, 195MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.65G/9.98G [01:05<00:16, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.67G/9.98G [01:08<02:36, 21.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.70G/9.98G [01:08<01:44, 31.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.72G/9.98G [01:08<01:25, 38.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 6.74G/9.98G [01:09<01:07, 48.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 6.77G/9.98G [01:09<00:47, 67.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 6.81G/9.98G [01:09<00:36, 87.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 6.83G/9.98G [01:09<00:32, 96.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.85G/9.98G [01:09<00:28, 112MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.87G/9.98G [01:09<00:24, 126MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.89G/9.98G [01:09<00:21, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.91G/9.98G [01:09<00:20, 152MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.93G/9.98G [01:10<00:18, 162MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 6.96G/9.98G [01:10<00:16, 178MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 6.99G/9.98G [01:10<00:15, 189MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 7.03G/9.98G [01:10<00:15, 196MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.05G/9.98G [01:10<00:14, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.07G/9.98G [01:10<00:14, 194MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.09G/9.98G [01:10<00:15, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.11G/9.98G [01:10<00:15, 188MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.13G/9.98G [01:11<00:14, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.15G/9.98G [01:11<00:14, 194MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.17G/9.98G [01:13<01:46, 26.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.19G/9.98G [01:13<01:20, 34.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.21G/9.98G [01:13<01:00, 45.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.24G/9.98G [01:14<00:46, 59.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.26G/9.98G [01:14<00:36, 73.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.28G/9.98G [01:14<00:29, 90.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.30G/9.98G [01:14<00:24, 108MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.32G/9.98G [01:14<00:21, 126MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.34G/9.98G [01:14<00:19, 137MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.36G/9.98G [01:14<00:18, 144MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.38G/9.98G [01:14<00:17, 150MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.40G/9.98G [01:14<00:16, 156MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.42G/9.98G [01:15<00:15, 162MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.44G/9.98G [01:15<00:15, 168MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.47G/9.98G [01:15<00:14, 171MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.49G/9.98G [01:15<00:14, 178MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.51G/9.98G [01:15<00:13, 181MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.54G/9.98G [01:15<00:13, 182MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.56G/9.98G [01:15<00:14, 172MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.58G/9.98G [01:15<00:14, 166MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.60G/9.98G [01:16<00:14, 167MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.62G/9.98G [01:16<00:14, 167MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.64G/9.98G [01:16<00:14, 165MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.67G/9.98G [01:18<01:31, 25.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.70G/9.98G [01:19<00:59, 38.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.72G/9.98G [01:19<00:46, 48.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.75G/9.98G [01:19<00:32, 68.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.77G/9.98G [01:19<00:26, 81.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.79G/9.98G [01:19<00:22, 96.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.81G/9.98G [01:19<00:19, 110MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.83G/9.98G [01:19<00:17, 125MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.85G/9.98G [01:19<00:15, 136MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.87G/9.98G [01:19<00:14, 148MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.90G/9.98G [01:20<00:12, 161MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.92G/9.98G [01:20<00:12, 171MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 7.95G/9.98G [01:20<00:10, 186MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 7.98G/9.98G [01:20<00:10, 193MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 8.00G/9.98G [01:20<00:10, 194MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.03G/9.98G [01:20<00:09, 202MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.05G/9.98G [01:20<00:09, 197MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.07G/9.98G [01:20<00:10, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.10G/9.98G [01:21<00:09, 193MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.12G/9.98G [01:21<00:09, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.14G/9.98G [01:21<00:09, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.16G/9.98G [01:23<01:06, 27.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.18G/9.98G [01:23<00:49, 36.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.20G/9.98G [01:23<00:37, 47.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.22G/9.98G [01:24<00:30, 57.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.25G/9.98G [01:24<00:21, 80.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.27G/9.98G [01:24<00:17, 96.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.29G/9.98G [01:24<00:15, 110MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.32G/9.98G [01:24<00:13, 121MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 8.34G/9.98G [01:24<00:12, 134MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 8.36G/9.98G [01:24<00:10, 150MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 8.39G/9.98G [01:24<00:09, 169MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 8.41G/9.98G [01:25<00:09, 171MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.44G/9.98G [01:25<00:08, 184MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.46G/9.98G [01:25<00:07, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.48G/9.98G [01:25<00:07, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.50G/9.98G [01:25<00:07, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.52G/9.98G [01:25<00:07, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 8.55G/9.98G [01:25<00:07, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 8.57G/9.98G [01:25<00:07, 194MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 8.59G/9.98G [01:28<00:59, 23.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 8.61G/9.98G [01:28<00:43, 31.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.63G/9.98G [01:28<00:32, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.65G/9.98G [01:28<00:24, 54.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.67G/9.98G [01:29<00:18, 69.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.69G/9.98G [01:29<00:15, 82.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.71G/9.98G [01:29<00:12, 99.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.73G/9.98G [01:29<00:14, 84.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.76G/9.98G [01:29<00:12, 101MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.78G/9.98G [01:29<00:10, 111MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.80G/9.98G [01:30<00:09, 128MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.82G/9.98G [01:30<00:08, 137MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 8.84G/9.98G [01:30<00:07, 151MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 8.86G/9.98G [01:30<00:07, 152MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 8.88G/9.98G [01:30<00:06, 163MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 8.90G/9.98G [01:30<00:06, 172MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 8.92G/9.98G [01:30<00:06, 169MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 8.94G/9.98G [01:30<00:06, 162MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 8.97G/9.98G [01:30<00:06, 164MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 8.99G/9.98G [01:31<00:05, 170MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 9.01G/9.98G [01:31<00:05, 171MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 9.03G/9.98G [01:31<00:05, 171MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 9.05G/9.98G [01:33<00:25, 35.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 9.07G/9.98G [01:33<00:19, 47.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 9.09G/9.98G [01:33<00:14, 61.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 9.11G/9.98G [01:33<00:11, 76.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.13G/9.98G [01:33<00:09, 88.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.16G/9.98G [01:33<00:07, 114MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.19G/9.98G [01:33<00:06, 128MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.21G/9.98G [01:33<00:05, 139MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.23G/9.98G [01:33<00:05, 147MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.25G/9.98G [01:34<00:04, 156MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.27G/9.98G [01:34<00:04, 165MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.29G/9.98G [01:34<00:04, 170MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.32G/9.98G [01:34<00:03, 186MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.34G/9.98G [01:34<00:03, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.36G/9.98G [01:34<00:03, 196MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.38G/9.98G [01:34<00:03, 193MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.41G/9.98G [01:34<00:03, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.43G/9.98G [01:35<00:02, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.45G/9.98G [01:35<00:02, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.47G/9.98G [01:35<00:02, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.49G/9.98G [01:35<00:02, 187MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.51G/9.98G [01:35<00:02, 188MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.53G/9.98G [01:35<00:02, 194MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.56G/9.98G [01:35<00:02, 202MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.59G/9.98G [01:35<00:01, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.62G/9.98G [01:35<00:01, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.65G/9.98G [01:36<00:01, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.67G/9.98G [01:36<00:01, 194MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.70G/9.98G [01:36<00:01, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.73G/9.98G [01:36<00:01, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.76G/9.98G [01:36<00:01, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.78G/9.98G [01:36<00:00, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.80G/9.98G [01:36<00:00, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.83G/9.98G [01:37<00:00, 195MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.85G/9.98G [01:37<00:00, 195MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.87G/9.98G [01:37<00:00, 196MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.89G/9.98G [01:37<00:00, 199MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.91G/9.98G [01:37<00:00, 166MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 9.93G/9.98G [01:37<00:00, 175MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 9.95G/9.98G [01:37<00:00, 181MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 9.98G/9.98G [01:37<00:00, 102MB/s]\n",
            "Downloading shards:  50% 1/2 [01:38<01:38, 98.03s/it]\n",
            "model-00002-of-00002.safetensors:   0% 0.00/3.50G [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   1% 21.0M/3.50G [00:00<00:16, 207MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   1% 41.9M/3.50G [00:00<00:17, 200MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   2% 62.9M/3.50G [00:00<00:17, 200MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   2% 83.9M/3.50G [00:00<00:17, 198MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   3% 105M/3.50G [00:00<00:17, 196MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:   4% 126M/3.50G [00:00<00:16, 200MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   4% 147M/3.50G [00:00<00:16, 200MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   5% 178M/3.50G [00:00<00:16, 204MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   6% 210M/3.50G [00:01<00:15, 208MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   7% 231M/3.50G [00:01<00:16, 203MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   7% 252M/3.50G [00:01<00:16, 196MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   8% 273M/3.50G [00:01<00:16, 197MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   8% 294M/3.50G [00:01<00:16, 195MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   9% 315M/3.50G [00:01<00:16, 197MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  10% 336M/3.50G [00:01<00:15, 200MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  10% 367M/3.50G [00:01<00:15, 197MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  11% 398M/3.50G [00:01<00:15, 202MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  12% 430M/3.50G [00:02<00:14, 206MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  13% 451M/3.50G [00:02<00:14, 203MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  14% 482M/3.50G [00:02<00:14, 206MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  14% 503M/3.50G [00:02<00:14, 203MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  15% 524M/3.50G [00:02<00:15, 198MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  16% 545M/3.50G [00:02<00:14, 199MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  16% 566M/3.50G [00:02<00:14, 197MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  17% 587M/3.50G [00:02<00:14, 196MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  17% 608M/3.50G [00:03<00:14, 197MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  18% 629M/3.50G [00:03<00:14, 195MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  19% 650M/3.50G [00:03<00:14, 198MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  19% 671M/3.50G [00:03<00:14, 198MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  20% 703M/3.50G [00:03<00:13, 201MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  21% 734M/3.50G [00:03<00:13, 205MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  22% 765M/3.50G [00:03<00:13, 208MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  22% 786M/3.50G [00:03<00:13, 207MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  23% 807M/3.50G [00:04<00:13, 200MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  24% 828M/3.50G [00:04<00:13, 200MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  24% 849M/3.50G [00:04<00:13, 196MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  25% 870M/3.50G [00:04<00:13, 194MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  25% 891M/3.50G [00:04<00:13, 195MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  26% 912M/3.50G [00:05<00:53, 47.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  27% 933M/3.50G [00:05<00:41, 61.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  27% 954M/3.50G [00:05<00:32, 77.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  28% 975M/3.50G [00:06<00:30, 83.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  28% 996M/3.50G [00:06<00:25, 98.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  29% 1.02G/3.50G [00:06<00:21, 115MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  30% 1.04G/3.50G [00:06<00:18, 130MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  30% 1.06G/3.50G [00:06<00:17, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  31% 1.08G/3.50G [00:06<00:16, 150MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  31% 1.10G/3.50G [00:06<00:15, 155MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  32% 1.12G/3.50G [00:06<00:15, 158MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  33% 1.14G/3.50G [00:07<00:14, 165MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  33% 1.16G/3.50G [00:07<00:13, 171MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  34% 1.18G/3.50G [00:07<00:13, 175MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  34% 1.21G/3.50G [00:07<00:12, 179MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  35% 1.23G/3.50G [00:07<00:12, 178MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  36% 1.25G/3.50G [00:07<00:13, 172MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  36% 1.27G/3.50G [00:07<00:13, 166MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  37% 1.29G/3.50G [00:07<00:13, 166MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  37% 1.31G/3.50G [00:08<00:13, 165MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  38% 1.33G/3.50G [00:09<00:45, 47.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  39% 1.35G/3.50G [00:10<01:18, 27.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  39% 1.36G/3.50G [00:11<01:15, 28.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  40% 1.38G/3.50G [00:11<00:52, 39.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  40% 1.42G/3.50G [00:11<00:34, 60.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  41% 1.44G/3.50G [00:11<00:27, 75.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  42% 1.46G/3.50G [00:11<00:22, 92.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  42% 1.48G/3.50G [00:11<00:18, 108MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  43% 1.50G/3.50G [00:11<00:16, 124MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  43% 1.52G/3.50G [00:11<00:14, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  44% 1.54G/3.50G [00:11<00:12, 152MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  45% 1.56G/3.50G [00:12<00:11, 163MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  45% 1.58G/3.50G [00:12<00:11, 171MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  46% 1.60G/3.50G [00:12<00:10, 180MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  46% 1.63G/3.50G [00:12<00:10, 187MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  47% 1.65G/3.50G [00:12<00:09, 192MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  48% 1.68G/3.50G [00:12<00:09, 201MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  49% 1.70G/3.50G [00:12<00:08, 201MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  49% 1.72G/3.50G [00:12<00:09, 196MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  50% 1.74G/3.50G [00:12<00:09, 195MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  50% 1.76G/3.50G [00:13<00:08, 195MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  51% 1.78G/3.50G [00:13<00:08, 194MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  52% 1.80G/3.50G [00:14<00:27, 60.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  52% 1.82G/3.50G [00:15<00:59, 28.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  53% 1.85G/3.50G [00:15<00:43, 37.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  53% 1.87G/3.50G [00:15<00:32, 50.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  54% 1.89G/3.50G [00:16<00:24, 64.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  55% 1.92G/3.50G [00:16<00:17, 89.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  55% 1.94G/3.50G [00:16<00:16, 96.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  56% 1.96G/3.50G [00:16<00:14, 110MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  57% 1.98G/3.50G [00:16<00:12, 126MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  57% 2.00G/3.50G [00:16<00:10, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  58% 2.02G/3.50G [00:16<00:10, 141MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  58% 2.04G/3.50G [00:16<00:09, 152MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  59% 2.07G/3.50G [00:17<00:08, 163MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  60% 2.09G/3.50G [00:17<00:08, 172MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  60% 2.11G/3.50G [00:17<00:07, 180MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  61% 2.13G/3.50G [00:17<00:07, 187MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  62% 2.16G/3.50G [00:17<00:06, 193MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  62% 2.18G/3.50G [00:17<00:06, 192MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  63% 2.20G/3.50G [00:17<00:06, 195MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  64% 2.22G/3.50G [00:17<00:06, 198MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  64% 2.24G/3.50G [00:17<00:06, 192MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  65% 2.26G/3.50G [00:20<00:51, 24.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  65% 2.29G/3.50G [00:20<00:37, 32.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  66% 2.31G/3.50G [00:20<00:28, 41.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  67% 2.33G/3.50G [00:21<00:21, 54.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  67% 2.35G/3.50G [00:21<00:16, 68.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  68% 2.37G/3.50G [00:21<00:13, 84.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  68% 2.39G/3.50G [00:21<00:11, 101MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  69% 2.41G/3.50G [00:21<00:09, 118MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  69% 2.43G/3.50G [00:21<00:08, 130MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  70% 2.45G/3.50G [00:21<00:07, 136MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  71% 2.47G/3.50G [00:21<00:07, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  71% 2.50G/3.50G [00:22<00:07, 142MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  72% 2.52G/3.50G [00:22<00:06, 146MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  72% 2.54G/3.50G [00:22<00:06, 152MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  73% 2.56G/3.50G [00:22<00:05, 165MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  74% 2.58G/3.50G [00:22<00:05, 173MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  74% 2.60G/3.50G [00:22<00:05, 179MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  75% 2.62G/3.50G [00:22<00:04, 180MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  75% 2.64G/3.50G [00:22<00:05, 171MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  76% 2.66G/3.50G [00:23<00:07, 107MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  77% 2.68G/3.50G [00:23<00:07, 116MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  77% 2.71G/3.50G [00:23<00:06, 127MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  78% 2.73G/3.50G [00:23<00:05, 137MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  78% 2.75G/3.50G [00:23<00:05, 146MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  79% 2.77G/3.50G [00:25<00:17, 42.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  80% 2.80G/3.50G [00:25<00:11, 62.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  81% 2.82G/3.50G [00:25<00:09, 70.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  81% 2.84G/3.50G [00:25<00:07, 84.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  82% 2.86G/3.50G [00:25<00:06, 101MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  83% 2.89G/3.50G [00:25<00:04, 127MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  83% 2.92G/3.50G [00:25<00:04, 133MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  84% 2.94G/3.50G [00:26<00:03, 144MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  84% 2.96G/3.50G [00:26<00:03, 154MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  85% 2.98G/3.50G [00:26<00:03, 162MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  86% 3.00G/3.50G [00:26<00:02, 172MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  86% 3.02G/3.50G [00:26<00:02, 181MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  87% 3.05G/3.50G [00:26<00:02, 192MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  88% 3.07G/3.50G [00:26<00:02, 196MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  89% 3.10G/3.50G [00:26<00:01, 202MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  89% 3.12G/3.50G [00:26<00:01, 203MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  90% 3.15G/3.50G [00:27<00:01, 198MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  90% 3.17G/3.50G [00:27<00:01, 191MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  91% 3.19G/3.50G [00:27<00:01, 191MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  92% 3.21G/3.50G [00:27<00:01, 192MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  92% 3.23G/3.50G [00:27<00:01, 195MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  93% 3.25G/3.50G [00:27<00:01, 195MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  94% 3.28G/3.50G [00:27<00:01, 201MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  94% 3.30G/3.50G [00:27<00:00, 202MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  95% 3.33G/3.50G [00:28<00:00, 206MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  96% 3.37G/3.50G [00:28<00:00, 204MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  97% 3.39G/3.50G [00:28<00:00, 197MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  97% 3.41G/3.50G [00:28<00:00, 193MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  98% 3.43G/3.50G [00:28<00:00, 194MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  99% 3.45G/3.50G [00:28<00:00, 198MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  99% 3.47G/3.50G [00:29<00:00, 83.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 3.50G/3.50G [00:31<00:00, 112MB/s] \n",
            "Downloading shards: 100% 2/2 [02:09<00:00, 64.75s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [01:09<00:00, 34.72s/it]\n",
            "generation_config.json: 100% 188/188 [00:00<00:00, 1.14MB/s]\n",
            "tokenizer_config.json: 100% 776/776 [00:00<00:00, 4.65MB/s]\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 304MB/s]\n",
            "tokenizer.json: 100% 1.84M/1.84M [00:00<00:00, 31.6MB/s]\n",
            "special_tokens_map.json: 100% 414/414 [00:00<00:00, 2.57MB/s]\n",
            "Lenght of train: 3838\n",
            "Lenght of valid: 548\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:159: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
            "  warnings.warn(\n",
            "100% 4/4 [00:00<00:00,  6.10ba/s]\n",
            "100% 1/1 [00:00<00:00, 14.87ba/s]\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:127: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n",
            "For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "Cloning https://huggingface.co/lfmatosmelo/llama2-7b-trofi-classification into local empty directory.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 2.9877, 'learning_rate': 0.00017241379310344826, 'epoch': 0.03}\n",
            "{'loss': 2.0106, 'learning_rate': 0.00019974902686642558, 'epoch': 0.05}\n",
            "{'loss': 1.9969, 'learning_rate': 0.00019879769716629774, 'epoch': 0.08}\n",
            "{'loss': 1.7702, 'learning_rate': 0.0001971436679663336, 'epoch': 0.1}\n",
            "{'loss': 1.9473, 'learning_rate': 0.00019479870356392938, 'epoch': 0.13}\n",
            "{'loss': 1.6535, 'learning_rate': 0.0001917794825392541, 'epoch': 0.16}\n",
            "{'loss': 1.9342, 'learning_rate': 0.0001881074791286998, 'epoch': 0.18}\n",
            "{'loss': 1.7024, 'learning_rate': 0.00018380881048918405, 'epoch': 0.21}\n",
            "{'loss': 1.8255, 'learning_rate': 0.00017891405093963938, 'epoch': 0.23}\n",
            "{'loss': 1.7015, 'learning_rate': 0.0001734580145008975, 'epoch': 0.26}\n",
            "{'loss': 1.8779, 'learning_rate': 0.00016747950728065688, 'epoch': 0.29}\n",
            "{'loss': 1.6701, 'learning_rate': 0.00016102105146469645, 'epoch': 0.31}\n",
            "{'loss': 1.8674, 'learning_rate': 0.00015412858287745093, 'epoch': 0.34}\n",
            "{'loss': 1.6387, 'learning_rate': 0.0001468511242630511, 'epoch': 0.36}\n",
            "{'loss': 1.8766, 'learning_rate': 0.00013924043661062016, 'epoch': 0.39}\n",
            "{'loss': 1.6212, 'learning_rate': 0.00013135065100377814, 'epoch': 0.42}\n",
            "{'loss': 1.8543, 'learning_rate': 0.00012323788361282814, 'epoch': 0.44}\n",
            "{'loss': 1.6126, 'learning_rate': 0.00011495983656799609, 'epoch': 0.47}\n",
            "{'loss': 1.8354, 'learning_rate': 0.00010657538755251619, 'epoch': 0.49}\n",
            "{'loss': 1.6941, 'learning_rate': 9.814417103458526e-05, 'epoch': 0.52}\n",
            "{'loss': 1.8553, 'learning_rate': 8.97261541166772e-05, 'epoch': 0.55}\n",
            "{'loss': 1.6477, 'learning_rate': 8.138121001899342e-05, 'epoch': 0.57}\n",
            "{'loss': 1.8216, 'learning_rate': 7.316869223065156e-05, 'epoch': 0.6}\n",
            "{'loss': 1.6304, 'learning_rate': 6.514701235746613e-05, 'epoch': 0.62}\n",
            "{'loss': 1.9044, 'learning_rate': 5.737322466888283e-05, 'epoch': 0.65}\n",
            "{'loss': 1.6421, 'learning_rate': 4.990262029897942e-05, 'epoch': 0.68}\n",
            "{'loss': 1.8003, 'learning_rate': 4.278833398778306e-05, 'epoch': 0.7}\n",
            "{'loss': 1.5788, 'learning_rate': 3.608096615995898e-05, 'epoch': 0.73}\n",
            "{'loss': 1.8166, 'learning_rate': 2.9828223028840286e-05, 'epoch': 0.76}\n",
            "{'loss': 1.6416, 'learning_rate': 2.407457728556115e-05, 'epoch': 0.78}\n",
            "{'loss': 1.8298, 'learning_rate': 1.886095178664552e-05, 'epoch': 0.81}\n",
            "{'loss': 1.6722, 'learning_rate': 1.4224428489826247e-05, 'epoch': 0.83}\n",
            "{'loss': 1.8787, 'learning_rate': 1.0197984708290808e-05, 'epoch': 0.86}\n",
            "{'loss': 1.5336, 'learning_rate': 6.810258559247995e-06, 'epoch': 0.89}\n",
            "{'loss': 1.7894, 'learning_rate': 4.0853452750644335e-06, 'epoch': 0.91}\n",
            "{'loss': 1.5711, 'learning_rate': 2.0426258257102428e-06, 'epoch': 0.94}\n",
            "{'loss': 1.8251, 'learning_rate': 6.966290714375933e-07, 'epoch': 0.96}\n",
            "{'loss': 1.6366, 'learning_rate': 5.69284261330183e-08, 'epoch': 0.99}\n",
            "{'train_runtime': 1213.5869, 'train_samples_per_second': 3.163, 'train_steps_per_second': 0.791, 'train_loss': 1.7931021173795065, 'epoch': 1.0}\n",
            "Saving fine-tuned model to llama2-7b-trofi-classification\n",
            "Uploading fine-tuned model (llama2-7b-trofi-classification) to HuggingFace Hub\n",
            "Upload file adapter_model.bin:   0% 1.00/128M [00:00<?, ?B/s]\n",
            "Upload file adapter_model.bin:  95% 122M/128M [00:04<00:00, 32.9MB/s] To https://huggingface.co/lfmatosmelo/llama2-7b-trofi-classification\n",
            "   3b2ab67..baca523  main -> main\n",
            "\n",
            "Upload file adapter_model.bin: 100% 128M/128M [00:05<00:00, 26.8MB/s]\n",
            "\n",
            "Upload file training_args.bin: 100% 4.30k/4.30k [00:05<00:00, 3.20MB/s]\u001b[A\n",
            "Upload file training_args.bin: 100% 4.30k/4.30k [00:05<00:00, 880B/s]  \n",
            "To https://huggingface.co/lfmatosmelo/llama2-7b-trofi-classification\n",
            "   baca523..1446c36  main -> main\n",
            "\n",
            "Fine-tuned model saved to 'llama2-7b-trofi-classification'\n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"$WORKDIR\" python -m src.main --llm llama2-7b --temperature 0 --dataset trofi --task classification --seed 1 --fine_tuning --push-model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "13hj4xNS55O7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e32dacd-911a-4fe8-dd3f-4f36514490b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-09 22:53:39.265345: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-09 22:53:39.265404: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-09 22:53:39.265441: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-09 22:53:40.968471: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "User is already logged in.\n",
            "\n",
            "llm: llama2-7b\n",
            "fine_tuned_model_path: llama2-7b-trofi-classification\n",
            "dataset: trofi\n",
            "task: classification\n",
            "temperature: 0.0\n",
            "seed: 1\n",
            "evaluate: True\n",
            "fine_tuning: True\n",
            "\n",
            "\n",
            "Fine-tuned model path received, model will be loaded for evaluation\n",
            "No. of unreachable objects: 0\n",
            "Loading checkpoint shards: 100% 2/2 [01:07<00:00, 33.87s/it]\n",
            "Lenght of test: 548\n",
            "Getting completions...\n",
            "Evaluating test set performance...\n",
            "Accuracy: 0.5036496350364964\n",
            "F1 score: 0.6682926829268293\n",
            "Precision: 0.5018315018315018\n",
            "Recall: 1.0\n",
            "\n",
            "Validation results: {\n",
            "    \"model\": \"llama2-7b\",\n",
            "    \"acc\": 0.5036496350364964,\n",
            "    \"f1\": 0.6682926829268293,\n",
            "    \"precision\": 0.5018315018315018,\n",
            "    \"recall\": 1.0,\n",
            "    \"temperature\": 0.0,\n",
            "    \"eval_split\": \"test\",\n",
            "    \"dataset_name\": \"trofi\",\n",
            "    \"fine_tuning\": true\n",
            "}\n",
            "\n",
            "Lenght of test: 1096\n",
            "Getting completions...\n",
            "Evaluating test set performance...\n",
            "Accuracy: 0.5027372262773723\n",
            "F1 score: 0.6670739156994502\n",
            "Precision: 0.5013774104683195\n",
            "Recall: 0.9963503649635036\n",
            "\n",
            "Test results: {\n",
            "    \"model\": \"llama2-7b\",\n",
            "    \"acc\": 0.5027372262773723,\n",
            "    \"f1\": 0.6670739156994502,\n",
            "    \"precision\": 0.5013774104683195,\n",
            "    \"recall\": 0.9963503649635036,\n",
            "    \"temperature\": 0.0,\n",
            "    \"eval_split\": \"test\",\n",
            "    \"dataset_name\": \"trofi\",\n",
            "    \"fine_tuning\": true\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"$WORKDIR\" python -m src.main --llm llama2-7b --temperature 0 --dataset trofi --task classification --fine_tuned_model_path \"llama2-7b-trofi-classification\" --seed 1 --fine_tuning --evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAjsFG53lyY5"
      },
      "source": [
        "## VUA POS - Metaphor classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "F3gQuRl3oJX_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d58b35d2-8fa4-49fe-8215-6a1fa34d796a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-09 22:58:55.843048: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-09 22:58:55.843103: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-09 22:58:55.843139: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-09 22:58:57.652636: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "User is already logged in.\n",
            "\n",
            "llm: llama2-7b\n",
            "fine_tuned_model_path: None\n",
            "dataset: vua_pos\n",
            "task: classification\n",
            "temperature: 0.0\n",
            "seed: 1\n",
            "evaluate: False\n",
            "fine_tuning: True\n",
            "\n",
            "\n",
            "Loading checkpoint shards: 100% 2/2 [01:09<00:00, 34.64s/it]\n",
            "Lenght of train: 3506\n",
            "Lenght of valid: 502\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:159: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
            "  warnings.warn(\n",
            "100% 4/4 [00:00<00:00,  4.68ba/s]\n",
            "100% 1/1 [00:00<00:00, 11.84ba/s]\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:127: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n",
            "For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "Cloning https://huggingface.co/lfmatosmelo/llama2-7b-vua-pos-classification into local empty directory.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 2.9974, 'learning_rate': 0.0001851851851851852, 'epoch': 0.03}\n",
            "{'loss': 2.0397, 'learning_rate': 0.00019963890121669128, 'epoch': 0.06}\n",
            "{'loss': 2.1931, 'learning_rate': 0.00019843045051787096, 'epoch': 0.09}\n",
            "{'loss': 1.7067, 'learning_rate': 0.00019638222592083143, 'epoch': 0.11}\n",
            "{'loss': 2.0989, 'learning_rate': 0.00019351170215565114, 'epoch': 0.14}\n",
            "{'loss': 1.6886, 'learning_rate': 0.0001898433695189763, 'epoch': 0.17}\n",
            "{'loss': 2.1664, 'learning_rate': 0.00018540852493144545, 'epoch': 0.2}\n",
            "{'loss': 1.6504, 'learning_rate': 0.00018024500492339719, 'epoch': 0.23}\n",
            "{'loss': 2.0813, 'learning_rate': 0.00017439686282693436, 'epoch': 0.26}\n",
            "{'loss': 1.6801, 'learning_rate': 0.0001679139929284271, 'epoch': 0.29}\n",
            "{'loss': 2.1087, 'learning_rate': 0.00016085170478805395, 'epoch': 0.31}\n",
            "{'loss': 1.5872, 'learning_rate': 0.00015327025135813594, 'epoch': 0.34}\n",
            "{'loss': 2.071, 'learning_rate': 0.0001452343149261919, 'epoch': 0.37}\n",
            "{'loss': 1.6126, 'learning_rate': 0.00013681245526846783, 'epoch': 0.4}\n",
            "{'loss': 2.0839, 'learning_rate': 0.0001280765247220993, 'epoch': 0.43}\n",
            "{'loss': 1.6543, 'learning_rate': 0.00011910105516630563, 'epoch': 0.46}\n",
            "{'loss': 2.124, 'learning_rate': 0.0001099626221426754, 'epoch': 0.48}\n",
            "{'loss': 1.682, 'learning_rate': 0.00010073919153964553, 'epoch': 0.51}\n",
            "{'loss': 2.0512, 'learning_rate': 9.150945441503093e-05, 'epoch': 0.54}\n",
            "{'loss': 1.5853, 'learning_rate': 8.235215563166528e-05, 'epoch': 0.57}\n",
            "{'loss': 2.0618, 'learning_rate': 7.33454220339956e-05, 'epoch': 0.6}\n",
            "{'loss': 1.7042, 'learning_rate': 6.45660958973924e-05, 'epoch': 0.63}\n",
            "{'loss': 2.067, 'learning_rate': 5.608907933694994e-05, 'epoch': 0.66}\n",
            "{'loss': 1.5419, 'learning_rate': 4.798669526905003e-05, 'epoch': 0.68}\n",
            "{'loss': 2.0134, 'learning_rate': 4.0328070377739936e-05, 'epoch': 0.71}\n",
            "{'loss': 1.5931, 'learning_rate': 3.317854535023714e-05, 'epoch': 0.74}\n",
            "{'loss': 1.9816, 'learning_rate': 2.6599117413224817e-05, 'epoch': 0.77}\n",
            "{'loss': 1.5613, 'learning_rate': 2.064591992602062e-05, 'epoch': 0.8}\n",
            "{'loss': 2.0174, 'learning_rate': 1.5369743470547027e-05, 'epoch': 0.83}\n",
            "{'loss': 1.7097, 'learning_rate': 1.0815602523994728e-05, 'epoch': 0.86}\n",
            "{'loss': 2.0476, 'learning_rate': 7.022351411174866e-06, 'epoch': 0.88}\n",
            "{'loss': 1.6862, 'learning_rate': 4.022352813119312e-06, 'epoch': 0.91}\n",
            "{'loss': 1.9726, 'learning_rate': 1.8412016600969695e-06, 'epoch': 0.94}\n",
            "{'loss': 1.6565, 'learning_rate': 4.975067646932118e-07, 'epoch': 0.97}\n",
            "{'loss': 1.855, 'learning_rate': 2.732057982124392e-09, 'epoch': 1.0}\n",
            "{'train_runtime': 1130.6313, 'train_samples_per_second': 3.101, 'train_steps_per_second': 0.776, 'train_loss': 1.8930280333641862, 'epoch': 1.0}\n",
            "Saving fine-tuned model to llama2-7b-vua-pos-classification\n",
            "Uploading fine-tuned model (llama2-7b-vua-pos-classification) to HuggingFace Hub\n",
            "Upload file adapter_model.bin:   0% 1.00/128M [00:00<?, ?B/s]\n",
            "Upload file adapter_model.bin: 137MB [00:04, 40.5MB/s]                To https://huggingface.co/lfmatosmelo/llama2-7b-vua-pos-classification\n",
            "   58f505b..665dc05  main -> main\n",
            "\n",
            "Upload file adapter_model.bin: 100% 128M/128M [00:05<00:00, 26.8MB/s]\n",
            "\n",
            "Upload file training_args.bin: 100% 4.30k/4.30k [00:05<00:00, 3.20MB/s]\u001b[A\n",
            "Upload file training_args.bin: 100% 4.30k/4.30k [00:05<00:00, 880B/s]  \n",
            "To https://huggingface.co/lfmatosmelo/llama2-7b-vua-pos-classification\n",
            "   665dc05..38f03c9  main -> main\n",
            "\n",
            "Fine-tuned model saved to 'llama2-7b-vua-pos-classification'\n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"$WORKDIR\" python -m src.main --llm llama2-7b --temperature 0 --dataset vua_pos --task classification --seed 1 --fine_tuning --push-model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qDAIuoEt55O8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73fcdf83-f822-4594-fde2-91206334af9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-09 23:34:09.737621: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-09 23:34:09.737687: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-09 23:34:09.737726: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-09 23:34:11.675397: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "User is already logged in.\n",
            "\n",
            "llm: llama2-7b\n",
            "fine_tuned_model_path: llama2-7b-vua-pos-classification\n",
            "dataset: vua_pos\n",
            "task: classification\n",
            "temperature: 0.0\n",
            "seed: 1\n",
            "evaluate: True\n",
            "fine_tuning: True\n",
            "\n",
            "\n",
            "Fine-tuned model path received, model will be loaded for evaluation\n",
            "No. of unreachable objects: 0\n",
            "Loading checkpoint shards: 100% 2/2 [01:10<00:00, 35.06s/it]\n",
            "Lenght of test: 502\n",
            "Getting completions...\n",
            "Evaluating test set performance...\n",
            "Accuracy: 0.603585657370518\n",
            "F1 score: 0.6074950690335306\n",
            "Precision: 0.6015625\n",
            "Recall: 0.6135458167330677\n",
            "\n",
            "Validation results: {\n",
            "    \"model\": \"llama2-7b\",\n",
            "    \"acc\": 0.603585657370518,\n",
            "    \"f1\": 0.6074950690335306,\n",
            "    \"precision\": 0.6015625,\n",
            "    \"recall\": 0.6135458167330677,\n",
            "    \"temperature\": 0.0,\n",
            "    \"eval_split\": \"test\",\n",
            "    \"dataset_name\": \"vua_pos\",\n",
            "    \"fine_tuning\": true\n",
            "}\n",
            "\n",
            "Lenght of test: 1002\n",
            "Getting completions...\n",
            "Evaluating test set performance...\n",
            "Accuracy: 0.5898203592814372\n",
            "F1 score: 0.5827411167512689\n",
            "Precision: 0.5929752066115702\n",
            "Recall: 0.5728542914171657\n",
            "\n",
            "Test results: {\n",
            "    \"model\": \"llama2-7b\",\n",
            "    \"acc\": 0.5898203592814372,\n",
            "    \"f1\": 0.5827411167512689,\n",
            "    \"precision\": 0.5929752066115702,\n",
            "    \"recall\": 0.5728542914171657,\n",
            "    \"temperature\": 0.0,\n",
            "    \"eval_split\": \"test\",\n",
            "    \"dataset_name\": \"vua_pos\",\n",
            "    \"fine_tuning\": true\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"$WORKDIR\" python -m src.main --llm llama2-7b --temperature 0 --dataset vua_pos --task classification --fine_tuned_model_path \"llama2-7b-vua-pos-classification\" --seed 1 --fine_tuning --evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPbjmgqdnREW"
      },
      "source": [
        "## VUA Verb - Metaphor classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oEleXDdAoKKQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51594220-be73-4f6e-bc87-a75c2326d9f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-10 00:14:42.212623: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-10 00:14:42.212694: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-10 00:14:42.212744: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-10 00:14:44.136673: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "User is already logged in.\n",
            "\n",
            "llm: llama2-7b\n",
            "fine_tuned_model_path: None\n",
            "dataset: vua_verb\n",
            "task: classification\n",
            "temperature: 0.0\n",
            "seed: 1\n",
            "evaluate: False\n",
            "fine_tuning: True\n",
            "\n",
            "\n",
            "Loading checkpoint shards: 100% 2/2 [01:17<00:00, 38.71s/it]\n",
            "Lenght of train: 2294\n",
            "Lenght of valid: 328\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:159: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
            "  warnings.warn(\n",
            "100% 3/3 [00:00<00:00,  8.26ba/s]\n",
            "100% 1/1 [00:00<00:00, 27.16ba/s]\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:127: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n",
            "For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "Cloning https://huggingface.co/lfmatosmelo/llama2-7b-vua-verb-classification into local empty directory.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 3.0334, 'learning_rate': 0.00019992179047854922, 'epoch': 0.04}\n",
            "{'loss': 1.8567, 'learning_rate': 0.00019836981604521076, 'epoch': 0.09}\n",
            "{'loss': 2.1638, 'learning_rate': 0.0001948582311066008, 'epoch': 0.13}\n",
            "{'loss': 1.6443, 'learning_rate': 0.00018945698942508772, 'epoch': 0.17}\n",
            "{'loss': 2.1297, 'learning_rate': 0.00018227368833455024, 'epoch': 0.22}\n",
            "{'loss': 1.5044, 'learning_rate': 0.00017345142530985887, 'epoch': 0.26}\n",
            "{'loss': 2.0497, 'learning_rate': 0.00016316594734331772, 'epoch': 0.3}\n",
            "{'loss': 1.6052, 'learning_rate': 0.00015162214991491538, 'epoch': 0.35}\n",
            "{'loss': 2.0817, 'learning_rate': 0.0001390499952998789, 'epoch': 0.39}\n",
            "{'loss': 1.6331, 'learning_rate': 0.00012569993152432028, 'epoch': 0.44}\n",
            "{'loss': 2.0625, 'learning_rate': 0.00011183790322728011, 'epoch': 0.48}\n",
            "{'loss': 1.5002, 'learning_rate': 9.774005381704497e-05, 'epoch': 0.52}\n",
            "{'loss': 2.0667, 'learning_rate': 8.368722445929653e-05, 'epoch': 0.57}\n",
            "{'loss': 1.4234, 'learning_rate': 6.995935948193294e-05, 'epoch': 0.61}\n",
            "{'loss': 2.1061, 'learning_rate': 5.682992964566213e-05, 'epoch': 0.65}\n",
            "{'loss': 1.4755, 'learning_rate': 4.4560484373566945e-05, 'epoch': 0.7}\n",
            "{'loss': 2.0784, 'learning_rate': 3.339544146386704e-05, 'epoch': 0.74}\n",
            "{'loss': 1.5351, 'learning_rate': 2.355721807923761e-05, 'epoch': 0.78}\n",
            "{'loss': 2.0997, 'learning_rate': 1.5241800007523122e-05, 'epoch': 0.83}\n",
            "{'loss': 1.5995, 'learning_rate': 8.614837457945868e-06, 'epoch': 0.87}\n",
            "{'loss': 2.0049, 'learning_rate': 3.808345167874361e-06, 'epoch': 0.91}\n",
            "{'loss': 1.5823, 'learning_rate': 9.180725568338044e-07, 'epoch': 0.96}\n",
            "{'train_runtime': 688.5079, 'train_samples_per_second': 3.332, 'train_steps_per_second': 0.834, 'train_loss': 1.871550888965354, 'epoch': 1.0}\n",
            "Saving fine-tuned model to llama2-7b-vua-verb-classification\n",
            "Uploading fine-tuned model (llama2-7b-vua-verb-classification) to HuggingFace Hub\n",
            "Upload file adapter_model.bin:   0% 1.00/128M [00:00<?, ?B/s]\n",
            "Upload file adapter_model.bin:  83% 107M/128M [00:03<00:00, 37.1MB/s] To https://huggingface.co/lfmatosmelo/llama2-7b-vua-verb-classification\n",
            "   8b45a29..1a093c8  main -> main\n",
            "\n",
            "Upload file adapter_model.bin: 100% 128M/128M [00:05<00:00, 26.8MB/s]\n",
            "\n",
            "Upload file training_args.bin: 100% 4.30k/4.30k [00:05<00:00, 3.20MB/s]\u001b[A\n",
            "Upload file training_args.bin: 100% 4.30k/4.30k [00:05<00:00, 881B/s]  \n",
            "To https://huggingface.co/lfmatosmelo/llama2-7b-vua-verb-classification\n",
            "   1a093c8..7fcc94d  main -> main\n",
            "\n",
            "Fine-tuned model saved to 'llama2-7b-vua-verb-classification'\n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"$WORKDIR\" python -m src.main --llm llama2-7b --temperature 0 --dataset vua_verb --task classification --seed 1 --fine_tuning --push-model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wpyMEpDq55O8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4299b4fb-e164-40c5-e6aa-c366b551b5ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-10 00:31:54.297062: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-10 00:31:54.297130: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-10 00:31:54.297171: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-10 00:31:56.557725: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "User is already logged in.\n",
            "\n",
            "llm: llama2-7b\n",
            "fine_tuned_model_path: llama2-7b-vua-verb-classification\n",
            "dataset: vua_verb\n",
            "task: classification\n",
            "temperature: 0.0\n",
            "seed: 1\n",
            "evaluate: True\n",
            "fine_tuning: True\n",
            "\n",
            "\n",
            "Fine-tuned model path received, model will be loaded for evaluation\n",
            "No. of unreachable objects: 0\n",
            "Loading checkpoint shards: 100% 2/2 [01:13<00:00, 36.91s/it]\n",
            "Lenght of test: 328\n",
            "Getting completions...\n",
            "Evaluating test set performance...\n",
            "Accuracy: 0.6676829268292683\n",
            "F1 score: 0.6746268656716418\n",
            "Precision: 0.6608187134502924\n",
            "Recall: 0.6890243902439024\n",
            "\n",
            "Validation results: {\n",
            "    \"model\": \"llama2-7b\",\n",
            "    \"acc\": 0.6676829268292683,\n",
            "    \"f1\": 0.6746268656716418,\n",
            "    \"precision\": 0.6608187134502924,\n",
            "    \"recall\": 0.6890243902439024,\n",
            "    \"temperature\": 0.0,\n",
            "    \"eval_split\": \"test\",\n",
            "    \"dataset_name\": \"vua_verb\",\n",
            "    \"fine_tuning\": true,\n",
            "    \"task_name\": \"classification\"\n",
            "}\n",
            "\n",
            "Lenght of test: 656\n",
            "Getting completions...\n",
            "Evaluating test set performance...\n",
            "Accuracy: 0.6463414634146342\n",
            "F1 score: 0.6547619047619049\n",
            "Precision: 0.6395348837209303\n",
            "Recall: 0.6707317073170732\n",
            "\n",
            "Test results: {\n",
            "    \"model\": \"llama2-7b\",\n",
            "    \"acc\": 0.6463414634146342,\n",
            "    \"f1\": 0.6547619047619049,\n",
            "    \"precision\": 0.6395348837209303,\n",
            "    \"recall\": 0.6707317073170732,\n",
            "    \"temperature\": 0.0,\n",
            "    \"eval_split\": \"test\",\n",
            "    \"dataset_name\": \"vua_verb\",\n",
            "    \"fine_tuning\": true,\n",
            "    \"task_name\": \"classification\"\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=\"$WORKDIR\" python -m src.main --llm llama2-7b --temperature 0 --dataset vua_verb --task classification --fine_tuned_model_path \"llama2-7b-vua-verb-classification\" --seed 1 --fine_tuning --evaluate"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "ElREVv_LqWJ-",
        "OWDNx3xCqJKR",
        "TZheHA4OlxsN",
        "-7YWEoprlx4R"
      ],
      "provenance": []
    },
    "interpreter": {
      "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}